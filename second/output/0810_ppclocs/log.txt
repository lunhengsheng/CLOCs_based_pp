model: {
  second: {
    voxel_generator {
      point_cloud_range : [0, -39.68, -3, 69.12, 39.68, 1]
      voxel_size : [0.16, 0.16, 4]
      max_number_of_points_per_voxel : 100
    }
    num_class: 1
    voxel_feature_extractor: {
      module_class_name: "PillarFeatureNet"
      num_filters: [64]
      with_distance: false
    }
    middle_feature_extractor: {
      module_class_name: "PointPillarsScatter"
    }
    rpn: {
      module_class_name: "RPN"
      layer_nums: [3, 5, 5]
      layer_strides: [2, 2, 2]
      num_filters: [64, 128, 256]
      upsample_strides: [1, 2, 4]
      num_upsample_filters: [128, 128, 128]
      use_groupnorm: false
      num_groups: 32
    }
    loss: {
      classification_loss: {
        weighted_sigmoid_focal: {
          alpha: 0.25
          gamma: 2.0
          anchorwise_output: true
        }
      }
      localization_loss: {
        weighted_smooth_l1: {
          sigma: 3.0
          code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
        }
      }
      classification_weight: 1.0
      localization_weight: 2.0
    }
    # Outputs
    use_sigmoid_score: true
    encode_background_as_zeros: true
    encode_rad_error_by_sin: true

    use_direction_classifier: true
    direction_loss_weight: 0.2
    use_aux_classifier: false
    # Loss
    pos_class_weight: 1.0
    neg_class_weight: 1.0

    loss_norm_type: NormByNumPositives
    # Postprocess
    post_center_limit_range: [0, -39.68, -5, 69.12, 39.68, 5]
    use_rotate_nms: false
    use_multi_class_nms: false
    nms_pre_max_size: 1000
    nms_post_max_size: 100             #MX original pp 300 CLOCs 100
    nms_score_threshold: 0.2           #MX original pp 0.05 CLOCs 0.2       #score 0.2, iou 0.5时效果最好
    nms_iou_threshold: 0.5            #MX original pp 0.5 CLOCs 0.01

    use_bev: false
    num_point_features: 4
    without_reflectivity: false
    box_coder: {
      ground_box3d_coder: {
        linear_dim: false
        encode_angle_vector: false
      }
    }
    target_assigner: {
      anchor_generators: {
         anchor_generator_stride: {
           sizes: [1.6, 3.9, 1.56] # wlh
           strides: [0.32, 0.32, 0.0] # if generate only 1 z_center, z_stride will be ignored   #MX这里可以调整anchor密度
           offsets: [0.16, -39.52, -1.78] # origin_offset + strides / 2
           rotations: [0, 1.57] # 0, pi/2
           matched_threshold : 0.6
           unmatched_threshold : 0.45
         }
       }

      sample_positive_fraction : -1
      sample_size : 512
      region_similarity_calculator: {
        nearest_iou_similarity: {
        }
      }
    }
  }
}


train_input_reader: {
  #record_file_path: "/mengxing/Data/Sets/kitti_pointpillars/kitti_train.tfrecord"
  class_names: ["Car"]
  max_num_epochs : 160
  batch_size: 1                 #2
  prefetch_size : 25
  max_number_of_voxels: 12000
  shuffle_points: true
  num_workers: 8    #2
  groundtruth_localization_noise_std: [0.25, 0.25, 0.25]                #MX？？
  groundtruth_rotation_uniform_noise: [-0.15707963267, 0.15707963267]
  global_rotation_uniform_noise: [-0.78539816, 0.78539816]
  global_scaling_uniform_noise: [0.95, 1.05]
  global_random_rotation_range_per_object: [0, 0]
  anchor_area_threshold: -1              #注意：pointpillars中为1，SECOND与CLOCs中为-1.置-1，使example['anchors_mask']=None #MX：与preprocess.py中代码关联,>0的条件
  remove_points_after_sample: false
  groundtruth_points_drop_percentage: 0.0
  groundtruth_drop_max_keep_points: 15
  database_sampler {
    database_info_path: "/home/lunhengsheng/CLOCs/kitti/kitti_dbinfos_train.pkl"
    sample_groups {
      name_to_max_num {
        key: "Car"
        value: 15
      }
    }
    database_prep_steps {
      filter_by_min_num_points {
        min_num_point_pairs {
          key: "Car"
          value: 5
        }
      }
    }
    database_prep_steps {
      filter_by_difficulty {
        removed_difficulties: [-1]
      }
    }
    global_random_rotation_range_per_object: [0, 0]
    rate: 1.0
  }

  remove_unknown_examples: false
  remove_environment: false
  kitti_info_path: "/home/lunhengsheng/CLOCs/kitti/kitti_infos_train.pkl"
  kitti_root_path: "/home/lunhengsheng/CLOCs/kitti"
}

train_config: {
  #optimizer: {
  #  adam_optimizer: {
  #    learning_rate: {
  #      exponential_decay_learning_rate: {
  #        initial_learning_rate: 0.0002
  #        decay_steps: 27840 # 1856 steps per epoch * 15 epochs
  #        decay_factor: 0.8
  #        staircase: true
  #      }
  #    }
  #    weight_decay: 0.0001
  #  }
  # use_moving_average: false
  #}

  optimizer: {
    adam_optimizer: {
      learning_rate: {
        one_cycle: {
          lr_max: 3e-3  # original 3e-3
          moms: [0.95, 0.85]
          div_factor: 10.0  #original 10
          pct_start: 0.4
        }
      }
      weight_decay: 0.01 # super converge. decrease this when you increase steps. og 0.01
    }
    fixed_weight_decay: true
    use_moving_average: false
  }

  inter_op_parallelism_threads: 4
  steps: 37120 #112215 #113715 #111360 # 619 * 50, super converge. increase this to achieve slightly better results original 30950
  steps_per_eval: 37120 #7424 #3712 #MX3712 #7481 # 619 * 5
  save_checkpoints_secs : 1800 # half hour 1800
  save_summary_steps : 10
  enable_mixed_precision: false # for fp16 training, don't use this.
  loss_scale_factor : 512.0
  clear_metrics_every_epoch: true
  #detection_2d_path: "../d2_detection_data"         #MX
}

eval_input_reader: {
  #record_file_path: "/mengxing/Data/Sets/kitti_pointpillars/kitti_val.tfrecord"
  class_names: ["Car"]
  batch_size: 1                 #2
  max_num_epochs : 160
  prefetch_size : 25
  max_number_of_voxels: 12000
  shuffle_points: false
  num_workers: 3
  anchor_area_threshold: -1          #注意：pointpillars中为1，SECOND与CLOCs中为-1.置-1，使example['anchors_mask']=None #MX：与preprocess.py中代码关联,>0的条件
  remove_environment: false
  kitti_info_path: "/home/lunhengsheng/CLOCs/kitti/kitti_infos_val.pkl"
  kitti_root_path: "/home/lunhengsheng/CLOCs/kitti"
  #kitti_info_path: "/mengxing/Data/Sets/raw_data/CLOCs_preprocess/object_format_2011_09_26_drive_0005/kitti_infos_test.pkl"
  #kitti_root_path: "/mengxing/Data/Sets/raw_data/CLOCs_preprocess/object_format_2011_09_26_drive_0005"
}

now it is 20 steps  and the cls_loss is : tensor(893.1616, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003000109113384191
now it is 40 steps  and the cls_loss is : tensor(1227.3174, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030004596412464566
now it is 60 steps  and the cls_loss is : tensor(888.0439, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003001051905568235
now it is 80 steps  and the cls_loss is : tensor(468.8560, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030018858957438265
now it is 100 steps  and the cls_loss is : tensor(542.7215, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000300296159683897
now it is 120 steps  and the cls_loss is : tensor(805.8947, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030042789895910705
now it is 140 steps  and the cls_loss is : tensor(595.0312, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000300583805040955
now it is 160 steps  and the cls_loss is : tensor(448.3504, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030076387513762936
now it is 180 steps  and the cls_loss is : tensor(273.2179, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030096810602461225
now it is 200 steps  and the cls_loss is : tensor(355.8181, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003011964940447371
now it is 220 steps  and the cls_loss is : tensor(370.8977, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030144903510825796
now it is 240 steps  and the cls_loss is : tensor(274.9055, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030172572469291774
now it is 260 steps  and the cls_loss is : tensor(387.5984, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030202655784403306
now it is 280 steps  and the cls_loss is : tensor(502.6347, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030235152917457934
now it is 300 steps  and the cls_loss is : tensor(171.7326, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003027006328652909
now it is 320 steps  and the cls_loss is : tensor(175.5946, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030307386266476347
now it is 340 steps  and the cls_loss is : tensor(243.0175, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003034712118895654
now it is 360 steps  and the cls_loss is : tensor(81.2313, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030389267342435843
now it is 380 steps  and the cls_loss is : tensor(309.8532, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000304338239722026
now it is 400 steps  and the cls_loss is : tensor(93.6907, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003048079028038046
now it is 420 steps  and the cls_loss is : tensor(110.4450, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030530165425943223
now it is 440 steps  and the cls_loss is : tensor(85.8641, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030581948524729475
now it is 460 steps  and the cls_loss is : tensor(54.8337, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003063613864945844
now it is 480 steps  and the cls_loss is : tensor(69.1916, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003069273482974688
now it is 500 steps  and the cls_loss is : tensor(70.2280, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003075173605212619
now it is 520 steps  and the cls_loss is : tensor(118.5975, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003081314126006066
now it is 540 steps  and the cls_loss is : tensor(29.9631, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030876949353966354
now it is 560 steps  and the cls_loss is : tensor(41.3835, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030943159191230887
now it is 580 steps  and the cls_loss is : tensor(52.9720, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031011769586233775
now it is 600 steps  and the cls_loss is : tensor(30.2769, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000310827793103677
now it is 620 steps  and the cls_loss is : tensor(17.4835, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003115618709206053
now it is 640 steps  and the cls_loss is : tensor(24.9568, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031231991616798103
now it is 660 steps  and the cls_loss is : tensor(13.2623, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003131019152714785
now it is 680 steps  and the cls_loss is : tensor(9.5714, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031390785422782735
now it is 700 steps  and the cls_loss is : tensor(12.1319, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003147377186050681
now it is 720 steps  and the cls_loss is : tensor(1.8115, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003155914935428078
now it is 740 steps  and the cls_loss is : tensor(8.7836, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031646916375248704
now it is 760 steps  and the cls_loss is : tensor(10.8263, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003173707135176525
now it is 780 steps  and the cls_loss is : tensor(3.0759, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031829612669424107
now it is 800 steps  and the cls_loss is : tensor(6.7790, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031924538671086484
now it is 820 steps  and the cls_loss is : tensor(7.1352, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000320218476569112
now it is 840 steps  and the cls_loss is : tensor(1.1795, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032121537884384965
now it is 860 steps  and the cls_loss is : tensor(4.5020, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032223607568353414
now it is 880 steps  and the cls_loss is : tensor(3.9405, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032328054881053305
now it is 900 steps  and the cls_loss is : tensor(4.0830, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003243487795214512
now it is 920 steps  and the cls_loss is : tensor(1.8700, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032544074868746725
now it is 940 steps  and the cls_loss is : tensor(2.0059, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032655643675467364
now it is 960 steps  and the cls_loss is : tensor(2.0557, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003276958237444288
now it is 980 steps  and the cls_loss is : tensor(2.3177, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003288588892537141
now it is 1000 steps  and the cls_loss is : tensor(1.5131, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003300456124554988
now it is 1020 steps  and the cls_loss is : tensor(2.0587, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033125597209911466
now it is 1040 steps  and the cls_loss is : tensor(1.2218, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033248994651063424
now it is 1060 steps  and the cls_loss is : tensor(1.7208, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003337475135932609
now it is 1080 steps  and the cls_loss is : tensor(1.4351, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033502865082772355
now it is 1100 steps  and the cls_loss is : tensor(1.6960, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033633333527267927
now it is 1120 steps  and the cls_loss is : tensor(1.4411, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033766154356512645
now it is 1140 steps  and the cls_loss is : tensor(1.2222, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033901325192082013
now it is 1160 steps  and the cls_loss is : tensor(1.2031, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003403884361346996
now it is 1180 steps  and the cls_loss is : tensor(1.0632, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00034178707158132255
now it is 1200 steps  and the cls_loss is : tensor(1.1570, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003432091332153048
now it is 1220 steps  and the cls_loss is : tensor(0.9596, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003446545955717692
now it is 1240 steps  and the cls_loss is : tensor(0.9760, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00034612343276679966
now it is 1260 steps  and the cls_loss is : tensor(0.9652, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003476156184979099
now it is 1280 steps  and the cls_loss is : tensor(0.9536, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003491311260445081
now it is 1300 steps  and the cls_loss is : tensor(0.9873, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00035066992826837977
now it is 1320 steps  and the cls_loss is : tensor(0.9044, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00035223199761417285
now it is 1340 steps  and the cls_loss is : tensor(0.9112, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00035381730610988893
now it is 1360 steps  and the cls_loss is : tensor(0.9732, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003554258253673868
now it is 1380 steps  and the cls_loss is : tensor(0.9569, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003570575265828902
now it is 1400 steps  and the cls_loss is : tensor(1.0234, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003587123805375023
now it is 1420 steps  and the cls_loss is : tensor(0.9605, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003603903575977313
now it is 1440 steps  and the cls_loss is : tensor(0.9489, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00036209142771601727
now it is 1460 steps  and the cls_loss is : tensor(0.9601, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00036381556043127514
now it is 1480 steps  and the cls_loss is : tensor(0.8623, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003655627248694356
now it is 1500 steps  and the cls_loss is : tensor(0.8592, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003673328897440013
now it is 1520 steps  and the cls_loss is : tensor(0.8965, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003691260233566044
now it is 1540 steps  and the cls_loss is : tensor(0.8682, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037094209359757714
now it is 1560 steps  and the cls_loss is : tensor(0.9750, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037278106794652426
now it is 1580 steps  and the cls_loss is : tensor(0.9558, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003746429134729064
now it is 1600 steps  and the cls_loss is : tensor(0.9052, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037652759683663023
now it is 1620 steps  and the cls_loss is : tensor(0.8552, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037843508428864366
now it is 1640 steps  and the cls_loss is : tensor(0.9323, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003803653416715436
now it is 1660 steps  and the cls_loss is : tensor(0.8620, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00038231833442018293
now it is 1680 steps  and the cls_loss is : tensor(0.8476, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00038429402756229476
now it is 1700 steps  and the cls_loss is : tensor(0.8879, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003862923857191132
now it is 1720 steps  and the cls_loss is : tensor(0.8186, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00038831337310601174
now it is 1740 steps  and the cls_loss is : tensor(0.8530, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003903569535331406
now it is 1760 steps  and the cls_loss is : tensor(0.8431, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00039242309040607697
now it is 1780 steps  and the cls_loss is : tensor(0.8796, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00039451174672647943
now it is 1800 steps  and the cls_loss is : tensor(0.7087, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003966228850927501
now it is 1820 steps  and the cls_loss is : tensor(0.8694, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003987564677007038
now it is 1840 steps  and the cls_loss is : tensor(0.7282, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004009124563442482
now it is 1860 steps  and the cls_loss is : tensor(0.6898, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00040309081241606546
now it is 1880 steps  and the cls_loss is : tensor(0.7592, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004052914969083013
now it is 1900 steps  and the cls_loss is : tensor(0.7192, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00040751447041326855
now it is 1920 steps  and the cls_loss is : tensor(0.7550, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004097596931241501
now it is 1940 steps  and the cls_loss is : tensor(0.8140, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00041202712483571135
now it is 1960 steps  and the cls_loss is : tensor(0.7060, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004143167249450216
now it is 1980 steps  and the cls_loss is : tensor(0.5844, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004166284524521795
now it is 2000 steps  and the cls_loss is : tensor(0.6036, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004189622659610476
now it is 2020 steps  and the cls_loss is : tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004213181236799963
now it is 2040 steps  and the cls_loss is : tensor(0.6596, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000423695983422648
now it is 2060 steps  and the cls_loss is : tensor(0.6071, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004260958026086354
now it is 2080 steps  and the cls_loss is : tensor(0.6328, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000428517538264363
now it is 2100 steps  and the cls_loss is : tensor(0.5407, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00043096114702377607
now it is 2120 steps  and the cls_loss is : tensor(0.5426, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00043342658512913936
now it is 2140 steps  and the cls_loss is : tensor(0.4982, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00043591380843181846
now it is 2160 steps  and the cls_loss is : tensor(0.4997, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004384227723930709
now it is 2180 steps  and the cls_loss is : tensor(0.4299, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004409534320848436
now it is 2200 steps  and the cls_loss is : tensor(0.4352, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00044350574219057925
now it is 2220 steps  and the cls_loss is : tensor(0.4405, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00044607965700602407
now it is 2240 steps  and the cls_loss is : tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00044867513044005106
now it is 2260 steps  and the cls_loss is : tensor(0.4018, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00045129211601548005
now it is 2280 steps  and the cls_loss is : tensor(0.3552, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004539305668699151
now it is 2300 steps  and the cls_loss is : tensor(0.3762, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00045659043575657903
now it is 2320 steps  and the cls_loss is : tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00045927167504516324
now it is 2340 steps  and the cls_loss is : tensor(0.2346, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004619742367226792
now it is 2360 steps  and the cls_loss is : tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004646980723943153
now it is 2380 steps  and the cls_loss is : tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00046744313328431035
now it is 2400 steps  and the cls_loss is : tensor(0.2005, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047020937023682
now it is 2420 steps  and the cls_loss is : tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004729967337168011
now it is 2440 steps  and the cls_loss is : tensor(0.3121, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047580517381089595
now it is 2460 steps  and the cls_loss is : tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047863464022833034
now it is 2480 steps  and the cls_loss is : tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000481485082301808
now it is 2500 steps  and the cls_loss is : tensor(0.2456, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00048435644898842415
now it is 2520 steps  and the cls_loss is : tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004872486888705756
now it is 2540 steps  and the cls_loss is : tensor(0.2464, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004901617501568826
now it is 2560 steps  and the cls_loss is : tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000493095580683116
now it is 2580 steps  and the cls_loss is : tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004960501279131315
now it is 2600 steps  and the cls_loss is : tensor(0.1879, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004990253389398113
now it is 2620 steps  and the cls_loss is : tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005020211604860095
now it is 2640 steps  and the cls_loss is : tensor(0.1771, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005050375389055086
now it is 2660 steps  and the cls_loss is : tensor(0.2060, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005080744201839782
now it is 2680 steps  and the cls_loss is : tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005111317499399423
now it is 2700 steps  and the cls_loss is : tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005142094734257559
now it is 2720 steps  and the cls_loss is : tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005173075355285801
now it is 2740 steps  and the cls_loss is : tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005204258807713752
now it is 2760 steps  and the cls_loss is : tensor(0.1961, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005235644533138884
now it is 2780 steps  and the cls_loss is : tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000526723196953658
now it is 2800 steps  and the cls_loss is : tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005299020551270185
now it is 2820 steps  and the cls_loss is : tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005331009709101104
now it is 2840 steps  and the cls_loss is : tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005363198870199067
now it is 2860 steps  and the cls_loss is : tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005395587458152302
now it is 2880 steps  and the cls_loss is : tensor(0.0920, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005428174892977916
now it is 2900 steps  and the cls_loss is : tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005460960591132263
now it is 2920 steps  and the cls_loss is : tensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005493943965521396
now it is 2940 steps  and the cls_loss is : tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005527124425511562
now it is 2960 steps  and the cls_loss is : tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005560501376939806
now it is 2980 steps  and the cls_loss is : tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000559407422212459
now it is 3000 steps  and the cls_loss is : tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005627842359876515
now it is 3020 steps  and the cls_loss is : tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005661805185509074
now it is 3040 steps  and the cls_loss is : tensor(0.2439, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005695962090849463
now it is 3060 steps  and the cls_loss is : tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005730312464249511
now it is 3080 steps  and the cls_loss is : tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005764855690596599
now it is 3100 steps  and the cls_loss is : tensor(0.2058, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005799591151324696
now it is 3120 steps  and the cls_loss is : tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005834518224425425
now it is 3140 steps  and the cls_loss is : tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005869636284459197
now it is 3160 steps  and the cls_loss is : tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005904944702566427
now it is 3180 steps  and the cls_loss is : tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005940442846478779
now it is 3200 steps  and the cls_loss is : tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005976130080530494
now it is 3220 steps  and the cls_loss is : tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006012005765669783
now it is 3240 steps  and the cls_loss is : tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006048069259470246
now it is 3260 steps  and the cls_loss is : tensor(0.5224, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006084319916142399
now it is 3280 steps  and the cls_loss is : tensor(0.3761, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006120757086545236
now it is 3300 steps  and the cls_loss is : tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006157380118197828
now it is 3320 steps  and the cls_loss is : tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006194188355291047
now it is 3340 steps  and the cls_loss is : tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000623118113869928
now it is 3360 steps  and the cls_loss is : tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006268357805992233
now it is 3380 steps  and the cls_loss is : tensor(0.1441, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000630571769144681
now it is 3400 steps  and the cls_loss is : tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006343260126059026
now it is 3420 steps  and the cls_loss is : tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006380984437555984
now it is 3440 steps  and the cls_loss is : tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006418889950407904
now it is 3460 steps  and the cls_loss is : tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006456975985840254
now it is 3480 steps  and the cls_loss is : tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006495241861845854
now it is 3500 steps  and the cls_loss is : tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006533686893197138
now it is 3520 steps  and the cls_loss is : tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006572310391458388
now it is 3540 steps  and the cls_loss is : tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006611111664998094
now it is 3560 steps  and the cls_loss is : tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006650090019001305
now it is 3580 steps  and the cls_loss is : tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006689244755482093
now it is 3600 steps  and the cls_loss is : tensor(0.0630, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006728575173296052
now it is 3620 steps  and the cls_loss is : tensor(0.5026, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006768080568152835
now it is 3640 steps  and the cls_loss is : tensor(0.1540, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006807760232628796
now it is 3660 steps  and the cls_loss is : tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006847613456179625
now it is 3680 steps  and the cls_loss is : tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006887639525153099
now it is 3700 steps  and the cls_loss is : tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000692783772280184
now it is 3720 steps  and the cls_loss is : tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006968207329296166
now it is 3740 steps  and the cls_loss is : tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007008747621736968
now it is 3760 steps  and the cls_loss is : tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007049457874168672
now it is 3780 steps  and the cls_loss is : tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007090337357592213
now it is 3800 steps  and the cls_loss is : tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007131385339978124
now it is 3820 steps  and the cls_loss is : tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007172601086279603
now it is 3840 steps  and the cls_loss is : tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007213983858445714
now it is 3860 steps  and the cls_loss is : tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007255532915434581
now it is 3880 steps  and the cls_loss is : tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007297247513226657
now it is 3900 steps  and the cls_loss is : tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007339126904838062
now it is 3920 steps  and the cls_loss is : tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007381170340333954
now it is 3940 steps  and the cls_loss is : tensor(0.3076, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007423377066841938
now it is 3960 steps  and the cls_loss is : tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007465746328565587
now it is 3980 steps  and the cls_loss is : tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007508277366797926
now it is 4000 steps  and the cls_loss is : tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007550969419935082
now it is 4020 steps  and the cls_loss is : tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007593821723489848
now it is 4040 steps  and the cls_loss is : tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007636833510105442
now it is 4060 steps  and the cls_loss is : tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007680004009569192
now it is 4080 steps  and the cls_loss is : tensor(0.1594, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007723332448826372
now it is 4100 steps  and the cls_loss is : tensor(0.1744, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007766818051994011
now it is 4120 steps  and the cls_loss is : tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007810460040374814
now it is 4140 steps  and the cls_loss is : tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007854257632471085
now it is 4160 steps  and the cls_loss is : tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007898210043998737
now it is 4180 steps  and the cls_loss is : tensor(0.1476, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007942316487901321
now it is 4200 steps  and the cls_loss is : tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007986576174364136
now it is 4220 steps  and the cls_loss is : tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008030988310828353
now it is 4240 steps  and the cls_loss is : tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008075552102005238
now it is 4260 steps  and the cls_loss is : tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008120266749890356
now it is 4280 steps  and the cls_loss is : tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008165131453777888
now it is 4300 steps  and the cls_loss is : tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008210145410274955
now it is 4320 steps  and the cls_loss is : tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008255307813316015
now it is 4340 steps  and the cls_loss is : tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008300617854177282
now it is 4360 steps  and the cls_loss is : tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008346074721491238
now it is 4380 steps  and the cls_loss is : tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008391677601261114
now it is 4400 steps  and the cls_loss is : tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008437425676875517
now it is 4420 steps  and the cls_loss is : tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008483318129123016
now it is 4440 steps  and the cls_loss is : tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008529354136206828
now it is 4460 steps  and the cls_loss is : tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008575532873759538
now it is 4480 steps  and the cls_loss is : tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008621853514857855
now it is 4500 steps  and the cls_loss is : tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008668315230037403
now it is 4520 steps  and the cls_loss is : tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000871491718730761
now it is 4540 steps  and the cls_loss is : tensor(0.2276, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008761658552166578
now it is 4560 steps  and the cls_loss is : tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008808538487616036
now it is 4580 steps  and the cls_loss is : tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008855556154176332
now it is 4600 steps  and the cls_loss is : tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008902710709901445
now it is 4620 steps  and the cls_loss is : tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008950001310394106
now it is 4640 steps  and the cls_loss is : tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008997427108820861
now it is 4660 steps  and the cls_loss is : tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009044987255927288
now it is 4680 steps  and the cls_loss is : tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009092680900053161
now it is 4700 steps  and the cls_loss is : tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009140507187147739
now it is 4720 steps  and the cls_loss is : tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009188465260785029
now it is 4740 steps  and the cls_loss is : tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009236554262179149
now it is 4760 steps  and the cls_loss is : tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009284773330199671
now it is 4780 steps  and the cls_loss is : tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009333121601387078
now it is 4800 steps  and the cls_loss is : tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009381598209968205
now it is 4820 steps  and the cls_loss is : tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009430202287871755
now it is 4840 steps  and the cls_loss is : tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009478932964743811
now it is 4860 steps  and the cls_loss is : tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009527789367963489
now it is 4880 steps  and the cls_loss is : tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009576770622658475
now it is 4900 steps  and the cls_loss is : tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000962587585172077
now it is 4920 steps  and the cls_loss is : tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009675104175822353
now it is 4940 steps  and the cls_loss is : tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009724454713430949
now it is 4960 steps  and the cls_loss is : tensor(0.1736, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009773926580825777
now it is 4980 steps  and the cls_loss is : tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009823518892113424
now it is 5000 steps  and the cls_loss is : tensor(0.1990, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009873230759243697
now it is 5020 steps  and the cls_loss is : tensor(0.1702, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009923061292025485
now it is 5040 steps  and the cls_loss is : tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000997300959814275
now it is 5060 steps  and the cls_loss is : tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010023074783170479
now it is 5080 steps  and the cls_loss is : tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010073255950590705
now it is 5100 steps  and the cls_loss is : tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001012355220180857
now it is 5120 steps  and the cls_loss is : tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00101739626361684
now it is 5140 steps  and the cls_loss is : tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010224486350969846
now it is 5160 steps  and the cls_loss is : tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010275122441484046
now it is 5180 steps  and the cls_loss is : tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010325870000969825
now it is 5200 steps  and the cls_loss is : tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010376728120689927
now it is 5220 steps  and the cls_loss is : tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010427695889927294
now it is 5240 steps  and the cls_loss is : tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010478772396001373
now it is 5260 steps  and the cls_loss is : tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010529956724284464
now it is 5280 steps  and the cls_loss is : tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010581247958218083
now it is 5300 steps  and the cls_loss is : tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010632645179329393
now it is 5320 steps  and the cls_loss is : tensor(0.1172, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010684147467247642
now it is 5340 steps  and the cls_loss is : tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010735753899720644
now it is 5360 steps  and the cls_loss is : tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010787463552631295
now it is 5380 steps  and the cls_loss is : tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010839275500014118
now it is 5400 steps  and the cls_loss is : tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010891188814071855
now it is 5420 steps  and the cls_loss is : tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001094320256519206
now it is 5440 steps  and the cls_loss is : tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010995315821963785
now it is 5460 steps  and the cls_loss is : tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011047527651194204
now it is 5480 steps  and the cls_loss is : tensor(0.1989, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011099837117925365
now it is 5500 steps  and the cls_loss is : tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011152243285450926
now it is 5520 steps  and the cls_loss is : tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001120474521533291
now it is 5540 steps  and the cls_loss is : tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011257341967418533
now it is 5560 steps  and the cls_loss is : tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011310032599857018
now it is 5580 steps  and the cls_loss is : tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011362816169116488
now it is 5600 steps  and the cls_loss is : tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011415691730000822
now it is 5620 steps  and the cls_loss is : tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011468658335666625
now it is 5640 steps  and the cls_loss is : tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011521715037640149
now it is 5660 steps  and the cls_loss is : tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011574860885834295
now it is 5680 steps  and the cls_loss is : tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011628094928565614
now it is 5700 steps  and the cls_loss is : tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011681416212571375
now it is 5720 steps  and the cls_loss is : tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011734823783026594
now it is 5740 steps  and the cls_loss is : tensor(0.2096, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011788316683561163
now it is 5760 steps  and the cls_loss is : tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011841893956276975
now it is 5780 steps  and the cls_loss is : tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011895554641765064
now it is 5800 steps  and the cls_loss is : tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011949297779122777
now it is 5820 steps  and the cls_loss is : tensor(0.4186, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012003122405971015
now it is 5840 steps  and the cls_loss is : tensor(0.1571, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012057027558471437
now it is 5860 steps  and the cls_loss is : tensor(0.1659, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012111012271343723
now it is 5880 steps  and the cls_loss is : tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001216507557788287
now it is 5900 steps  and the cls_loss is : tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00122192165099765
now it is 5920 steps  and the cls_loss is : tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012273434098122185
now it is 5940 steps  and the cls_loss is : tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012327727371444824
now it is 5960 steps  and the cls_loss is : tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012382095357714009
now it is 5980 steps  and the cls_loss is : tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012436537083361464
now it is 6000 steps  and the cls_loss is : tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012491051573498436
now it is 6020 steps  and the cls_loss is : tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001254563785193321
now it is 6040 steps  and the cls_loss is : tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012600294941188526
now it is 6060 steps  and the cls_loss is : tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012655021862519131
now it is 6080 steps  and the cls_loss is : tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012709817635929285
now it is 6100 steps  and the cls_loss is : tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012764681280190307
now it is 6120 steps  and the cls_loss is : tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012819611812858163
now it is 6140 steps  and the cls_loss is : tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012874608250291032
now it is 6160 steps  and the cls_loss is : tensor(0.3162, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012929669607666954
now it is 6180 steps  and the cls_loss is : tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012984794899001428
now it is 6200 steps  and the cls_loss is : tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013039983137165102
now it is 6220 steps  and the cls_loss is : tensor(0.2290, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001309523333390142
now it is 6240 steps  and the cls_loss is : tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001315054449984435
now it is 6260 steps  and the cls_loss is : tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013205915644536068
now it is 6280 steps  and the cls_loss is : tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001326134577644472
now it is 6300 steps  and the cls_loss is : tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013316833902982158
now it is 6320 steps  and the cls_loss is : tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013372379030521732
now it is 6340 steps  and the cls_loss is : tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013427980164416068
now it is 6360 steps  and the cls_loss is : tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001348363630901489
now it is 6380 steps  and the cls_loss is : tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013539346467682848
now it is 6400 steps  and the cls_loss is : tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013595109642817347
now it is 6420 steps  and the cls_loss is : tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013650924835866436
now it is 6440 steps  and the cls_loss is : tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013706791047346683
now it is 6460 steps  and the cls_loss is : tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013762707276861054
now it is 6480 steps  and the cls_loss is : tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013818672523116856
now it is 6500 steps  and the cls_loss is : tensor(0.1774, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013874685783943645
now it is 6520 steps  and the cls_loss is : tensor(0.3420, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013930746056311175
now it is 6540 steps  and the cls_loss is : tensor(0.2321, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013986852336347372
now it is 6560 steps  and the cls_loss is : tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014043003619356304
now it is 6580 steps  and the cls_loss is : tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001409919889983616
now it is 6600 steps  and the cls_loss is : tensor(0.2156, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014155437171497274
now it is 6620 steps  and the cls_loss is : tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014211717427280127
now it is 6640 steps  and the cls_loss is : tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014268038659373409
now it is 6660 steps  and the cls_loss is : tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014324399859232016
now it is 6680 steps  and the cls_loss is : tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014380800017595172
now it is 6700 steps  and the cls_loss is : tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014437238124504453
now it is 6720 steps  and the cls_loss is : tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014493713169321891
now it is 6740 steps  and the cls_loss is : tensor(0.7097, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014550224140748075
now it is 6760 steps  and the cls_loss is : tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014606770026840256
now it is 6780 steps  and the cls_loss is : tensor(0.2078, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014663349815030463
now it is 6800 steps  and the cls_loss is : tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014719962492143641
now it is 6820 steps  and the cls_loss is : tensor(0.2204, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014776607044415797
now it is 6840 steps  and the cls_loss is : tensor(0.1181, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014833282457512142
now it is 6860 steps  and the cls_loss is : tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014889987716545268
now it is 6880 steps  and the cls_loss is : tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014946721806093314
now it is 6900 steps  and the cls_loss is : tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015003483710218147
now it is 6920 steps  and the cls_loss is : tensor(0.1573, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015060272412483558
now it is 6940 steps  and the cls_loss is : tensor(0.0856, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001511708689597347
now it is 6960 steps  and the cls_loss is : tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001517392614331014
now it is 6980 steps  and the cls_loss is : tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001523078913667237
now it is 7000 steps  and the cls_loss is : tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015287674857813742
now it is 7020 steps  and the cls_loss is : tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015344582288080869
now it is 7040 steps  and the cls_loss is : tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00154015104084316
now it is 7060 steps  and the cls_loss is : tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015458458199453294
now it is 7080 steps  and the cls_loss is : tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001551542464138106
now it is 7100 steps  and the cls_loss is : tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015572408714116033
now it is 7120 steps  and the cls_loss is : tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015629409397243626
now it is 7140 steps  and the cls_loss is : tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015686425670051827
now it is 7160 steps  and the cls_loss is : tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015743456511549431
now it is 7180 steps  and the cls_loss is : tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015800500900484374
now it is 7200 steps  and the cls_loss is : tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015857557815361987
now it is 7220 steps  and the cls_loss is : tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015914626234463307
now it is 7240 steps  and the cls_loss is : tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015971705135863347
now it is 7260 steps  and the cls_loss is : tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016028793497449444
now it is 7280 steps  and the cls_loss is : tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016085890296939497
now it is 7300 steps  and the cls_loss is : tensor(0.4548, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016142994511900328
now it is 7320 steps  and the cls_loss is : tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016200105119765975
now it is 7340 steps  and the cls_loss is : tensor(0.2187, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016257221097855975
now it is 7360 steps  and the cls_loss is : tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016314341423393722
now it is 7380 steps  and the cls_loss is : tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001637146507352475
now it is 7400 steps  and the cls_loss is : tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016428591025335066
now it is 7420 steps  and the cls_loss is : tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016485718255869447
now it is 7440 steps  and the cls_loss is : tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016542845742149792
now it is 7460 steps  and the cls_loss is : tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00165999724611934
now it is 7480 steps  and the cls_loss is : tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016657097390031328
now it is 7500 steps  and the cls_loss is : tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016714219505726679
now it is 7520 steps  and the cls_loss is : tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016771337785392922
now it is 7540 steps  and the cls_loss is : tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001682845120621224
now it is 7560 steps  and the cls_loss is : tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016885558745453808
now it is 7580 steps  and the cls_loss is : tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001694265938049213
now it is 7600 steps  and the cls_loss is : tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016999752088825337
now it is 7620 steps  and the cls_loss is : tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017056835848093508
now it is 7640 steps  and the cls_loss is : tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017113909636096967
now it is 7660 steps  and the cls_loss is : tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017170972430814613
now it is 7680 steps  and the cls_loss is : tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017228023210422172
now it is 7700 steps  and the cls_loss is : tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017285060953310543
now it is 7720 steps  and the cls_loss is : tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017342084638104075
now it is 7740 steps  and the cls_loss is : tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017399093243678854
now it is 7760 steps  and the cls_loss is : tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017456085749180982
now it is 7780 steps  and the cls_loss is : tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017513061134044868
now it is 7800 steps  and the cls_loss is : tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001757001837801151
now it is 7820 steps  and the cls_loss is : tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017626956461146747
now it is 7840 steps  and the cls_loss is : tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017683874363859525
now it is 7860 steps  and the cls_loss is : tensor(0.2913, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017740771066920174
now it is 7880 steps  and the cls_loss is : tensor(0.2226, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017797645551478642
now it is 7900 steps  and the cls_loss is : tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001785449679908274
now it is 7920 steps  and the cls_loss is : tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017911323791696394
now it is 7940 steps  and the cls_loss is : tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001796812551171785
now it is 7960 steps  and the cls_loss is : tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018024900941997915
now it is 7980 steps  and the cls_loss is : tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018081649065858172
now it is 8000 steps  and the cls_loss is : tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018138368867109188
now it is 8020 steps  and the cls_loss is : tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001819505933006868
now it is 8040 steps  and the cls_loss is : tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001825171943957974
now it is 8060 steps  and the cls_loss is : tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001830834818102901
now it is 8080 steps  and the cls_loss is : tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018364944540364822
now it is 8100 steps  and the cls_loss is : tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018421507504115377
now it is 8120 steps  and the cls_loss is : tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00184780360594069
now it is 8140 steps  and the cls_loss is : tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018534529193981774
now it is 8160 steps  and the cls_loss is : tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018590985896216646
now it is 8180 steps  and the cls_loss is : tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001864740515514056
now it is 8200 steps  and the cls_loss is : tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001870378596045307
now it is 8220 steps  and the cls_loss is : tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018760127302542302
now it is 8240 steps  and the cls_loss is : tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001881642817250307
now it is 8260 steps  and the cls_loss is : tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00188726875621549
now it is 8280 steps  and the cls_loss is : tensor(0.1700, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018928904464060132
now it is 8300 steps  and the cls_loss is : tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018985077871541912
now it is 8320 steps  and the cls_loss is : tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019041206778702263
now it is 8340 steps  and the cls_loss is : tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001909729018044005
now it is 8360 steps  and the cls_loss is : tensor(0.4966, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019153327072469026
now it is 8380 steps  and the cls_loss is : tensor(0.3469, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001920931645133578
now it is 8400 steps  and the cls_loss is : tensor(0.2196, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019265257314437737
now it is 8420 steps  and the cls_loss is : tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019321148660041076
now it is 8440 steps  and the cls_loss is : tensor(0.2507, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001937698948729869
now it is 8460 steps  and the cls_loss is : tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019432778796268117
now it is 8480 steps  and the cls_loss is : tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019488515587929417
now it is 8500 steps  and the cls_loss is : tensor(0.1057, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00195441988642031
now it is 8520 steps  and the cls_loss is : tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019599827627967948
now it is 8540 steps  and the cls_loss is : tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019655400883078922
now it is 8560 steps  and the cls_loss is : tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019710917634384972
now it is 8580 steps  and the cls_loss is : tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019766376887746864
now it is 8600 steps  and the cls_loss is : tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019821777650054963
now it is 8620 steps  and the cls_loss is : tensor(0.1843, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019877118929247056
now it is 8640 steps  and the cls_loss is : tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019932399734326088
now it is 8660 steps  and the cls_loss is : tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019987619075377914
now it is 8680 steps  and the cls_loss is : tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002004277596358902
now it is 8700 steps  and the cls_loss is : tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020097869411264246
now it is 8720 steps  and the cls_loss is : tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002015289843184446
now it is 8740 steps  and the cls_loss is : tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002020786203992422
now it is 8760 steps  and the cls_loss is : tensor(0.1844, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002026275925126944
now it is 8780 steps  and the cls_loss is : tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020317589082834986
now it is 8800 steps  and the cls_loss is : tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00203723505527823
now it is 8820 steps  and the cls_loss is : tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002042704268049699
now it is 8840 steps  and the cls_loss is : tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020481664486606344
now it is 8860 steps  and the cls_loss is : tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020536214992996943
now it is 8880 steps  and the cls_loss is : tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020590693222832094
now it is 8900 steps  and the cls_loss is : tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002064509820056939
now it is 8920 steps  and the cls_loss is : tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020699428951978125
now it is 8940 steps  and the cls_loss is : tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002075368450415679
now it is 8960 steps  and the cls_loss is : tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020807863885550443
now it is 8980 steps  and the cls_loss is : tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002086196612596817
now it is 9000 steps  and the cls_loss is : tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002091599025660038
now it is 9020 steps  and the cls_loss is : tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020969935310036223
now it is 9040 steps  and the cls_loss is : tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002102380032028087
now it is 9060 steps  and the cls_loss is : tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021077584322772842
now it is 9080 steps  and the cls_loss is : tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021131286354401256
now it is 9100 steps  and the cls_loss is : tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021184905453523082
now it is 9120 steps  and the cls_loss is : tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002123844065998037
now it is 9140 steps  and the cls_loss is : tensor(0.1297, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002129189101511743
now it is 9160 steps  and the cls_loss is : tensor(0.0626, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021345255561798014
now it is 9180 steps  and the cls_loss is : tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021398533344422436
now it is 9200 steps  and the cls_loss is : tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021451723408944705
now it is 9220 steps  and the cls_loss is : tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002150482480288959
now it is 9240 steps  and the cls_loss is : tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002155783657536971
now it is 9260 steps  and the cls_loss is : tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00216107577771025
now it is 9280 steps  and the cls_loss is : tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002166358746042727
now it is 9300 steps  and the cls_loss is : tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021716324679322144
now it is 9320 steps  and the cls_loss is : tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021768968489421013
now it is 9340 steps  and the cls_loss is : tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002182151794803043
now it is 9360 steps  and the cls_loss is : tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021873972114146516
now it is 9380 steps  and the cls_loss is : tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021926330048471793
now it is 9400 steps  and the cls_loss is : tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021978590813432
now it is 9420 steps  and the cls_loss is : tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002203075347319288
now it is 9440 steps  and the cls_loss is : tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022082817093676973
now it is 9460 steps  and the cls_loss is : tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00221347807425803
now it is 9480 steps  and the cls_loss is : tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022186643489389077
now it is 9500 steps  and the cls_loss is : tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022238404405396373
now it is 9520 steps  and the cls_loss is : tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002229006256371874
now it is 9540 steps  and the cls_loss is : tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002234161703931284
now it is 9560 steps  and the cls_loss is : tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022393066908991946
now it is 9580 steps  and the cls_loss is : tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022444411251442515
now it is 9600 steps  and the cls_loss is : tensor(0.1842, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002249564914724071
now it is 9620 steps  and the cls_loss is : tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002254677967886882
now it is 9640 steps  and the cls_loss is : tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002259780193073169
now it is 9660 steps  and the cls_loss is : tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002264871498917316
now it is 9680 steps  and the cls_loss is : tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022699517942492376
now it is 9700 steps  and the cls_loss is : tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022750209880960143
now it is 9720 steps  and the cls_loss is : tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022800789896835227
now it is 9740 steps  and the cls_loss is : tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022851257084380576
now it is 9760 steps  and the cls_loss is : tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002290161053987955
now it is 9780 steps  and the cls_loss is : tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022951849361652127
now it is 9800 steps  and the cls_loss is : tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023001972650071034
now it is 9820 steps  and the cls_loss is : tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023051979507577843
now it is 9840 steps  and the cls_loss is : tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023101869038699065
now it is 9860 steps  and the cls_loss is : tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023151640350062164
now it is 9880 steps  and the cls_loss is : tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023201292550411572
now it is 9900 steps  and the cls_loss is : tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002325082475062467
now it is 9920 steps  and the cls_loss is : tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023300236063727633
now it is 9940 steps  and the cls_loss is : tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002334952560491141
now it is 9960 steps  and the cls_loss is : tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023398692491547485
now it is 9980 steps  and the cls_loss is : tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002344773584320375
now it is 10000 steps  and the cls_loss is : tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023496654781660214
now it is 10020 steps  and the cls_loss is : tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023545448430924774
now it is 10040 steps  and the cls_loss is : tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023594115917248866
now it is 10060 steps  and the cls_loss is : tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023642656369143146
now it is 10080 steps  and the cls_loss is : tensor(0.2859, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002369106891739306
now it is 10100 steps  and the cls_loss is : tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023739352695074426
now it is 10120 steps  and the cls_loss is : tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002378750683756898
now it is 10140 steps  and the cls_loss is : tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002383553048257982
now it is 10160 steps  and the cls_loss is : tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023883422770146854
now it is 10180 steps  and the cls_loss is : tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023931182842662235
now it is 10200 steps  and the cls_loss is : tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023978809844885677
now it is 10220 steps  and the cls_loss is : tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024026302923959787
now it is 10240 steps  and the cls_loss is : tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002407366122942535
now it is 10260 steps  and the cls_loss is : tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002412088391323651
now it is 10280 steps  and the cls_loss is : tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002416797012977602
now it is 10300 steps  and the cls_loss is : tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024214919035870355
now it is 10320 steps  and the cls_loss is : tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002426172979080479
now it is 10340 steps  and the cls_loss is : tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024308401556338488
now it is 10360 steps  and the cls_loss is : tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024354933496719498
now it is 10380 steps  and the cls_loss is : tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024401324778699713
now it is 10400 steps  and the cls_loss is : tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00244475745715498
now it is 10420 steps  and the cls_loss is : tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024493682047074085
now it is 10440 steps  and the cls_loss is : tensor(0.4602, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024539646379625342
now it is 10460 steps  and the cls_loss is : tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002458546674611965
now it is 10480 steps  and the cls_loss is : tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024631142326051064
now it is 10500 steps  and the cls_loss is : tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024676672301506327
now it is 10520 steps  and the cls_loss is : tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002472205585717955
now it is 10540 steps  and the cls_loss is : tensor(0.3003, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002476729218038676
now it is 10560 steps  and the cls_loss is : tensor(0.1939, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00248123804610805
now it is 10580 steps  and the cls_loss is : tensor(0.2114, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024857319891864287
now it is 10600 steps  and the cls_loss is : tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024902109668007116
now it is 10620 steps  and the cls_loss is : tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002494674898745784
now it is 10640 steps  and the cls_loss is : tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024991237050859556
now it is 10660 steps  and the cls_loss is : tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002503557306156388
now it is 10680 steps  and the cls_loss is : tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002507975622564525
now it is 10700 steps  and the cls_loss is : tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025123785751915142
now it is 10720 steps  and the cls_loss is : tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002516766085193622
now it is 10740 steps  and the cls_loss is : tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025211380740036444
now it is 10760 steps  and the cls_loss is : tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025254944633323183
now it is 10780 steps  and the cls_loss is : tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025298351751697184
now it is 10800 steps  and the cls_loss is : tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025341601317866577
now it is 10820 steps  and the cls_loss is : tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025384692557360792
now it is 10840 steps  and the cls_loss is : tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002542762469854438
now it is 10860 steps  and the cls_loss is : tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002547039697263091
now it is 10880 steps  and the cls_loss is : tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025513008613696677
now it is 10900 steps  and the cls_loss is : tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002555545885869442
now it is 10920 steps  and the cls_loss is : tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002559774694746701
now it is 10940 steps  and the cls_loss is : tensor(0.1618, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025639872122761066
now it is 10960 steps  and the cls_loss is : tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025681833630240482
now it is 10980 steps  and the cls_loss is : tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025723630718499963
now it is 11000 steps  and the cls_loss is : tensor(0.1906, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002576526263907846
now it is 11020 steps  and the cls_loss is : tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002580672864647259
now it is 11040 steps  and the cls_loss is : tensor(0.3818, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025848027998150004
now it is 11060 steps  and the cls_loss is : tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002588915995456262
now it is 11080 steps  and the cls_loss is : tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025930123779159915
now it is 11100 steps  and the cls_loss is : tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002597091873840213
now it is 11120 steps  and the cls_loss is : tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026011544101773353
now it is 11140 steps  and the cls_loss is : tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002605199914179464
now it is 11160 steps  and the cls_loss is : tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026092283134037026
now it is 11180 steps  and the cls_loss is : tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00261323953571345
now it is 11200 steps  and the cls_loss is : tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026172335092796923
now it is 11220 steps  and the cls_loss is : tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026212101625822906
now it is 11240 steps  and the cls_loss is : tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002625169424411257
now it is 11260 steps  and the cls_loss is : tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002629111223868036
now it is 11280 steps  and the cls_loss is : tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026330354903667703
now it is 11300 steps  and the cls_loss is : tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002636942153635564
now it is 11320 steps  and the cls_loss is : tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002640831143717745
now it is 11340 steps  and the cls_loss is : tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002644702390973112
now it is 11360 steps  and the cls_loss is : tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002648555826079188
now it is 11380 steps  and the cls_loss is : tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026523913800324565
now it is 11400 steps  and the cls_loss is : tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026562089841495997
now it is 11420 steps  and the cls_loss is : tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002660008570068727
now it is 11440 steps  and the cls_loss is : tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026637900697506016
now it is 11460 steps  and the cls_loss is : tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002667553415479855
now it is 11480 steps  and the cls_loss is : tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026712985398662037
now it is 11500 steps  and the cls_loss is : tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026750253758456525
now it is 11520 steps  and the cls_loss is : tensor(0.0630, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026787338566816982
now it is 11540 steps  and the cls_loss is : tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026824239159665224
now it is 11560 steps  and the cls_loss is : tensor(0.1784, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026860954876221834
now it is 11580 steps  and the cls_loss is : tensor(0.1570, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026897485059017953
now it is 11600 steps  and the cls_loss is : tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002693382905390709
now it is 11620 steps  and the cls_loss is : tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026969986210076827
now it is 11640 steps  and the cls_loss is : tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027005955880060467
now it is 11660 steps  and the cls_loss is : tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027041737419748624
now it is 11680 steps  and the cls_loss is : tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027077330188400774
now it is 11700 steps  and the cls_loss is : tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002711273354865671
now it is 11720 steps  and the cls_loss is : tensor(0.0839, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027147946866547972
now it is 11740 steps  and the cls_loss is : tensor(0.9883, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027182969511509187
now it is 11760 steps  and the cls_loss is : tensor(0.2837, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027217800856389356
now it is 11780 steps  and the cls_loss is : tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002725244027746311
now it is 11800 steps  and the cls_loss is : tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027286887154441856
now it is 11820 steps  and the cls_loss is : tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027321140870484877
now it is 11840 steps  and the cls_loss is : tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027355200812210416
now it is 11860 steps  and the cls_loss is : tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027389066369706617
now it is 11880 steps  and the cls_loss is : tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027422736936542473
now it is 11900 steps  and the cls_loss is : tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027456211909778674
now it is 11920 steps  and the cls_loss is : tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002748949068997841
now it is 11940 steps  and the cls_loss is : tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027522572681218096
now it is 11960 steps  and the cls_loss is : tensor(0.3562, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027555457291098067
now it is 11980 steps  and the cls_loss is : tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027588143930753145
now it is 12000 steps  and the cls_loss is : tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027620632014863223
now it is 12020 steps  and the cls_loss is : tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002765292096166373
now it is 12040 steps  and the cls_loss is : tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027685010192956038
now it is 12060 steps  and the cls_loss is : tensor(0.3217, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027716899134117845
now it is 12080 steps  and the cls_loss is : tensor(0.1940, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027748587214113437
now it is 12100 steps  and the cls_loss is : tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002778007386550392
now it is 12120 steps  and the cls_loss is : tensor(0.1632, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027811358524457387
now it is 12140 steps  and the cls_loss is : tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002784244063075903
now it is 12160 steps  and the cls_loss is : tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027873319627821124
now it is 12180 steps  and the cls_loss is : tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002790399496269304
now it is 12200 steps  and the cls_loss is : tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002793446608607114
now it is 12220 steps  and the cls_loss is : tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027964732452308593
now it is 12240 steps  and the cls_loss is : tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027994793519425147
now it is 12260 steps  and the cls_loss is : tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028024648749116867
now it is 12280 steps  and the cls_loss is : tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002805429760676573
now it is 12300 steps  and the cls_loss is : tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028083739561449235
now it is 12320 steps  and the cls_loss is : tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028112974085949885
now it is 12340 steps  and the cls_loss is : tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002814200065676465
now it is 12360 steps  and the cls_loss is : tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002817081875411432
now it is 12380 steps  and the cls_loss is : tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028199427861952827
now it is 12400 steps  and the cls_loss is : tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028227827467976474
now it is 12420 steps  and the cls_loss is : tensor(0.2981, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028256017063633125
now it is 12440 steps  and the cls_loss is : tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00282839961441313
now it is 12460 steps  and the cls_loss is : tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002831176420844921
now it is 12480 steps  and the cls_loss is : tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028339320759343746
now it is 12500 steps  and the cls_loss is : tensor(0.2946, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028366665303359365
now it is 12520 steps  and the cls_loss is : tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028393797350836935
now it is 12540 steps  and the cls_loss is : tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002842071641592251
now it is 12560 steps  and the cls_loss is : tensor(0.1689, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028447422016576016
now it is 12580 steps  and the cls_loss is : tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028473913674579884
now it is 12600 steps  and the cls_loss is : tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002850019091554764
now it is 12620 steps  and the cls_loss is : tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002852625326893235
now it is 12640 steps  and the cls_loss is : tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028552100268035095
now it is 12660 steps  and the cls_loss is : tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028577731450013305
now it is 12680 steps  and the cls_loss is : tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028603146355889045
now it is 12700 steps  and the cls_loss is : tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002862834453055724
now it is 12720 steps  and the cls_loss is : tensor(0.1104, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002865332552279383
now it is 12740 steps  and the cls_loss is : tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002867808888526384
now it is 12760 steps  and the cls_loss is : tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028702634174529386
now it is 12780 steps  and the cls_loss is : tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002872696095105764
now it is 12800 steps  and the cls_loss is : tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028751068779228678
now it is 12820 steps  and the cls_loss is : tensor(0.1587, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002877495722734328
now it is 12840 steps  and the cls_loss is : tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028798625867630678
now it is 12860 steps  and the cls_loss is : tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028822074276256193
now it is 12880 steps  and the cls_loss is : tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028845302033328854
now it is 12900 steps  and the cls_loss is : tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028868308722908888
now it is 12920 steps  and the cls_loss is : tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028891093933015185
now it is 12940 steps  and the cls_loss is : tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028913657255632674
now it is 12960 steps  and the cls_loss is : tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002893599828671962
now it is 12980 steps  and the cls_loss is : tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028958116626214866
now it is 13000 steps  and the cls_loss is : tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028980011878045006
now it is 13020 steps  and the cls_loss is : tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002900168365013146
now it is 13040 steps  and the cls_loss is : tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029023131554397497
now it is 13060 steps  and the cls_loss is : tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00290443552067752
now it is 13080 steps  and the cls_loss is : tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029065354227212335
now it is 13100 steps  and the cls_loss is : tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002908612823967915
now it is 13120 steps  and the cls_loss is : tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002910667687217511
now it is 13140 steps  and the cls_loss is : tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002912699975673557
now it is 13160 steps  and the cls_loss is : tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029147096529438354
now it is 13180 steps  and the cls_loss is : tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029166966830410273
now it is 13200 steps  and the cls_loss is : tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002918661030383357
now it is 13220 steps  and the cls_loss is : tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029206026597952297
now it is 13240 steps  and the cls_loss is : tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029225215365078602
now it is 13260 steps  and the cls_loss is : tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002924417626159897
now it is 13280 steps  and the cls_loss is : tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002926290894798035
now it is 13300 steps  and the cls_loss is : tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029281413088776283
now it is 13320 steps  and the cls_loss is : tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029299688352632854
now it is 13340 steps  and the cls_loss is : tensor(0.3454, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002931773441229466
now it is 13360 steps  and the cls_loss is : tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002933555094461066
now it is 13380 steps  and the cls_loss is : tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029353137630539964
now it is 13400 steps  and the cls_loss is : tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002937049415515754
now it is 13420 steps  and the cls_loss is : tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002938762020765986
now it is 13440 steps  and the cls_loss is : tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002940451548137046
now it is 13460 steps  and the cls_loss is : tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029421179673745452
now it is 13480 steps  and the cls_loss is : tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029437612486378894
now it is 13500 steps  and the cls_loss is : tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029453813625008192
now it is 13520 steps  and the cls_loss is : tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029469782799519334
now it is 13540 steps  and the cls_loss is : tensor(0.1630, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029485519723952084
now it is 13560 steps  and the cls_loss is : tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002950102411650512
now it is 13580 steps  and the cls_loss is : tensor(0.0558, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029516295699541064
now it is 13600 steps  and the cls_loss is : tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002953133419959147
now it is 13620 steps  and the cls_loss is : tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002954613934736171
now it is 13640 steps  and the cls_loss is : tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029560710877735794
now it is 13660 steps  and the cls_loss is : tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029575048529781127
now it is 13680 steps  and the cls_loss is : tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029589152046753174
now it is 13700 steps  and the cls_loss is : tensor(0.0816, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002960302117610006
now it is 13720 steps  and the cls_loss is : tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029616655669467092
now it is 13740 steps  and the cls_loss is : tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002963005528270121
now it is 13760 steps  and the cls_loss is : tensor(0.4782, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029643219775855353
now it is 13780 steps  and the cls_loss is : tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002965614891319276
now it is 13800 steps  and the cls_loss is : tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029668842463191182
now it is 13820 steps  and the cls_loss is : tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029681300198547054
now it is 13840 steps  and the cls_loss is : tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002969352189617952
now it is 13860 steps  and the cls_loss is : tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002970550733723449
now it is 13880 steps  and the cls_loss is : tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002971725630708849
now it is 13900 steps  and the cls_loss is : tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029728768595352556
now it is 13920 steps  and the cls_loss is : tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002974004399587599
now it is 13940 steps  and the cls_loss is : tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029751082306750027
now it is 13960 steps  and the cls_loss is : tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029761883330311485
now it is 13980 steps  and the cls_loss is : tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002977244687314629
now it is 14000 steps  and the cls_loss is : tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029782772746092924
now it is 14020 steps  and the cls_loss is : tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002979286076424584
now it is 14040 steps  and the cls_loss is : tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029802710746958763
now it is 14060 steps  and the cls_loss is : tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002981232251784791
now it is 14080 steps  and the cls_loss is : tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002982169590479516
now it is 14100 steps  and the cls_loss is : tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029830830739951157
now it is 14120 steps  and the cls_loss is : tensor(0.5948, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029839726859738273
now it is 14140 steps  and the cls_loss is : tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029848384104853563
now it is 14160 steps  and the cls_loss is : tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029856802320271628
now it is 14180 steps  and the cls_loss is : tensor(0.2039, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029864981355247357
now it is 14200 steps  and the cls_loss is : tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029872921063318664
now it is 14220 steps  and the cls_loss is : tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029880621302309086
now it is 14240 steps  and the cls_loss is : tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029888081934330334
now it is 14260 steps  and the cls_loss is : tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029895302825784765
now it is 14280 steps  and the cls_loss is : tensor(0.6172, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029902283847367777
now it is 14300 steps  and the cls_loss is : tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002990902487407012
now it is 14320 steps  and the cls_loss is : tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002991552578518014
now it is 14340 steps  and the cls_loss is : tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002992178646428592
now it is 14360 steps  and the cls_loss is : tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029927806799277404
now it is 14380 steps  and the cls_loss is : tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002993358668234836
now it is 14400 steps  and the cls_loss is : tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029939126009998346
now it is 14420 steps  and the cls_loss is : tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029944424683034545
now it is 14440 steps  and the cls_loss is : tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029949482606573545
now it is 14460 steps  and the cls_loss is : tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002995429969004304
now it is 14480 steps  and the cls_loss is : tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029958875847183445
now it is 14500 steps  and the cls_loss is : tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029963210996049455
now it is 14520 steps  and the cls_loss is : tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029967305059011495
now it is 14540 steps  and the cls_loss is : tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029971157962757127
now it is 14560 steps  and the cls_loss is : tensor(0.1202, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997476963829235
now it is 14580 steps  and the cls_loss is : tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997814002094283
now it is 14600 steps  and the cls_loss is : tensor(0.1720, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029981269050355095
now it is 14620 steps  and the cls_loss is : tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029984156670497556
now it is 14640 steps  and the cls_loss is : tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998680282966157
now it is 14660 steps  and the cls_loss is : tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998920748046232
now it is 14680 steps  and the cls_loss is : tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029991370579839694
now it is 14700 steps  and the cls_loss is : tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029993292089059045
now it is 14720 steps  and the cls_loss is : tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999497197371188
now it is 14740 steps  and the cls_loss is : tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999641020371647
now it is 14760 steps  and the cls_loss is : tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029997606753318423
now it is 14780 steps  and the cls_loss is : tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029998561601091104
now it is 14800 steps  and the cls_loss is : tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029999274729936042
now it is 14820 steps  and the cls_loss is : tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029999746127083227
now it is 14840 steps  and the cls_loss is : tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029999975784091347
now it is 14860 steps  and the cls_loss is : tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029999982204688383
now it is 14880 steps  and the cls_loss is : tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029999856856881262
now it is 14900 steps  and the cls_loss is : tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999961213121653
now it is 14920 steps  and the cls_loss is : tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999924802964188
now it is 14940 steps  and the cls_loss is : tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029998764555055077
now it is 14960 steps  and the cls_loss is : tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029998161711303943
now it is 14980 steps  and the cls_loss is : tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999743950318632
now it is 15000 steps  and the cls_loss is : tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029996597936450026
now it is 15020 steps  and the cls_loss is : tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029995637017792825
now it is 15040 steps  and the cls_loss is : tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999455675486236
now it is 15060 steps  and the cls_loss is : tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029993357156256092
now it is 15080 steps  and the cls_loss is : tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999203823152125
now it is 15100 steps  and the cls_loss is : tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029990599991154727
now it is 15120 steps  and the cls_loss is : tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998904244660302
now it is 15140 steps  and the cls_loss is : tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029987365610262126
now it is 15160 steps  and the cls_loss is : tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998556949547745
now it is 15180 steps  and the cls_loss is : tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998365411654369
now it is 15200 steps  and the cls_loss is : tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029981619488704736
now it is 15220 steps  and the cls_loss is : tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029979465628153534
now it is 15240 steps  and the cls_loss is : tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997719255203198
now it is 15260 steps  and the cls_loss is : tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997480027843074
now it is 15280 steps  and the cls_loss is : tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997228882638917
now it is 15300 steps  and the cls_loss is : tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029969658215895107
now it is 15320 steps  and the cls_loss is : tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029966908467884737
now it is 15340 steps  and the cls_loss is : tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029964039604242422
now it is 15360 steps  and the cls_loss is : tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029961051647800527
now it is 15380 steps  and the cls_loss is : tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029957944622339234
now it is 15400 steps  and the cls_loss is : tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029954718552586378
now it is 15420 steps  and the cls_loss is : tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029951373464217196
now it is 15440 steps  and the cls_loss is : tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002994790938385419
now it is 15460 steps  and the cls_loss is : tensor(0.4855, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002994432633906686
now it is 15480 steps  and the cls_loss is : tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00299406243583715
now it is 15500 steps  and the cls_loss is : tensor(0.2092, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029936803471231
now it is 15520 steps  and the cls_loss is : tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029932863708054575
now it is 15540 steps  and the cls_loss is : tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029928805100197533
now it is 15560 steps  and the cls_loss is : tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029924627679961038
now it is 15580 steps  and the cls_loss is : tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002992033148059183
now it is 15600 steps  and the cls_loss is : tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029915916536281994
now it is 15620 steps  and the cls_loss is : tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002991138288216865
now it is 15640 steps  and the cls_loss is : tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002990673055433369
now it is 15660 steps  and the cls_loss is : tensor(0.4508, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029901959589803515
now it is 15680 steps  and the cls_loss is : tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029897070026548692
now it is 15700 steps  and the cls_loss is : tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029892061903483693
now it is 15720 steps  and the cls_loss is : tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029886935260466565
now it is 15740 steps  and the cls_loss is : tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029881690138298606
now it is 15760 steps  and the cls_loss is : tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002987632657872408
now it is 15780 steps  and the cls_loss is : tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002987084462442982
now it is 15800 steps  and the cls_loss is : tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002986524431904495
now it is 15820 steps  and the cls_loss is : tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029859525707140516
now it is 15840 steps  and the cls_loss is : tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00298536888342291
now it is 15860 steps  and the cls_loss is : tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029847733746764505
now it is 15880 steps  and the cls_loss is : tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002984166049214138
now it is 15900 steps  and the cls_loss is : tensor(0.0731, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002983546911869479
now it is 15920 steps  and the cls_loss is : tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029829159675699908
now it is 15940 steps  and the cls_loss is : tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029822732213371553
now it is 15960 steps  and the cls_loss is : tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002981618678286385
now it is 15980 steps  and the cls_loss is : tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029809523436269787
now it is 16000 steps  and the cls_loss is : tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002980274222662078
now it is 16020 steps  and the cls_loss is : tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029795843207886326
now it is 16040 steps  and the cls_loss is : tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029788826434973496
now it is 16060 steps  and the cls_loss is : tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002978169196372653
now it is 16080 steps  and the cls_loss is : tensor(0.7167, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002977443985092641
now it is 16100 steps  and the cls_loss is : tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029767070154290364
now it is 16120 steps  and the cls_loss is : tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029759582932471452
now it is 16140 steps  and the cls_loss is : tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002975197824505807
now it is 16160 steps  and the cls_loss is : tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00297442561525735
now it is 16180 steps  and the cls_loss is : tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002973641671647538
now it is 16200 steps  and the cls_loss is : tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002972845999915528
now it is 16220 steps  and the cls_loss is : tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029720386063938164
now it is 16240 steps  and the cls_loss is : tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002971219497508189
now it is 16260 steps  and the cls_loss is : tensor(0.0562, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002970388679777671
now it is 16280 steps  and the cls_loss is : tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029695461598144746
now it is 16300 steps  and the cls_loss is : tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029686919443239457
now it is 16320 steps  and the cls_loss is : tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002967826040104512
now it is 16340 steps  and the cls_loss is : tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029669484540476273
now it is 16360 steps  and the cls_loss is : tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029660591931377177
now it is 16380 steps  and the cls_loss is : tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002965158264452126
now it is 16400 steps  and the cls_loss is : tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029642456751610546
now it is 16420 steps  and the cls_loss is : tensor(0.1684, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002963321432527509
now it is 16440 steps  and the cls_loss is : tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029623855439072405
now it is 16460 steps  and the cls_loss is : tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029614380167486865
now it is 16480 steps  and the cls_loss is : tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029604788585929115
now it is 16500 steps  and the cls_loss is : tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002959508077073548
now it is 16520 steps  and the cls_loss is : tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029585256799167354
now it is 16540 steps  and the cls_loss is : tensor(0.1587, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029575316749410573
now it is 16560 steps  and the cls_loss is : tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029565260700574808
now it is 16580 steps  and the cls_loss is : tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002955508873269292
now it is 16600 steps  and the cls_loss is : tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029544800926720356
now it is 16620 steps  and the cls_loss is : tensor(0.1440, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029534397364534455
now it is 16640 steps  and the cls_loss is : tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002952387812893384
now it is 16660 steps  and the cls_loss is : tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029513243303637728
now it is 16680 steps  and the cls_loss is : tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002950249297328529
now it is 16700 steps  and the cls_loss is : tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029491627223434957
now it is 16720 steps  and the cls_loss is : tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002948064614056375
now it is 16740 steps  and the cls_loss is : tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002946954981206659
now it is 16760 steps  and the cls_loss is : tensor(0.3364, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002945833832625559
now it is 16780 steps  and the cls_loss is : tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002944701177235938
now it is 16800 steps  and the cls_loss is : tensor(0.1551, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002943557024052237
now it is 16820 steps  and the cls_loss is : tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029424013821804044
now it is 16840 steps  and the cls_loss is : tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002941234260817823
now it is 16860 steps  and the cls_loss is : tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002940055669253238
now it is 16880 steps  and the cls_loss is : tensor(0.1552, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002938865616866682
now it is 16900 steps  and the cls_loss is : tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029376641131293995
now it is 16920 steps  and the cls_loss is : tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002936451167603775
now it is 16940 steps  and the cls_loss is : tensor(0.3686, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029352267899432527
now it is 16960 steps  and the cls_loss is : tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029339909898922615
now it is 16980 steps  and the cls_loss is : tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002932743777286138
now it is 17000 steps  and the cls_loss is : tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002931485162051048
now it is 17020 steps  and the cls_loss is : tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029302151542039056
now it is 17040 steps  and the cls_loss is : tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029289337638522973
now it is 17060 steps  and the cls_loss is : tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002927641001194398
now it is 17080 steps  and the cls_loss is : tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029263368765188903
now it is 17100 steps  and the cls_loss is : tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002925021400204885
now it is 17120 steps  and the cls_loss is : tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002923694582721837
now it is 17140 steps  and the cls_loss is : tensor(0.1618, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002922356434629461
now it is 17160 steps  and the cls_loss is : tensor(0.1161, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029210069665776485
now it is 17180 steps  and the cls_loss is : tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029196461893063828
now it is 17200 steps  and the cls_loss is : tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002918274113645655
now it is 17220 steps  and the cls_loss is : tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029168907505153748
now it is 17240 steps  and the cls_loss is : tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002915496110925286
now it is 17260 steps  and the cls_loss is : tensor(0.0523, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002914090205974878
now it is 17280 steps  and the cls_loss is : tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029126730468532975
now it is 17300 steps  and the cls_loss is : tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029112446448392604
now it is 17320 steps  and the cls_loss is : tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029098050113009594
now it is 17340 steps  and the cls_loss is : tensor(0.1188, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029083541576959767
now it is 17360 steps  and the cls_loss is : tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029068920955711915
now it is 17380 steps  and the cls_loss is : tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002905418836562687
now it is 17400 steps  and the cls_loss is : tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00290393439239566
now it is 17420 steps  and the cls_loss is : tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029024387748843253
now it is 17440 steps  and the cls_loss is : tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029009319959318234
now it is 17460 steps  and the cls_loss is : tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028994140675301255
now it is 17480 steps  and the cls_loss is : tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002897885001759936
now it is 17500 steps  and the cls_loss is : tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028963448107906004
now it is 17520 steps  and the cls_loss is : tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002894793506880004
now it is 17540 steps  and the cls_loss is : tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028932311023744774
now it is 17560 steps  and the cls_loss is : tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002891657609708698
now it is 17580 steps  and the cls_loss is : tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028900730414055894
now it is 17600 steps  and the cls_loss is : tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002888477410076222
now it is 17620 steps  and the cls_loss is : tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028868707284197145
now it is 17640 steps  and the cls_loss is : tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028852530092231318
now it is 17660 steps  and the cls_loss is : tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002883624265361381
now it is 17680 steps  and the cls_loss is : tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002881984509797114
now it is 17700 steps  and the cls_loss is : tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002880333755580618
now it is 17720 steps  and the cls_loss is : tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028786720158497188
now it is 17740 steps  and the cls_loss is : tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028769993038296683
now it is 17760 steps  and the cls_loss is : tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028753156328330458
now it is 17780 steps  and the cls_loss is : tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028736210162596497
now it is 17800 steps  and the cls_loss is : tensor(0.2003, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002871915467596389
now it is 17820 steps  and the cls_loss is : tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00287019900041718
now it is 17840 steps  and the cls_loss is : tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028684716283828345
now it is 17860 steps  and the cls_loss is : tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002866733365240952
now it is 17880 steps  and the cls_loss is : tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002864984224825812
now it is 17900 steps  and the cls_loss is : tensor(0.4840, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028632242210582626
now it is 17920 steps  and the cls_loss is : tensor(0.2017, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028614533679456092
now it is 17940 steps  and the cls_loss is : tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002859671679581505
now it is 17960 steps  and the cls_loss is : tensor(0.1561, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002857879170145836
now it is 17980 steps  and the cls_loss is : tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00285607585390461
now it is 18000 steps  and the cls_loss is : tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028542617452098425
now it is 18020 steps  and the cls_loss is : tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028524368584994437
now it is 18040 steps  and the cls_loss is : tensor(0.0779, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028506012082971026
now it is 18060 steps  and the cls_loss is : tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028487548092121693
now it is 18080 steps  and the cls_loss is : tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002846897675939543
now it is 18100 steps  and the cls_loss is : tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028450298232595523
now it is 18120 steps  and the cls_loss is : tensor(0.1364, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028431512660378375
now it is 18140 steps  and the cls_loss is : tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002841262019225234
now it is 18160 steps  and the cls_loss is : tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002839362097857651
now it is 18180 steps  and the cls_loss is : tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028374515170559536
now it is 18200 steps  and the cls_loss is : tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002835530292025842
now it is 18220 steps  and the cls_loss is : tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028335984380577304
now it is 18240 steps  and the cls_loss is : tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028316559705266254
now it is 18260 steps  and the cls_loss is : tensor(0.1702, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028297029048920033
now it is 18280 steps  and the cls_loss is : tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002827739256697688
now it is 18300 steps  and the cls_loss is : tensor(0.0573, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028257650415717244
now it is 18320 steps  and the cls_loss is : tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00282378027522626
now it is 18340 steps  and the cls_loss is : tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028217849734574123
now it is 18360 steps  and the cls_loss is : tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028197791521451486
now it is 18380 steps  and the cls_loss is : tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002817762827253159
now it is 18400 steps  and the cls_loss is : tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028157360148287256
now it is 18420 steps  and the cls_loss is : tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028136987310026
now it is 18440 steps  and the cls_loss is : tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028116509919888697
now it is 18460 steps  and the cls_loss is : tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028095928140848343
now it is 18480 steps  and the cls_loss is : tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002807524213670871
now it is 18500 steps  and the cls_loss is : tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028054452072103085
now it is 18520 steps  and the cls_loss is : tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002803355811249292
now it is 18540 steps  and the cls_loss is : tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002801256042416654
now it is 18560 steps  and the cls_loss is : tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002799145917423782
now it is 18580 steps  and the cls_loss is : tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002797025453064485
now it is 18600 steps  and the cls_loss is : tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002794894666214858
now it is 18620 steps  and the cls_loss is : tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002792753573833151
now it is 18640 steps  and the cls_loss is : tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027906021929596323
now it is 18660 steps  and the cls_loss is : tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027884405407164518
now it is 18680 steps  and the cls_loss is : tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002786268634307507
now it is 18700 steps  and the cls_loss is : tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002784086491018305
now it is 18720 steps  and the cls_loss is : tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027818941282158247
now it is 18740 steps  and the cls_loss is : tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002779691563348379
now it is 18760 steps  and the cls_loss is : tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002777478813945476
now it is 18780 steps  and the cls_loss is : tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002775255897617678
now it is 18800 steps  and the cls_loss is : tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002773022832056464
now it is 18820 steps  and the cls_loss is : tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002770779635034087
now it is 18840 steps  and the cls_loss is : tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002768526324403433
now it is 18860 steps  and the cls_loss is : tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027662629180978788
now it is 18880 steps  and the cls_loss is : tensor(0.4509, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027639894341311495
now it is 18900 steps  and the cls_loss is : tensor(0.1587, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002761705890597176
now it is 18920 steps  and the cls_loss is : tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027594123056699483
now it is 18940 steps  and the cls_loss is : tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027571086976033747
now it is 18960 steps  and the cls_loss is : tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027547950847311323
now it is 18980 steps  and the cls_loss is : tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002752471485466525
now it is 19000 steps  and the cls_loss is : tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027501379183023336
now it is 19020 steps  and the cls_loss is : tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002747794401810673
now it is 19040 steps  and the cls_loss is : tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027454409546428375
now it is 19060 steps  and the cls_loss is : tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027430775955291603
now it is 19080 steps  and the cls_loss is : tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027407043432788585
now it is 19100 steps  and the cls_loss is : tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027383212167798854
now it is 19120 steps  and the cls_loss is : tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002735928234998782
now it is 19140 steps  and the cls_loss is : tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027335254169805223
now it is 19160 steps  and the cls_loss is : tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002731112781848365
now it is 19180 steps  and the cls_loss is : tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027286903488037
now it is 19200 steps  and the cls_loss is : tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027262581371258953
now it is 19220 steps  and the cls_loss is : tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027238161661721433
now it is 19240 steps  and the cls_loss is : tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027213644553773088
now it is 19260 steps  and the cls_loss is : tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027189030242537717
now it is 19280 steps  and the cls_loss is : tensor(0.0679, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002716431892391274
now it is 19300 steps  and the cls_loss is : tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002713951079456761
now it is 19320 steps  and the cls_loss is : tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027114606051942287
now it is 19340 steps  and the cls_loss is : tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027089604894245623
now it is 19360 steps  and the cls_loss is : tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002706450752045382
now it is 19380 steps  and the cls_loss is : tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002703931413030884
now it is 19400 steps  and the cls_loss is : tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002701402492431679
now it is 19420 steps  and the cls_loss is : tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002698864010374636
now it is 19440 steps  and the cls_loss is : tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00269631598706272
now it is 19460 steps  and the cls_loss is : tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002693758442774831
now it is 19480 steps  and the cls_loss is : tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002691191397865645
now it is 19500 steps  and the cls_loss is : tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002688614872765449
now it is 19520 steps  and the cls_loss is : tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026860288879799804
now it is 19540 steps  and the cls_loss is : tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002683433464090264
now it is 19560 steps  and the cls_loss is : tensor(0.7315, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002680828621752445
now it is 19580 steps  and the cls_loss is : tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026782143816976296
now it is 19600 steps  and the cls_loss is : tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026755907647317166
now it is 19620 steps  and the cls_loss is : tensor(0.1825, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026729577917352313
now it is 19640 steps  and the cls_loss is : tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026703154836631633
now it is 19660 steps  and the cls_loss is : tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026676638615447945
now it is 19680 steps  and the cls_loss is : tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026650029464835353
now it is 19700 steps  and the cls_loss is : tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026623327596567567
now it is 19720 steps  and the cls_loss is : tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026596533223156187
now it is 19740 steps  and the cls_loss is : tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026569646557849046
now it is 19760 steps  and the cls_loss is : tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002654266781462849
now it is 19780 steps  and the cls_loss is : tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026515597208209693
now it is 19800 steps  and the cls_loss is : tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002648843495403894
now it is 19820 steps  and the cls_loss is : tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026461181268291885
now it is 19840 steps  and the cls_loss is : tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00264338363678719
now it is 19860 steps  and the cls_loss is : tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026406400470408266
now it is 19880 steps  and the cls_loss is : tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00263788737942545
now it is 19900 steps  and the cls_loss is : tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00263512565584866
now it is 19920 steps  and the cls_loss is : tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026323548982901284
now it is 19940 steps  and the cls_loss is : tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002629575128801427
now it is 19960 steps  and the cls_loss is : tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026267863695058494
now it is 19980 steps  and the cls_loss is : tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002623988642598238
now it is 20000 steps  and the cls_loss is : tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002621181970344804
now it is 20020 steps  and the cls_loss is : tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026183663750829513
now it is 20040 steps  and the cls_loss is : tensor(0.2021, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026155418792211007
now it is 20060 steps  and the cls_loss is : tensor(0.2750, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00261270850523851
now it is 20080 steps  and the cls_loss is : tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002609866275685094
now it is 20100 steps  and the cls_loss is : tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026070152131812455
now it is 20120 steps  and the cls_loss is : tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002604155340417659
now it is 20140 steps  and the cls_loss is : tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026012866801551435
now it is 20160 steps  and the cls_loss is : tensor(0.5240, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002598409255224447
now it is 20180 steps  and the cls_loss is : tensor(0.1817, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025955230885260725
now it is 20200 steps  and the cls_loss is : tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025926282030300954
now it is 20220 steps  and the cls_loss is : tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025897246217759812
now it is 20240 steps  and the cls_loss is : tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002586812367872402
now it is 20260 steps  and the cls_loss is : tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025838914644970546
now it is 20280 steps  and the cls_loss is : tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025809619348964707
now it is 20300 steps  and the cls_loss is : tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025780238023858384
now it is 20320 steps  and the cls_loss is : tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025750770903488125
now it is 20340 steps  and the cls_loss is : tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002572121822237329
now it is 20360 steps  and the cls_loss is : tensor(0.2278, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00256915802157142
now it is 20380 steps  and the cls_loss is : tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002566185711939025
now it is 20400 steps  and the cls_loss is : tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002563204916995803
now it is 20420 steps  and the cls_loss is : tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002560215660464946
now it is 20440 steps  and the cls_loss is : tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025572179661369886
now it is 20460 steps  and the cls_loss is : tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025542118578696185
now it is 20480 steps  and the cls_loss is : tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025511973595874877
now it is 20500 steps  and the cls_loss is : tensor(0.2021, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002548174495282022
now it is 20520 steps  and the cls_loss is : tensor(0.2456, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025451432890112296
now it is 20540 steps  and the cls_loss is : tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002542103764899509
now it is 20560 steps  and the cls_loss is : tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002539055947137459
now it is 20580 steps  and the cls_loss is : tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025359998599816837
now it is 20600 steps  and the cls_loss is : tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002532935527754602
now it is 20620 steps  and the cls_loss is : tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025298629748442504
now it is 20640 steps  and the cls_loss is : tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002526782225704093
now it is 20660 steps  and the cls_loss is : tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025236933048528253
now it is 20680 steps  and the cls_loss is : tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025205962368741778
now it is 20700 steps  and the cls_loss is : tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025174910464167213
now it is 20720 steps  and the cls_loss is : tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025143777581936723
now it is 20740 steps  and the cls_loss is : tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002511256396982693
now it is 20760 steps  and the cls_loss is : tensor(0.2413, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025081269876256968
now it is 20780 steps  and the cls_loss is : tensor(0.3647, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00250498955502865
now it is 20800 steps  and the cls_loss is : tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025018441241613726
now it is 20820 steps  and the cls_loss is : tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024986907200573406
now it is 20840 steps  and the cls_loss is : tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024955293678134865
now it is 20860 steps  and the cls_loss is : tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024923600925899994
now it is 20880 steps  and the cls_loss is : tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002489182919610125
now it is 20900 steps  and the cls_loss is : tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024859978741599647
now it is 20920 steps  and the cls_loss is : tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024828049815882737
now it is 20940 steps  and the cls_loss is : tensor(0.2025, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024796042673062607
now it is 20960 steps  and the cls_loss is : tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002476395756787385
now it is 20980 steps  and the cls_loss is : tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002473179475567153
now it is 21000 steps  and the cls_loss is : tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002469955449242916
now it is 21020 steps  and the cls_loss is : tensor(0.1140, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024667237034736666
now it is 21040 steps  and the cls_loss is : tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002463484263979832
now it is 21060 steps  and the cls_loss is : tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024602371565430746
now it is 21080 steps  and the cls_loss is : tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00245698240700608
now it is 21100 steps  and the cls_loss is : tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002453720041272357
now it is 21120 steps  and the cls_loss is : tensor(0.1608, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00245045008530603
now it is 21140 steps  and the cls_loss is : tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024471725651316278
now it is 21160 steps  and the cls_loss is : tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024438875068338844
now it is 21180 steps  and the cls_loss is : tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002440594936557526
now it is 21200 steps  and the cls_loss is : tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024372948805070627
now it is 21220 steps  and the cls_loss is : tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002433987364946584
now it is 21240 steps  and the cls_loss is : tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002430672416199546
now it is 21260 steps  and the cls_loss is : tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002427350060648562
now it is 21280 steps  and the cls_loss is : tensor(0.2920, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002424020324735196
now it is 21300 steps  and the cls_loss is : tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024206832349597486
now it is 21320 steps  and the cls_loss is : tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024173388178810465
now it is 21340 steps  and the cls_loss is : tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024139871001162346
now it is 21360 steps  and the cls_loss is : tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024106281083405593
now it is 21380 steps  and the cls_loss is : tensor(0.3003, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024072618692871596
now it is 21400 steps  and the cls_loss is : tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024038884097468535
now it is 21420 steps  and the cls_loss is : tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024005077565679234
now it is 21440 steps  and the cls_loss is : tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002397119936655905
now it is 21460 steps  and the cls_loss is : tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023937249769733705
now it is 21480 steps  and the cls_loss is : tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023903229045397155
now it is 21500 steps  and the cls_loss is : tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023869137464309445
now it is 21520 steps  and the cls_loss is : tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002383497529779454
now it is 21540 steps  and the cls_loss is : tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023800742817738168
now it is 21560 steps  and the cls_loss is : tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002376644029658567
now it is 21580 steps  and the cls_loss is : tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023732068007339814
now it is 21600 steps  and the cls_loss is : tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002369762622355863
now it is 21620 steps  and the cls_loss is : tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002366311521935324
now it is 21640 steps  and the cls_loss is : tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002362853526938565
now it is 21660 steps  and the cls_loss is : tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002359388664886662
now it is 21680 steps  and the cls_loss is : tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002355916963355339
now it is 21700 steps  and the cls_loss is : tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002352438449974757
now it is 21720 steps  and the cls_loss is : tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002348953152429289
now it is 21740 steps  and the cls_loss is : tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023454610984573
now it is 21760 steps  and the cls_loss is : tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023419623158509296
now it is 21780 steps  and the cls_loss is : tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023384568324558656
now it is 21800 steps  and the cls_loss is : tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023349446761711276
now it is 21820 steps  and the cls_loss is : tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023314258749488406
now it is 21840 steps  and the cls_loss is : tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023279004567940166
now it is 21860 steps  and the cls_loss is : tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002324368449764328
now it is 21880 steps  and the cls_loss is : tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023208298819698873
now it is 21900 steps  and the cls_loss is : tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00231728478157302
now it is 21920 steps  and the cls_loss is : tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002313733176788045
now it is 21940 steps  and the cls_loss is : tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023101750958810455
now it is 21960 steps  and the cls_loss is : tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002306610567169647
now it is 21980 steps  and the cls_loss is : tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023030396190227916
now it is 22000 steps  and the cls_loss is : tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022994622798605106
now it is 22020 steps  and the cls_loss is : tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002295878578153699
now it is 22040 steps  and the cls_loss is : tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00229228854242389
now it is 22060 steps  and the cls_loss is : tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022886922012430276
now it is 22080 steps  and the cls_loss is : tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022850895832332387
now it is 22100 steps  and the cls_loss is : tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002281480717066605
now it is 22120 steps  and the cls_loss is : tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002277865631464935
now it is 22140 steps  and the cls_loss is : tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002274244355199537
now it is 22160 steps  and the cls_loss is : tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022706169170909865
now it is 22180 steps  and the cls_loss is : tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022669833460089027
now it is 22200 steps  and the cls_loss is : tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002263343670871711
now it is 22220 steps  and the cls_loss is : tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002259697920646421
now it is 22240 steps  and the cls_loss is : tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022560461243483886
now it is 22260 steps  and the cls_loss is : tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022523883110410906
now it is 22280 steps  and the cls_loss is : tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022487245098358906
now it is 22300 steps  and the cls_loss is : tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022450547498918077
now it is 22320 steps  and the cls_loss is : tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022413790604152847
now it is 22340 steps  and the cls_loss is : tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022376974706599575
now it is 22360 steps  and the cls_loss is : tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022340100099264163
now it is 22380 steps  and the cls_loss is : tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002230316707561981
now it is 22400 steps  and the cls_loss is : tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00222661759296046
now it is 22420 steps  and the cls_loss is : tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002222912695561922
now it is 22440 steps  and the cls_loss is : tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002219202044852456
now it is 22460 steps  and the cls_loss is : tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022154856703639433
now it is 22480 steps  and the cls_loss is : tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002211763601673816
now it is 22500 steps  and the cls_loss is : tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002208035868404826
now it is 22520 steps  and the cls_loss is : tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022043025002248073
now it is 22540 steps  and the cls_loss is : tensor(0.0731, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002200563526846441
now it is 22560 steps  and the cls_loss is : tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021968189780270167
now it is 22580 steps  and the cls_loss is : tensor(0.7069, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021930688835681993
now it is 22600 steps  and the cls_loss is : tensor(0.1587, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021893132733157876
now it is 22620 steps  and the cls_loss is : tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021855521771594806
now it is 22640 steps  and the cls_loss is : tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002181785625032636
now it is 22660 steps  and the cls_loss is : tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002178013646912035
now it is 22680 steps  and the cls_loss is : tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002174236272817643
now it is 22700 steps  and the cls_loss is : tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021704535328123695
now it is 22720 steps  and the cls_loss is : tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021666654570018282
now it is 22740 steps  and the cls_loss is : tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021628720755341017
now it is 22760 steps  and the cls_loss is : tensor(0.3948, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021590734185994967
now it is 22780 steps  and the cls_loss is : tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002155269516430306
now it is 22800 steps  and the cls_loss is : tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021514603993005683
now it is 22820 steps  and the cls_loss is : tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021476460975258242
now it is 22840 steps  and the cls_loss is : tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021438266414628804
now it is 22860 steps  and the cls_loss is : tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002140002061509562
now it is 22880 steps  and the cls_loss is : tensor(0.1684, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002136172388104476
now it is 22900 steps  and the cls_loss is : tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021323376517267648
now it is 22920 steps  and the cls_loss is : tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021284978828958667
now it is 22940 steps  and the cls_loss is : tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021246531121712703
now it is 22960 steps  and the cls_loss is : tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002120803370152273
now it is 22980 steps  and the cls_loss is : tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021169486874777384
now it is 23000 steps  and the cls_loss is : tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021130890948258497
now it is 23020 steps  and the cls_loss is : tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002109224622913868
now it is 23040 steps  and the cls_loss is : tensor(0.1892, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002105355302497886
now it is 23060 steps  and the cls_loss is : tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021014811643725846
now it is 23080 steps  and the cls_loss is : tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020976022393709875
now it is 23100 steps  and the cls_loss is : tensor(0.1454, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002093718558364216
now it is 23120 steps  and the cls_loss is : tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002089830152261241
now it is 23140 steps  and the cls_loss is : tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002085937052008641
now it is 23160 steps  and the cls_loss is : tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020820392885903525
now it is 23180 steps  and the cls_loss is : tensor(0.1127, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002078136893027426
now it is 23200 steps  and the cls_loss is : tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020742298963777757
now it is 23220 steps  and the cls_loss is : tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020703183297359367
now it is 23240 steps  and the cls_loss is : tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020664022242328135
now it is 23260 steps  and the cls_loss is : tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020624816110354337
now it is 23280 steps  and the cls_loss is : tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002058556521346702
now it is 23300 steps  and the cls_loss is : tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002054626986405149
now it is 23320 steps  and the cls_loss is : tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002050693037484683
now it is 23340 steps  and the cls_loss is : tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002046754705894343
now it is 23360 steps  and the cls_loss is : tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002042812022978047
now it is 23380 steps  and the cls_loss is : tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020388650201143455
now it is 23400 steps  and the cls_loss is : tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020349137287161683
now it is 23420 steps  and the cls_loss is : tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020309581802305777
now it is 23440 steps  and the cls_loss is : tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002026998406138515
now it is 23460 steps  and the cls_loss is : tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020230344379545536
now it is 23480 steps  and the cls_loss is : tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002019066307226646
now it is 23500 steps  and the cls_loss is : tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002015094045535872
now it is 23520 steps  and the cls_loss is : tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020111176844961895
now it is 23540 steps  and the cls_loss is : tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002007137255754181
now it is 23560 steps  and the cls_loss is : tensor(0.3049, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002003152790988803
now it is 23580 steps  and the cls_loss is : tensor(0.0630, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001999164321911133
now it is 23600 steps  and the cls_loss is : tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001995171880264119
now it is 23620 steps  and the cls_loss is : tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019911754978223233
now it is 23640 steps  and the cls_loss is : tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019871752063916727
now it is 23660 steps  and the cls_loss is : tensor(0.0544, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001983171037809205
now it is 23680 steps  and the cls_loss is : tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019791630239428134
now it is 23700 steps  and the cls_loss is : tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001975151196690997
now it is 23720 steps  and the cls_loss is : tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019711355879826016
now it is 23740 steps  and the cls_loss is : tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00196711622977657
now it is 23760 steps  and the cls_loss is : tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019630931540616857
now it is 23780 steps  and the cls_loss is : tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001959066392856319
now it is 23800 steps  and the cls_loss is : tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001955035978208171
now it is 23820 steps  and the cls_loss is : tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019510019421940207
now it is 23840 steps  and the cls_loss is : tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019469643169194668
now it is 23860 steps  and the cls_loss is : tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001942923134518675
now it is 23880 steps  and the cls_loss is : tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001938878427154121
now it is 23900 steps  and the cls_loss is : tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019348302270163337
now it is 23920 steps  and the cls_loss is : tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019307785663236399
now it is 23940 steps  and the cls_loss is : tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001926723477321909
now it is 23960 steps  and the cls_loss is : tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019226649922842942
now it is 23980 steps  and the cls_loss is : tensor(0.0754, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019186031435109764
now it is 24000 steps  and the cls_loss is : tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001914537963328909
now it is 24020 steps  and the cls_loss is : tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019104694840915576
now it is 24040 steps  and the cls_loss is : tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019063977381786443
now it is 24060 steps  and the cls_loss is : tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001902322757995889
now it is 24080 steps  and the cls_loss is : tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018982445759747535
now it is 24100 steps  and the cls_loss is : tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018941632245721804
now it is 24120 steps  and the cls_loss is : tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001890078736270338
now it is 24140 steps  and the cls_loss is : tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018859911435763592
now it is 24160 steps  and the cls_loss is : tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018819004790220839
now it is 24180 steps  and the cls_loss is : tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018778067751638
now it is 24200 steps  and the cls_loss is : tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018737100645819839
now it is 24220 steps  and the cls_loss is : tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018696103798810425
now it is 24240 steps  and the cls_loss is : tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018655077536890517
now it is 24260 steps  and the cls_loss is : tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018614022186574984
now it is 24280 steps  and the cls_loss is : tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00185729380746102
now it is 24300 steps  and the cls_loss is : tensor(0.2757, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018531825527971443
now it is 24320 steps  and the cls_loss is : tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018490684873860286
now it is 24340 steps  and the cls_loss is : tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001844951643970202
now it is 24360 steps  and the cls_loss is : tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018408320553143006
now it is 24380 steps  and the cls_loss is : tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00183670975420481
now it is 24400 steps  and the cls_loss is : tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018325847734498033
now it is 24420 steps  and the cls_loss is : tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018284571458786806
now it is 24440 steps  and the cls_loss is : tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018243269043419059
now it is 24460 steps  and the cls_loss is : tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018201940817107484
now it is 24480 steps  and the cls_loss is : tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018160587108770178
now it is 24500 steps  and the cls_loss is : tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001811920824752806
now it is 24520 steps  and the cls_loss is : tensor(0.2005, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001807780456270221
now it is 24540 steps  and the cls_loss is : tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001803637638381129
now it is 24560 steps  and the cls_loss is : tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017994924040568897
now it is 24580 steps  and the cls_loss is : tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001795344786288094
now it is 24600 steps  and the cls_loss is : tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017911948180843024
now it is 24620 steps  and the cls_loss is : tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017870425324737812
now it is 24640 steps  and the cls_loss is : tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017828879625032413
now it is 24660 steps  and the cls_loss is : tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017787311412375726
now it is 24680 steps  and the cls_loss is : tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017745721017595833
now it is 24700 steps  and the cls_loss is : tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001770410877169735
now it is 24720 steps  and the cls_loss is : tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017662475005858812
now it is 24740 steps  and the cls_loss is : tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017620820051430007
now it is 24760 steps  and the cls_loss is : tensor(0.3542, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017579144239929369
now it is 24780 steps  and the cls_loss is : tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017537447903041325
now it is 24800 steps  and the cls_loss is : tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001749573137261365
now it is 24820 steps  and the cls_loss is : tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017453994980654835
now it is 24840 steps  and the cls_loss is : tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017412239059331448
now it is 24860 steps  and the cls_loss is : tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017370463940965485
now it is 24880 steps  and the cls_loss is : tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017328669958031715
now it is 24900 steps  and the cls_loss is : tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017286857443155057
now it is 24920 steps  and the cls_loss is : tensor(0.1576, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001724502672910791
now it is 24940 steps  and the cls_loss is : tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017203178148807521
now it is 24960 steps  and the cls_loss is : tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001716131203531332
now it is 24980 steps  and the cls_loss is : tensor(0.1537, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017119428721824293
now it is 25000 steps  and the cls_loss is : tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017077528541676297
now it is 25020 steps  and the cls_loss is : tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017035611828339439
now it is 25040 steps  and the cls_loss is : tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016993678915415405
now it is 25060 steps  and the cls_loss is : tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016951730136634806
now it is 25080 steps  and the cls_loss is : tensor(0.1357, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016909765825854524
now it is 25100 steps  and the cls_loss is : tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001686778631705506
now it is 25120 steps  and the cls_loss is : tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016825791944337861
now it is 25140 steps  and the cls_loss is : tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016783783041922687
now it is 25160 steps  and the cls_loss is : tensor(0.3265, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016741759944144921
now it is 25180 steps  and the cls_loss is : tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016699722985452925
now it is 25200 steps  and the cls_loss is : tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016657672500405385
now it is 25220 steps  and the cls_loss is : tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016615608823668626
now it is 25240 steps  and the cls_loss is : tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016573532290013971
now it is 25260 steps  and the cls_loss is : tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016531443234315067
now it is 25280 steps  and the cls_loss is : tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016489341991545205
now it is 25300 steps  and the cls_loss is : tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016447228896774688
now it is 25320 steps  and the cls_loss is : tensor(0.3544, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016405104285168138
now it is 25340 steps  and the cls_loss is : tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016362968491981835
now it is 25360 steps  and the cls_loss is : tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001632082185256105
now it is 25380 steps  and the cls_loss is : tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016278664702337375
now it is 25400 steps  and the cls_loss is : tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016236497376826058
now it is 25420 steps  and the cls_loss is : tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016194320211623322
now it is 25440 steps  and the cls_loss is : tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016152133542403707
now it is 25460 steps  and the cls_loss is : tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016109937704917386
now it is 25480 steps  and the cls_loss is : tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016067733034987506
now it is 25500 steps  and the cls_loss is : tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016025519868507509
now it is 25520 steps  and the cls_loss is : tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015983298541438454
now it is 25540 steps  and the cls_loss is : tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015941069389806349
now it is 25560 steps  and the cls_loss is : tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015898832749699473
now it is 25580 steps  and the cls_loss is : tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001585658895726571
now it is 25600 steps  and the cls_loss is : tensor(0.3158, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015814338348709856
now it is 25620 steps  and the cls_loss is : tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001577208126029096
now it is 25640 steps  and the cls_loss is : tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015729818028319652
now it is 25660 steps  and the cls_loss is : tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015687548989155441
now it is 25680 steps  and the cls_loss is : tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015645274479204065
now it is 25700 steps  and the cls_loss is : tensor(0.1285, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001560299483491479
now it is 25720 steps  and the cls_loss is : tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015560710392777761
now it is 25740 steps  and the cls_loss is : tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015518421489321293
now it is 25760 steps  and the cls_loss is : tensor(0.0561, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001547612846110921
now it is 25780 steps  and the cls_loss is : tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001543383164473817
now it is 25800 steps  and the cls_loss is : tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001539153137683498
now it is 25820 steps  and the cls_loss is : tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015349227994053904
now it is 25840 steps  and the cls_loss is : tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001530692183307401
now it is 25860 steps  and the cls_loss is : tensor(0.1294, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015264613230596474
now it is 25880 steps  and the cls_loss is : tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015222302523341896
now it is 25900 steps  and the cls_loss is : tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001517999004804764
now it is 25920 steps  and the cls_loss is : tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015137676141465121
now it is 25940 steps  and the cls_loss is : tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015095361140357165
now it is 25960 steps  and the cls_loss is : tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015053045381495302
now it is 25980 steps  and the cls_loss is : tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015010729201657092
now it is 26000 steps  and the cls_loss is : tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014968412937623446
now it is 26020 steps  and the cls_loss is : tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014926096926175941
now it is 26040 steps  and the cls_loss is : tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014883781504094152
now it is 26060 steps  and the cls_loss is : tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001484146700815296
now it is 26080 steps  and the cls_loss is : tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014799153775119866
now it is 26100 steps  and the cls_loss is : tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014756842141752336
now it is 26120 steps  and the cls_loss is : tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001471453244479509
now it is 26140 steps  and the cls_loss is : tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014672225020977456
now it is 26160 steps  and the cls_loss is : tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014629920207010643
now it is 26180 steps  and the cls_loss is : tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014587618339585112
now it is 26200 steps  and the cls_loss is : tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014545319755367866
now it is 26220 steps  and the cls_loss is : tensor(0.0937, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001450302479099978
now it is 26240 steps  and the cls_loss is : tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014460733783092908
now it is 26260 steps  and the cls_loss is : tensor(0.3788, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001441844706822784
now it is 26280 steps  and the cls_loss is : tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014376164982950967
now it is 26300 steps  and the cls_loss is : tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001433388786377187
now it is 26320 steps  and the cls_loss is : tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014291616047160574
now it is 26340 steps  and the cls_loss is : tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014249349869544924
now it is 26360 steps  and the cls_loss is : tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014207089667307876
now it is 26380 steps  and the cls_loss is : tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014164835776784837
now it is 26400 steps  and the cls_loss is : tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001412258853426097
now it is 26420 steps  and the cls_loss is : tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014080348275968546
now it is 26440 steps  and the cls_loss is : tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014038115338084235
now it is 26460 steps  and the cls_loss is : tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013995890056726446
now it is 26480 steps  and the cls_loss is : tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013953672767952666
now it is 26500 steps  and the cls_loss is : tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013911463807756762
now it is 26520 steps  and the cls_loss is : tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013869263512066316
now it is 26540 steps  and the cls_loss is : tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013827072216739949
now it is 26560 steps  and the cls_loss is : tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013784890257564667
now it is 26580 steps  and the cls_loss is : tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013742717970253151
now it is 26600 steps  and the cls_loss is : tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013700555690441128
now it is 26620 steps  and the cls_loss is : tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013658403753684654
now it is 26640 steps  and the cls_loss is : tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013616262495457496
now it is 26660 steps  and the cls_loss is : tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013574132251148409
now it is 26680 steps  and the cls_loss is : tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013532013356058511
now it is 26700 steps  and the cls_loss is : tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013489906145398574
now it is 26720 steps  and the cls_loss is : tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013447810954286407
now it is 26740 steps  and the cls_loss is : tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013405728117744124
now it is 26760 steps  and the cls_loss is : tensor(0.0678, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013363657970695548
now it is 26780 steps  and the cls_loss is : tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013321600847963479
now it is 26800 steps  and the cls_loss is : tensor(0.2400, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001327955708426709
now it is 26820 steps  and the cls_loss is : tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013237527014219206
now it is 26840 steps  and the cls_loss is : tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001319551097232369
now it is 26860 steps  and the cls_loss is : tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013153509292972742
now it is 26880 steps  and the cls_loss is : tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013111522310444276
now it is 26900 steps  and the cls_loss is : tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013069550358899215
now it is 26920 steps  and the cls_loss is : tensor(0.3527, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001302759377237888
now it is 26940 steps  and the cls_loss is : tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012985652884802278
now it is 26960 steps  and the cls_loss is : tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012943728029963504
now it is 26980 steps  and the cls_loss is : tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001290181954152903
now it is 27000 steps  and the cls_loss is : tensor(0.0567, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012859927753035086
now it is 27020 steps  and the cls_loss is : tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012818052997884976
now it is 27040 steps  and the cls_loss is : tensor(0.1194, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012776195609346473
now it is 27060 steps  and the cls_loss is : tensor(0.0848, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012734355920549095
now it is 27080 steps  and the cls_loss is : tensor(0.1078, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001269253426448153
now it is 27100 steps  and the cls_loss is : tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012650730973988921
now it is 27120 steps  and the cls_loss is : tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001260894638177026
now it is 27140 steps  and the cls_loss is : tensor(0.0771, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012567180820375725
now it is 27160 steps  and the cls_loss is : tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012525434622204033
now it is 27180 steps  and the cls_loss is : tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001248370811949978
now it is 27200 steps  and the cls_loss is : tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012442001644350842
now it is 27220 steps  and the cls_loss is : tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012400315528685673
now it is 27240 steps  and the cls_loss is : tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012358650104270716
now it is 27260 steps  and the cls_loss is : tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012317005702707716
now it is 27280 steps  and the cls_loss is : tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001227538265543113
now it is 27300 steps  and the cls_loss is : tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001223378129370543
now it is 27320 steps  and the cls_loss is : tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012192201948622537
now it is 27340 steps  and the cls_loss is : tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012150644951099115
now it is 27360 steps  and the cls_loss is : tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012109110631874
now it is 27380 steps  and the cls_loss is : tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012067599321505511
now it is 27400 steps  and the cls_loss is : tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012026111350368874
now it is 27420 steps  and the cls_loss is : tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011984647048653542
now it is 27440 steps  and the cls_loss is : tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011943206746360608
now it is 27460 steps  and the cls_loss is : tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011901790773300143
now it is 27480 steps  and the cls_loss is : tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011860399459088615
now it is 27500 steps  and the cls_loss is : tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001181903313314621
now it is 27520 steps  and the cls_loss is : tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011777692124694274
now it is 27540 steps  and the cls_loss is : tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011736376762752623
now it is 27560 steps  and the cls_loss is : tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011695087376136996
now it is 27580 steps  and the cls_loss is : tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011653824293456373
now it is 27600 steps  and the cls_loss is : tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011612587843110409
now it is 27620 steps  and the cls_loss is : tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011571378353286783
now it is 27640 steps  and the cls_loss is : tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011530196151958631
now it is 27660 steps  and the cls_loss is : tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011489041566881879
now it is 27680 steps  and the cls_loss is : tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011447914925592686
now it is 27700 steps  and the cls_loss is : tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011406816555404795
now it is 27720 steps  and the cls_loss is : tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011365746783406976
now it is 27740 steps  and the cls_loss is : tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011324705936460366
now it is 27760 steps  and the cls_loss is : tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011283694341195922
now it is 27780 steps  and the cls_loss is : tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001124271232401177
now it is 27800 steps  and the cls_loss is : tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011201760211070658
now it is 27820 steps  and the cls_loss is : tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011160838328297317
now it is 27840 steps  and the cls_loss is : tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011119947001375912
now it is 27860 steps  and the cls_loss is : tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011079086555747385
now it is 27880 steps  and the cls_loss is : tensor(0.1017, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011038257316606935
now it is 27900 steps  and the cls_loss is : tensor(0.0724, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010997459608901388
now it is 27920 steps  and the cls_loss is : tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010956693757326623
now it is 27940 steps  and the cls_loss is : tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010915960086324977
now it is 27960 steps  and the cls_loss is : tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010875258920082691
now it is 27980 steps  and the cls_loss is : tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001083459058252729
now it is 28000 steps  and the cls_loss is : tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010793955397325047
now it is 28020 steps  and the cls_loss is : tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010753353687878366
now it is 28040 steps  and the cls_loss is : tensor(0.3298, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010712785777323246
now it is 28060 steps  and the cls_loss is : tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010672251988526672
now it is 28080 steps  and the cls_loss is : tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010631752644084086
now it is 28100 steps  and the cls_loss is : tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010591288066316776
now it is 28120 steps  and the cls_loss is : tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001055085857726936
now it is 28140 steps  and the cls_loss is : tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001051046449870717
now it is 28160 steps  and the cls_loss is : tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001047010615211374
now it is 28180 steps  and the cls_loss is : tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010429783858688206
now it is 28200 steps  and the cls_loss is : tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010389497939342772
now it is 28220 steps  and the cls_loss is : tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010349248714700162
now it is 28240 steps  and the cls_loss is : tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010309036505091052
now it is 28260 steps  and the cls_loss is : tensor(0.0742, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001026886163055153
now it is 28280 steps  and the cls_loss is : tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010228724410820537
now it is 28300 steps  and the cls_loss is : tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001018862516533735
now it is 28320 steps  and the cls_loss is : tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010148564213238998
now it is 28340 steps  and the cls_loss is : tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010108541873357767
now it is 28360 steps  and the cls_loss is : tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010068558464218624
now it is 28380 steps  and the cls_loss is : tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010028614304036711
now it is 28400 steps  and the cls_loss is : tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009988709710714784
now it is 28420 steps  and the cls_loss is : tensor(0.2050, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009948845001840727
now it is 28440 steps  and the cls_loss is : tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009909020494684958
now it is 28460 steps  and the cls_loss is : tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009869236506197985
now it is 28480 steps  and the cls_loss is : tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00098294933530078
now it is 28500 steps  and the cls_loss is : tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009789791351417438
now it is 28520 steps  and the cls_loss is : tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009750130817402387
now it is 28540 steps  and the cls_loss is : tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009710512066608135
now it is 28560 steps  and the cls_loss is : tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009670935414347609
now it is 28580 steps  and the cls_loss is : tensor(0.1837, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000963140117559871
now it is 28600 steps  and the cls_loss is : tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000959190966500176
now it is 28620 steps  and the cls_loss is : tensor(0.0771, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009552461196857043
now it is 28640 steps  and the cls_loss is : tensor(0.5177, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009513056085122259
now it is 28660 steps  and the cls_loss is : tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009473694643410075
now it is 28680 steps  and the cls_loss is : tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009434377184985578
now it is 28700 steps  and the cls_loss is : tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009395104022763824
now it is 28720 steps  and the cls_loss is : tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009355875469307312
now it is 28740 steps  and the cls_loss is : tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009316691836823533
now it is 28760 steps  and the cls_loss is : tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009277553437162448
now it is 28780 steps  and the cls_loss is : tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009238460581814048
now it is 28800 steps  and the cls_loss is : tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009199413581905825
now it is 28820 steps  and the cls_loss is : tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009160412748200338
now it is 28840 steps  and the cls_loss is : tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009121458391092724
now it is 28860 steps  and the cls_loss is : tensor(0.2121, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009082550820608221
now it is 28880 steps  and the cls_loss is : tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009043690346399708
now it is 28900 steps  and the cls_loss is : tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000900487727774525
now it is 28920 steps  and the cls_loss is : tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008966111923545608
now it is 28940 steps  and the cls_loss is : tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008927394592321823
now it is 28960 steps  and the cls_loss is : tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000888872559221271
now it is 28980 steps  and the cls_loss is : tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000885010523097246
now it is 29000 steps  and the cls_loss is : tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008811533815968128
now it is 29020 steps  and the cls_loss is : tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000877301165417726
now it is 29040 steps  and the cls_loss is : tensor(0.0630, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008734539052185384
now it is 29060 steps  and the cls_loss is : tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008696116316183611
now it is 29080 steps  and the cls_loss is : tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008657743751966177
now it is 29100 steps  and the cls_loss is : tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008619421664928023
now it is 29120 steps  and the cls_loss is : tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008581150360062351
now it is 29140 steps  and the cls_loss is : tensor(0.3276, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008542930141958214
now it is 29160 steps  and the cls_loss is : tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008504761314798072
now it is 29180 steps  and the cls_loss is : tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008466644182355388
now it is 29200 steps  and the cls_loss is : tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008428579047992198
now it is 29220 steps  and the cls_loss is : tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008390566214656713
now it is 29240 steps  and the cls_loss is : tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008352605984880869
now it is 29260 steps  and the cls_loss is : tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008314698660777988
now it is 29280 steps  and the cls_loss is : tensor(0.0586, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008276844544040292
now it is 29300 steps  and the cls_loss is : tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008239043935936583
now it is 29320 steps  and the cls_loss is : tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000820129713730976
now it is 29340 steps  and the cls_loss is : tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008163604448574518
now it is 29360 steps  and the cls_loss is : tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008125966169714863
now it is 29380 steps  and the cls_loss is : tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008088382600281804
now it is 29400 steps  and the cls_loss is : tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008050854039390916
now it is 29420 steps  and the cls_loss is : tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008013380785719989
now it is 29440 steps  and the cls_loss is : tensor(0.2176, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007975963137506633
now it is 29460 steps  and the cls_loss is : tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007938601392545922
now it is 29480 steps  and the cls_loss is : tensor(0.1181, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007901295848188
now it is 29500 steps  and the cls_loss is : tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007864046801335741
now it is 29520 steps  and the cls_loss is : tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007826854548442368
now it is 29540 steps  and the cls_loss is : tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007789719385509105
now it is 29560 steps  and the cls_loss is : tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007752641608082792
now it is 29580 steps  and the cls_loss is : tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007715621511253599
now it is 29600 steps  and the cls_loss is : tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007678659389652584
now it is 29620 steps  and the cls_loss is : tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007641755537449447
now it is 29640 steps  and the cls_loss is : tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007604910248350104
now it is 29660 steps  and the cls_loss is : tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007568123815594406
now it is 29680 steps  and the cls_loss is : tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007531396531953777
now it is 29700 steps  and the cls_loss is : tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007494728689728891
now it is 29720 steps  and the cls_loss is : tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007458120580747358
now it is 29740 steps  and the cls_loss is : tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007421572496361377
now it is 29760 steps  and the cls_loss is : tensor(0.2114, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007385084727445438
now it is 29780 steps  and the cls_loss is : tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007348657564393997
now it is 29800 steps  and the cls_loss is : tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007312291297119169
now it is 29820 steps  and the cls_loss is : tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007275986215048421
now it is 29840 steps  and the cls_loss is : tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007239742607122249
now it is 29860 steps  and the cls_loss is : tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000720356076179193
now it is 29880 steps  and the cls_loss is : tensor(0.0628, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007167440967017154
now it is 29900 steps  and the cls_loss is : tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007131383510263809
now it is 29920 steps  and the cls_loss is : tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007095388678501619
now it is 29940 steps  and the cls_loss is : tensor(0.0798, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007059456758201917
now it is 29960 steps  and the cls_loss is : tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007023588035335339
now it is 29980 steps  and the cls_loss is : tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006987782795369552
now it is 30000 steps  and the cls_loss is : tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006952041323266989
now it is 30020 steps  and the cls_loss is : tensor(0.1826, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006916363903482552
now it is 30040 steps  and the cls_loss is : tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006880750819961413
now it is 30060 steps  and the cls_loss is : tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006845202356136664
now it is 30080 steps  and the cls_loss is : tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006809718794927154
now it is 30100 steps  and the cls_loss is : tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006774300418735153
now it is 30120 steps  and the cls_loss is : tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006738947509444183
now it is 30140 steps  and the cls_loss is : tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006703660348416703
now it is 30160 steps  and the cls_loss is : tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006668439216491919
now it is 30180 steps  and the cls_loss is : tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000663328439398353
now it is 30200 steps  and the cls_loss is : tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006598196160677502
now it is 30220 steps  and the cls_loss is : tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006563174795829834
now it is 30240 steps  and the cls_loss is : tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006528220578164341
now it is 30260 steps  and the cls_loss is : tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006493333785870441
now it is 30280 steps  and the cls_loss is : tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006458514696600925
now it is 30300 steps  and the cls_loss is : tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006423763587469768
now it is 30320 steps  and the cls_loss is : tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006389080735049914
now it is 30340 steps  and the cls_loss is : tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006354466415371046
now it is 30360 steps  and the cls_loss is : tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006319920903917463
now it is 30380 steps  and the cls_loss is : tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006285444475625796
now it is 30400 steps  and the cls_loss is : tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006251037404882908
now it is 30420 steps  and the cls_loss is : tensor(0.1326, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006216699965523624
now it is 30440 steps  and the cls_loss is : tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006182432430828638
now it is 30460 steps  and the cls_loss is : tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006148235073522257
now it is 30480 steps  and the cls_loss is : tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006114108165770293
now it is 30500 steps  and the cls_loss is : tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006080051979177861
now it is 30520 steps  and the cls_loss is : tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006046066784787239
now it is 30540 steps  and the cls_loss is : tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006012152853075691
now it is 30560 steps  and the cls_loss is : tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005978310453953332
now it is 30580 steps  and the cls_loss is : tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005944539856760964
now it is 30600 steps  and the cls_loss is : tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005910841330267945
now it is 30620 steps  and the cls_loss is : tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005877215142670049
now it is 30640 steps  and the cls_loss is : tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005843661561587327
now it is 30660 steps  and the cls_loss is : tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005810180854061959
now it is 30680 steps  and the cls_loss is : tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005776773286556184
now it is 30700 steps  and the cls_loss is : tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005743439124950105
now it is 30720 steps  and the cls_loss is : tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005710178634539646
now it is 30740 steps  and the cls_loss is : tensor(0.0568, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005676992080034375
now it is 30760 steps  and the cls_loss is : tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005643879725555446
now it is 30780 steps  and the cls_loss is : tensor(0.0598, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005610841834633474
now it is 30800 steps  and the cls_loss is : tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005577878670206443
now it is 30820 steps  and the cls_loss is : tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005544990494617609
now it is 30840 steps  and the cls_loss is : tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005512177569613424
now it is 30860 steps  and the cls_loss is : tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005479440156341436
now it is 30880 steps  and the cls_loss is : tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005446778515348225
now it is 30900 steps  and the cls_loss is : tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005414192906577322
now it is 30920 steps  and the cls_loss is : tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005381683589367144
now it is 30940 steps  and the cls_loss is : tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005349250822448913
now it is 30960 steps  and the cls_loss is : tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005316894863944645
now it is 30980 steps  and the cls_loss is : tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005284615971365021
now it is 31000 steps  and the cls_loss is : tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005252414401607419
now it is 31020 steps  and the cls_loss is : tensor(0.1009, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005220290410953792
now it is 31040 steps  and the cls_loss is : tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005188244255068704
now it is 31060 steps  and the cls_loss is : tensor(0.0530, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005156276188997219
now it is 31080 steps  and the cls_loss is : tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005124386467162937
now it is 31100 steps  and the cls_loss is : tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005092575343365929
now it is 31120 steps  and the cls_loss is : tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005060843070780732
now it is 31140 steps  and the cls_loss is : tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005029189901954332
now it is 31160 steps  and the cls_loss is : tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004997616088804154
now it is 31180 steps  and the cls_loss is : tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004966121882616055
now it is 31200 steps  and the cls_loss is : tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004934707534042326
now it is 31220 steps  and the cls_loss is : tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004903373293099698
now it is 31240 steps  and the cls_loss is : tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004872119409167354
now it is 31260 steps  and the cls_loss is : tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004840946130984925
now it is 31280 steps  and the cls_loss is : tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004809853706650558
now it is 31300 steps  and the cls_loss is : tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047788423836188723
now it is 31320 steps  and the cls_loss is : tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004747912408699064
now it is 31340 steps  and the cls_loss is : tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047170640280528773
now it is 31360 steps  and the cls_loss is : tensor(0.3662, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004686297487192689
now it is 31380 steps  and the cls_loss is : tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00046556130309795344
now it is 31400 steps  and the cls_loss is : tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004625010903621166
now it is 31420 steps  and the cls_loss is : tensor(0.1064, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00045944913486701064
now it is 31440 steps  and the cls_loss is : tensor(0.0490, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004564054609021707
now it is 31460 steps  and the cls_loss is : tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00045337009269122257
now it is 31480 steps  and the cls_loss is : tensor(0.0688, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00045034305439168866
now it is 31500 steps  and the cls_loss is : tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00044732437009479647
now it is 31520 steps  and the cls_loss is : tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00044431406382528714
now it is 31540 steps  and the cls_loss is : tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00044131215954122183
now it is 31560 steps  and the cls_loss is : tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004383186811337964
now it is 31580 steps  and the cls_loss is : tensor(0.1079, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00043533365242714425
now it is 31600 steps  and the cls_loss is : tensor(0.0867, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004323570971781535
now it is 31620 steps  and the cls_loss is : tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00042938903907627164
now it is 31640 steps  and the cls_loss is : tensor(0.0605, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00042642950174332325
now it is 31660 steps  and the cls_loss is : tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004234785087333163
now it is 31680 steps  and the cls_loss is : tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00042053608353225826
now it is 31700 steps  and the cls_loss is : tensor(0.1101, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00041760224955796836
now it is 31720 steps  and the cls_loss is : tensor(0.1606, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004146770301598906
now it is 31740 steps  and the cls_loss is : tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004117604486189089
now it is 31760 steps  and the cls_loss is : tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00040885252814715965
now it is 31780 steps  and the cls_loss is : tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00040595329188785153
now it is 31800 steps  and the cls_loss is : tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004030627629150745
now it is 31820 steps  and the cls_loss is : tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00040018096423362424
now it is 31840 steps  and the cls_loss is : tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003973079187788109
now it is 31860 steps  and the cls_loss is : tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003944436494162832
now it is 31880 steps  and the cls_loss is : tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00039158817894184247
now it is 31900 steps  and the cls_loss is : tensor(0.5032, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003887415300812632
now it is 31920 steps  and the cls_loss is : tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003859037254901108
now it is 31940 steps  and the cls_loss is : tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00038307478775356253
now it is 31960 steps  and the cls_loss is : tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003802547393862272
now it is 31980 steps  and the cls_loss is : tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003774436028319656
now it is 32000 steps  and the cls_loss is : tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037464140046371226
now it is 32020 steps  and the cls_loss is : tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037184815458329835
now it is 32040 steps  and the cls_loss is : tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00036906388742127095
now it is 32060 steps  and the cls_loss is : tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00036628862113672163
now it is 32080 steps  and the cls_loss is : tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003635223778171035
now it is 32100 steps  and the cls_loss is : tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000360765179478062
now it is 32120 steps  and the cls_loss is : tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00035801704806325316
now it is 32140 steps  and the cls_loss is : tensor(0.2713, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000355278005444176
now it is 32160 steps  and the cls_loss is : tensor(0.0741, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003525480734199908
now it is 32180 steps  and the cls_loss is : tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00034982727371735253
now it is 32200 steps  and the cls_loss is : tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00034711562799023344
now it is 32220 steps  and the cls_loss is : tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00034441315781975294
now it is 32240 steps  and the cls_loss is : tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003417198847140046
now it is 32260 steps  and the cls_loss is : tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003390358301078858
now it is 32280 steps  and the cls_loss is : tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003363610153629268
now it is 32300 steps  and the cls_loss is : tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003336954617671207
now it is 32320 steps  and the cls_loss is : tensor(0.0702, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033103919053475414
now it is 32340 steps  and the cls_loss is : tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003283922228062388
now it is 32360 steps  and the cls_loss is : tensor(0.3684, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003257545796479409
now it is 32380 steps  and the cls_loss is : tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003231262820520187
now it is 32400 steps  and the cls_loss is : tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003205073509362486
now it is 32420 steps  and the cls_loss is : tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031789780714386534
now it is 32440 steps  and the cls_loss is : tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003152976714433904
now it is 32460 steps  and the cls_loss is : tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031270696452847065
now it is 32480 steps  and the cls_loss is : tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003101257070177121
now it is 32500 steps  and the cls_loss is : tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030755391945451547
now it is 32520 steps  and the cls_loss is : tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000304991622306914
now it is 32540 steps  and the cls_loss is : tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003024388359674092
now it is 32560 steps  and the cls_loss is : tensor(0.2263, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000299895580752809
now it is 32580 steps  and the cls_loss is : tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00029736187690406683
now it is 32600 steps  and the cls_loss is : tensor(0.0524, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00029483774458611905
now it is 32620 steps  and the cls_loss is : tensor(0.0832, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002923232038877262
now it is 32640 steps  and the cls_loss is : tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002898182748213107
now it is 32660 steps  and the cls_loss is : tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00028732297732280115
now it is 32680 steps  and the cls_loss is : tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002848373312514691
now it is 32700 steps  and the cls_loss is : tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00028236135638977654
now it is 32720 steps  and the cls_loss is : tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00027989507244321197
now it is 32740 steps  and the cls_loss is : tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00027743849904014034
now it is 32760 steps  and the cls_loss is : tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002749916557316408
now it is 32780 steps  and the cls_loss is : tensor(0.0839, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002725545619913552
now it is 32800 steps  and the cls_loss is : tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00027012723721533147
now it is 32820 steps  and the cls_loss is : tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002677097007218693
now it is 32840 steps  and the cls_loss is : tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002653019717513669
now it is 32860 steps  and the cls_loss is : tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00026290406946616714
now it is 32880 steps  and the cls_loss is : tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002605160129504057
now it is 32900 steps  and the cls_loss is : tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00025813782120985893
now it is 32920 steps  and the cls_loss is : tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00025576951317179253
now it is 32940 steps  and the cls_loss is : tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00025341110768481136
now it is 32960 steps  and the cls_loss is : tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002510626235187076
now it is 32980 steps  and the cls_loss is : tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002487240793643153
now it is 33000 steps  and the cls_loss is : tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002463954938333564
now it is 33020 steps  and the cls_loss is : tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00024407688545829807
now it is 33040 steps  and the cls_loss is : tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002417682726922002
now it is 33060 steps  and the cls_loss is : tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00023946967390857195
now it is 33080 steps  and the cls_loss is : tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002371811074012243
now it is 33100 steps  and the cls_loss is : tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00023490259138412453
now it is 33120 steps  and the cls_loss is : tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00023263414399125106
now it is 33140 steps  and the cls_loss is : tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002303757832764495
now it is 33160 steps  and the cls_loss is : tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00022812752721328906
now it is 33180 steps  and the cls_loss is : tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00022588939369491915
now it is 33200 steps  and the cls_loss is : tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00022366140053392653
now it is 33220 steps  and the cls_loss is : tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00022144356546219534
now it is 33240 steps  and the cls_loss is : tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00021923590613076276
now it is 33260 steps  and the cls_loss is : tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002170384401096833
now it is 33280 steps  and the cls_loss is : tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002148511848878829
now it is 33300 steps  and the cls_loss is : tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002126741578730265
now it is 33320 steps  and the cls_loss is : tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00021050737639137257
now it is 33340 steps  and the cls_loss is : tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00020835085768764185
now it is 33360 steps  and the cls_loss is : tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00020620461892487436
now it is 33380 steps  and the cls_loss is : tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0002040686771842969
now it is 33400 steps  and the cls_loss is : tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000201943049465185
now it is 33420 steps  and the cls_loss is : tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00019982775268472807
now it is 33440 steps  and the cls_loss is : tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00019772280367789596
now it is 33460 steps  and the cls_loss is : tensor(0.1107, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00019562821919730155
now it is 33480 steps  and the cls_loss is : tensor(0.0495, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00019354401591307294
now it is 33500 steps  and the cls_loss is : tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001914702104127145
now it is 33520 steps  and the cls_loss is : tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00018940681920098088
now it is 33540 steps  and the cls_loss is : tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00018735385869974024
now it is 33560 steps  and the cls_loss is : tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001853113452478475
now it is 33580 steps  and the cls_loss is : tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00018327929510101237
now it is 33600 steps  and the cls_loss is : tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00018125772443167067
now it is 33620 steps  and the cls_loss is : tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00017924664932885534
now it is 33640 steps  and the cls_loss is : tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001772460857980684
now it is 33660 steps  and the cls_loss is : tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00017525604976115382
now it is 33680 steps  and the cls_loss is : tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00017327655705617044
now it is 33700 steps  and the cls_loss is : tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00017130762343726602
now it is 33720 steps  and the cls_loss is : tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00016934926457455276
now it is 33740 steps  and the cls_loss is : tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00016740149605397968
now it is 33760 steps  and the cls_loss is : tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00016546433337721368
now it is 33780 steps  and the cls_loss is : tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00016353779196151032
now it is 33800 steps  and the cls_loss is : tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00016162188713959595
now it is 33820 steps  and the cls_loss is : tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00015971663415954228
now it is 33840 steps  and the cls_loss is : tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001578220481846478
now it is 33860 steps  and the cls_loss is : tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001559381442933141
now it is 33880 steps  and the cls_loss is : tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00015406493747892894
now it is 33900 steps  and the cls_loss is : tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00015220244264974473
now it is 33920 steps  and the cls_loss is : tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00015035067462876073
now it is 33940 steps  and the cls_loss is : tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00014850964815360502
now it is 33960 steps  and the cls_loss is : tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00014667937787641726
now it is 33980 steps  and the cls_loss is : tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00014485987836373177
now it is 34000 steps  and the cls_loss is : tensor(0.0533, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00014305116409636215
now it is 34020 steps  and the cls_loss is : tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00014125324946928514
now it is 34040 steps  and the cls_loss is : tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00013946614879152748
now it is 34060 steps  and the cls_loss is : tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00013768987628604956
now it is 34080 steps  and the cls_loss is : tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00013592444608963615
now it is 34100 steps  and the cls_loss is : tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00013416987225277913
now it is 34120 steps  and the cls_loss is : tensor(0.2351, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00013242616873957014
now it is 34140 steps  and the cls_loss is : tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00013069334942758596
now it is 34160 steps  and the cls_loss is : tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0001289714281077799
now it is 34180 steps  and the cls_loss is : tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00012726041848437223
now it is 34200 steps  and the cls_loss is : tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00012556033417473997
now it is 34220 steps  and the cls_loss is : tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00012387118870930877
now it is 34240 steps  and the cls_loss is : tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00012219299553144648
now it is 34260 steps  and the cls_loss is : tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00012052576799735434
now it is 34280 steps  and the cls_loss is : tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00011886951937596178
now it is 34300 steps  and the cls_loss is : tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00011722426284882088
now it is 34320 steps  and the cls_loss is : tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00011559001151000116
now it is 34340 steps  and the cls_loss is : tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00011396677836598432
now it is 34360 steps  and the cls_loss is : tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00011235457633556353
now it is 34380 steps  and the cls_loss is : tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00011075341824973725
now it is 34400 steps  and the cls_loss is : tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00010916331685161015
now it is 34420 steps  and the cls_loss is : tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00010758428479628862
now it is 34440 steps  and the cls_loss is : tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00010601633465078379
now it is 34460 steps  and the cls_loss is : tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00010445947889390718
now it is 34480 steps  and the cls_loss is : tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00010291372991617533
now it is 34500 steps  and the cls_loss is : tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00010137910001970857
now it is 34520 steps  and the cls_loss is : tensor(0.0821, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.985560141813438e-05
now it is 34540 steps  and the cls_loss is : tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.834324623648964e-05
now it is 34560 steps  and the cls_loss is : tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.684204651112476e-05
now it is 34580 steps  and the cls_loss is : tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.535201418960703e-05
now it is 34600 steps  and the cls_loss is : tensor(0.0731, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.38731611306259e-05
now it is 34620 steps  and the cls_loss is : tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.240549910389906e-05
now it is 34640 steps  and the cls_loss is : tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.094903979007797e-05
now it is 34660 steps  and the cls_loss is : tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.950379478065518e-05
now it is 34680 steps  and the cls_loss is : tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.806977557787296e-05
now it is 34700 steps  and the cls_loss is : tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.664699359462985e-05
now it is 34720 steps  and the cls_loss is : tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.523546015439246e-05
now it is 34740 steps  and the cls_loss is : tensor(0.0815, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.38351864911022e-05
now it is 34760 steps  and the cls_loss is : tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.244618374908844e-05
now it is 34780 steps  and the cls_loss is : tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.106846298297888e-05
now it is 34800 steps  and the cls_loss is : tensor(0.0669, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.970203515761136e-05
now it is 34820 steps  and the cls_loss is : tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.834691114794695e-05
now it is 34840 steps  and the cls_loss is : tensor(0.0509, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.700310173898336e-05
now it is 34860 steps  and the cls_loss is : tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.56706176256689e-05
now it is 34880 steps  and the cls_loss is : tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.434946941281738e-05
now it is 34900 steps  and the cls_loss is : tensor(0.0858, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.303966761502402e-05
now it is 34920 steps  and the cls_loss is : tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.174122265658137e-05
now it is 34940 steps  and the cls_loss is : tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.045414487139681e-05
now it is 34960 steps  and the cls_loss is : tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.917844450290984e-05
now it is 34980 steps  and the cls_loss is : tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.791413170401014e-05
now it is 35000 steps  and the cls_loss is : tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.666121653695912e-05
now it is 35020 steps  and the cls_loss is : tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.541970897330581e-05
now it is 35040 steps  and the cls_loss is : tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.418961889381195e-05
now it is 35060 steps  and the cls_loss is : tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.29709560883694e-05
now it is 35080 steps  and the cls_loss is : tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.176373025592515e-05
now it is 35100 steps  and the cls_loss is : tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.0567951004402545e-05
now it is 35120 steps  and the cls_loss is : tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.938362785062547e-05
now it is 35140 steps  and the cls_loss is : tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.821077022024224e-05
now it is 35160 steps  and the cls_loss is : tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.7049387447650286e-05
now it is 35180 steps  and the cls_loss is : tensor(0.0559, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.589948877592348e-05
now it is 35200 steps  and the cls_loss is : tensor(0.0669, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.476108335673623e-05
now it is 35220 steps  and the cls_loss is : tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.3634180250292856e-05
now it is 35240 steps  and the cls_loss is : tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.2518788425253504e-05
now it is 35260 steps  and the cls_loss is : tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.141491675866433e-05
now it is 35280 steps  and the cls_loss is : tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.032257403588609e-05
now it is 35300 steps  and the cls_loss is : tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.924176895052436e-05
now it is 35320 steps  and the cls_loss is : tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.8172510104360416e-05
now it is 35340 steps  and the cls_loss is : tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.711480600728245e-05
now it is 35360 steps  and the cls_loss is : tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.606866507721849e-05
now it is 35380 steps  and the cls_loss is : tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.50340956400689e-05
now it is 35400 steps  and the cls_loss is : tensor(0.0734, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.401110592964e-05
now it is 35420 steps  and the cls_loss is : tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.299970408757923e-05
now it is 35440 steps  and the cls_loss is : tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.199989816330938e-05
now it is 35460 steps  and the cls_loss is : tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.1011696113965527e-05
now it is 35480 steps  and the cls_loss is : tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.003510580433067e-05
now it is 35500 steps  and the cls_loss is : tensor(0.1728, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.90701350067745e-05
now it is 35520 steps  and the cls_loss is : tensor(0.1243, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.811679140118979e-05
now it is 35540 steps  and the cls_loss is : tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.717508257493325e-05
now it is 35560 steps  and the cls_loss is : tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.624501602276324e-05
now it is 35580 steps  and the cls_loss is : tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.532659914678117e-05
now it is 35600 steps  and the cls_loss is : tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.441983925637273e-05
now it is 35620 steps  and the cls_loss is : tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.3524743568149225e-05
now it is 35640 steps  and the cls_loss is : tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.2641319205890156e-05
now it is 35660 steps  and the cls_loss is : tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.176957320048708e-05
now it is 35680 steps  and the cls_loss is : tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.090951248988702e-05
now it is 35700 steps  and the cls_loss is : tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.006114391903713e-05
now it is 35720 steps  and the cls_loss is : tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.9224474239831277e-05
now it is 35740 steps  and the cls_loss is : tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.8399510111055224e-05
now it is 35760 steps  and the cls_loss is : tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.758625809833354e-05
now it is 35780 steps  and the cls_loss is : tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.6784724674079106e-05
now it is 35800 steps  and the cls_loss is : tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.5994916217438678e-05
now it is 35820 steps  and the cls_loss is : tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.5216839014245253e-05
now it is 35840 steps  and the cls_loss is : tensor(0.0541, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.4450499256965625e-05
now it is 35860 steps  and the cls_loss is : tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.369590304465206e-05
now it is 35880 steps  and the cls_loss is : tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.2953056382894205e-05
now it is 35900 steps  and the cls_loss is : tensor(0.0735, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.2221965183770435e-05
now it is 35920 steps  and the cls_loss is : tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.1502635265801062e-05
now it is 35940 steps  and the cls_loss is : tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.0795072353902722e-05
now it is 35960 steps  and the cls_loss is : tensor(0.0851, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.0099282079341386e-05
now it is 35980 steps  and the cls_loss is : tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.941526997968909e-05
now it is 36000 steps  and the cls_loss is : tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.874304149877894e-05
now it is 36020 steps  and the cls_loss is : tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.8082601986661685e-05
now it is 36040 steps  and the cls_loss is : tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.7433956699563714e-05
now it is 36060 steps  and the cls_loss is : tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.679711079984511e-05
now it is 36080 steps  and the cls_loss is : tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.617206935595819e-05
now it is 36100 steps  and the cls_loss is : tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.555883734240735e-05
now it is 36120 steps  and the cls_loss is : tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.495741963970961e-05
now it is 36140 steps  and the cls_loss is : tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.436782103435598e-05
now it is 36160 steps  and the cls_loss is : tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.379004621877232e-05
now it is 36180 steps  and the cls_loss is : tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.3224099791283368e-05
now it is 36200 steps  and the cls_loss is : tensor(0.0561, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.2669986256075445e-05
now it is 36220 steps  and the cls_loss is : tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.2127710023160308e-05
now it is 36240 steps  and the cls_loss is : tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.1597275408340852e-05
now it is 36260 steps  and the cls_loss is : tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.107868663317613e-05
now it is 36280 steps  and the cls_loss is : tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.0571947824948055e-05
now it is 36300 steps  and the cls_loss is : tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.0077063016628093e-05
now it is 36320 steps  and the cls_loss is : tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.594036146845945e-06
now it is 36340 steps  and the cls_loss is : tensor(0.4302, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  9.122871059857753e-06
now it is 36360 steps  and the cls_loss is : tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.663571505515116e-06
now it is 36380 steps  and the cls_loss is : tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.216141139236283e-06
now it is 36400 steps  and the cls_loss is : tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.780583521975846e-06
now it is 36420 steps  and the cls_loss is : tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.3569021201975915e-06
now it is 36440 steps  and the cls_loss is : tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.945100305845525e-06
now it is 36460 steps  and the cls_loss is : tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.54518135631856e-06
now it is 36480 steps  and the cls_loss is : tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.157148454443539e-06
now it is 36500 steps  and the cls_loss is : tensor(0.0560, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.781004688449589e-06
now it is 36520 steps  and the cls_loss is : tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.416753051944635e-06
now it is 36540 steps  and the cls_loss is : tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.064396443890762e-06
now it is 36560 steps  and the cls_loss is : tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.723937668580891e-06
now it is 36580 steps  and the cls_loss is : tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.395379435617637e-06
now it is 36600 steps  and the cls_loss is : tensor(0.6260, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.078724359890492e-06
now it is 36620 steps  and the cls_loss is : tensor(0.0821, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.7739749615558377e-06
now it is 36640 steps  and the cls_loss is : tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.4811336660163024e-06
now it is 36660 steps  and the cls_loss is : tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.200202803901936e-06
now it is 36680 steps  and the cls_loss is : tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.9311846110512283e-06
now it is 36700 steps  and the cls_loss is : tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.6740812284941248e-06
now it is 36720 steps  and the cls_loss is : tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.4288947024337044e-06
now it is 36740 steps  and the cls_loss is : tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.195626984231194e-06
now it is 36760 steps  and the cls_loss is : tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.9742799303893147e-06
now it is 36780 steps  and the cls_loss is : tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.764855302538626e-06
now it is 36800 steps  and the cls_loss is : tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.567354767422205e-06
now it is 36820 steps  and the cls_loss is : tensor(0.0636, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.381779896883989e-06
now it is 36840 steps  and the cls_loss is : tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.2081321678544543e-06
now it is 36860 steps  and the cls_loss is : tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.0464129623402909e-06
now it is 36880 steps  and the cls_loss is : tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.966235674130781e-07
now it is 36900 steps  and the cls_loss is : tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  7.587651751984601e-07
now it is 36920 steps  and the cls_loss is : tensor(0.0658, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  6.328388828669869e-07
now it is 36940 steps  and the cls_loss is : tensor(0.0951, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.188456926259544e-07
now it is 36960 steps  and the cls_loss is : tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  4.1678651171041115e-07
now it is 36980 steps  and the cls_loss is : tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.2666215237683047e-07
now it is 37000 steps  and the cls_loss is : tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  2.484733318959494e-07
now it is 37020 steps  and the cls_loss is : tensor(0.1255, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.8222067254744018e-07
now it is 37040 steps  and the cls_loss is : tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  1.2790470161541325e-07
now it is 37060 steps  and the cls_loss is : tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  8.55258513827555e-08
now it is 37080 steps  and the cls_loss is : tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  5.5084459129464965e-08
now it is 37100 steps  and the cls_loss is : tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.6580767128653965e-08
now it is 37120 steps  and the cls_loss is : tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  3.0014922645549944e-08
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.24841992099608243
generate label finished(10.19/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:95.75, 92.48, 87.14
bev  AP:91.62, 87.95, 82.94
3d   AP:87.98, 78.12, 72.86
aos  AP:95.57, 91.70, 86.16
Car AP@0.70, 0.50, 0.50:
bbox AP:95.75, 92.48, 87.14
bev  AP:95.81, 94.94, 89.78
3d   AP:95.80, 94.62, 89.56
aos  AP:95.57, 91.70, 86.16

