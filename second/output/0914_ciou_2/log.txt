model: {
  second: {
    voxel_generator {
      point_cloud_range : [0, -39.68, -3, 69.12, 39.68, 1]
      voxel_size : [0.16, 0.16, 4]
      max_number_of_points_per_voxel : 100
    }
    num_class: 1
    voxel_feature_extractor: {
      module_class_name: "PillarFeatureNet"
      num_filters: [64]
      with_distance: false
    }
    middle_feature_extractor: {
      module_class_name: "PointPillarsScatter"
    }
    rpn: {
      module_class_name: "RPN"
      layer_nums: [3, 5, 5]
      layer_strides: [2, 2, 2]
      num_filters: [64, 128, 256]
      upsample_strides: [1, 2, 4]
      num_upsample_filters: [128, 128, 128]
      use_groupnorm: false
      num_groups: 32
    }
    loss: {
      classification_loss: {
        weighted_sigmoid_focal: {
          alpha: 0.25
          gamma: 2.0
          anchorwise_output: true
        }
      }
      localization_loss: {
        weighted_smooth_l1: {
          sigma: 3.0
          code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
        }
      }
      classification_weight: 1.0
      localization_weight: 2.0
    }
    # Outputs
    use_sigmoid_score: true
    encode_background_as_zeros: true
    encode_rad_error_by_sin: true

    use_direction_classifier: true
    direction_loss_weight: 0.2
    use_aux_classifier: false
    # Loss
    pos_class_weight: 1.0
    neg_class_weight: 1.0

    loss_norm_type: NormByNumPositives
    # Postprocess
    post_center_limit_range: [0, -39.68, -5, 69.12, 39.68, 5]
    use_rotate_nms: false
    use_multi_class_nms: false
    nms_pre_max_size: 1000
    nms_post_max_size: 100             #MX original pp 300 CLOCs 100
    nms_score_threshold: 0.2           #MX original pp 0.05 CLOCs 0.2       #score 0.2, iou 0.5时效果最好
    nms_iou_threshold: 0.5            #MX original pp 0.5 CLOCs 0.01

    use_bev: false
    num_point_features: 4
    without_reflectivity: false
    box_coder: {
      ground_box3d_coder: {
        linear_dim: false
        encode_angle_vector: false
      }
    }
    target_assigner: {
      anchor_generators: {
         anchor_generator_stride: {
           sizes: [1.6, 3.9, 1.56] # wlh
           strides: [0.32, 0.32, 0.0] # if generate only 1 z_center, z_stride will be ignored   #MX这里可以调整anchor密度
           offsets: [0.16, -39.52, -1.78] # origin_offset + strides / 2
           rotations: [0, 1.57] # 0, pi/2
           matched_threshold : 0.6
           unmatched_threshold : 0.45
         }
       }

      sample_positive_fraction : -1
      sample_size : 512
      region_similarity_calculator: {
        nearest_iou_similarity: {
        }
      }
    }
  }
}


train_input_reader: {
  #record_file_path: "/mengxing/Data/Sets/kitti_pointpillars/kitti_train.tfrecord"
  class_names: ["Car"]
  max_num_epochs : 160
  batch_size: 1                 #2
  prefetch_size : 25
  max_number_of_voxels: 12000
  shuffle_points: true
  num_workers: 8    #2
  groundtruth_localization_noise_std: [0.25, 0.25, 0.25]                #MX？？
  groundtruth_rotation_uniform_noise: [-0.15707963267, 0.15707963267]
  global_rotation_uniform_noise: [-0.78539816, 0.78539816]
  global_scaling_uniform_noise: [0.95, 1.05]
  global_random_rotation_range_per_object: [0, 0]
  anchor_area_threshold: -1              #注意：pointpillars中为1，SECOND与CLOCs中为-1.置-1，使example['anchors_mask']=None #MX：与preprocess.py中代码关联,>0的条件
  remove_points_after_sample: false
  groundtruth_points_drop_percentage: 0.0
  groundtruth_drop_max_keep_points: 15
  database_sampler {
    database_info_path: "/home/lunhengsheng/CLOCs/kitti/kitti_dbinfos_train.pkl"
    sample_groups {
      name_to_max_num {
        key: "Car"
        value: 15
      }
    }
    database_prep_steps {
      filter_by_min_num_points {
        min_num_point_pairs {
          key: "Car"
          value: 5
        }
      }
    }
    database_prep_steps {
      filter_by_difficulty {
        removed_difficulties: [-1]
      }
    }
    global_random_rotation_range_per_object: [0, 0]
    rate: 1.0
  }

  remove_unknown_examples: false
  remove_environment: false
  kitti_info_path: "/home/lunhengsheng/CLOCs/kitti/kitti_infos_train.pkl"
  kitti_root_path: "/home/lunhengsheng/CLOCs/kitti"
}

train_config: {
  #optimizer: {
  #  adam_optimizer: {
  #    learning_rate: {
  #      exponential_decay_learning_rate: {
  #        initial_learning_rate: 0.0002
  #        decay_steps: 27840 # 1856 steps per epoch * 15 epochs
  #        decay_factor: 0.8
  #        staircase: true
  #      }
  #    }
  #    weight_decay: 0.0001
  #  }
  # use_moving_average: false
  #}

  optimizer: {
    adam_optimizer: {
      learning_rate: {
        one_cycle: {
          lr_max: 3e-3  # original 3e-3
          moms: [0.95, 0.85]
          div_factor: 10.0  #original 10
          pct_start: 0.4
        }
      }
      weight_decay: 0.01 # super converge. decrease this when you increase steps. og 0.01
    }
    fixed_weight_decay: true
    use_moving_average: false
  }

  inter_op_parallelism_threads: 4
  steps: 37120 #112215 #113715 #111360 # 619 * 50, super converge. increase this to achieve slightly better results original 30950
  steps_per_eval: 3712 #7424 #3712 #MX3712 #7481 # 619 * 5
  save_checkpoints_secs : 1800 # half hour 1800
  save_summary_steps : 10
  enable_mixed_precision: false # for fp16 training, don't use this.
  loss_scale_factor : 512.0
  clear_metrics_every_epoch: true
  #detection_2d_path: "../d2_detection_data"         #MX
}

eval_input_reader: {
  #record_file_path: "/mengxing/Data/Sets/kitti_pointpillars/kitti_val.tfrecord"
  class_names: ["Car"]
  batch_size: 1                 #2
  max_num_epochs : 160
  prefetch_size : 25
  max_number_of_voxels: 12000
  shuffle_points: false
  num_workers: 3
  anchor_area_threshold: -1          #注意：pointpillars中为1，SECOND与CLOCs中为-1.置-1，使example['anchors_mask']=None #MX：与preprocess.py中代码关联,>0的条件
  remove_environment: false
  kitti_info_path: "/home/lunhengsheng/CLOCs/kitti/kitti_infos_val.pkl"
  kitti_root_path: "/home/lunhengsheng/CLOCs/kitti"
}

now it is 20 steps  and the cls_loss is : tensor(892.3116, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003000109113384191
now it is 40 steps  and the cls_loss is : tensor(1232.4878, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030004596412464566
now it is 60 steps  and the cls_loss is : tensor(887.8149, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003001051905568235
now it is 80 steps  and the cls_loss is : tensor(470.9664, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030018858957438265
now it is 100 steps  and the cls_loss is : tensor(547.4501, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000300296159683897
now it is 120 steps  and the cls_loss is : tensor(813.8798, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030042789895910705
now it is 140 steps  and the cls_loss is : tensor(600.4748, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000300583805040955
now it is 160 steps  and the cls_loss is : tensor(368.6166, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030076387513762936
now it is 180 steps  and the cls_loss is : tensor(277.1927, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030096810602461225
now it is 200 steps  and the cls_loss is : tensor(367.6233, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003011964940447371
now it is 220 steps  and the cls_loss is : tensor(379.1955, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030144903510825796
now it is 240 steps  and the cls_loss is : tensor(278.4548, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030172572469291774
now it is 260 steps  and the cls_loss is : tensor(393.6430, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030202655784403306
now it is 280 steps  and the cls_loss is : tensor(509.7938, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030235152917457934
now it is 300 steps  and the cls_loss is : tensor(175.7337, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003027006328652909
now it is 320 steps  and the cls_loss is : tensor(176.2066, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030307386266476347
now it is 340 steps  and the cls_loss is : tensor(246.4443, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003034712118895654
now it is 360 steps  and the cls_loss is : tensor(126.5900, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030389267342435843
now it is 380 steps  and the cls_loss is : tensor(309.3114, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000304338239722026
now it is 400 steps  and the cls_loss is : tensor(94.4622, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003048079028038046
now it is 420 steps  and the cls_loss is : tensor(107.9380, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030530165425943223
now it is 440 steps  and the cls_loss is : tensor(84.7401, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030581948524729475
now it is 460 steps  and the cls_loss is : tensor(53.8629, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003063613864945844
now it is 480 steps  and the cls_loss is : tensor(69.0523, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003069273482974688
now it is 500 steps  and the cls_loss is : tensor(68.7735, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003075173605212619
now it is 520 steps  and the cls_loss is : tensor(115.7083, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003081314126006066
now it is 540 steps  and the cls_loss is : tensor(29.1777, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030876949353966354
now it is 560 steps  and the cls_loss is : tensor(40.5993, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00030943159191230887
now it is 580 steps  and the cls_loss is : tensor(51.4381, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031011769586233775
now it is 600 steps  and the cls_loss is : tensor(31.7059, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000310827793103677
now it is 620 steps  and the cls_loss is : tensor(17.0708, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003115618709206053
now it is 640 steps  and the cls_loss is : tensor(20.5872, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031231991616798103
now it is 660 steps  and the cls_loss is : tensor(13.3344, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003131019152714785
now it is 680 steps  and the cls_loss is : tensor(9.3262, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031390785422782735
now it is 700 steps  and the cls_loss is : tensor(11.7118, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003147377186050681
now it is 720 steps  and the cls_loss is : tensor(1.7734, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003155914935428078
now it is 740 steps  and the cls_loss is : tensor(8.4330, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031646916375248704
now it is 760 steps  and the cls_loss is : tensor(10.4548, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003173707135176525
now it is 780 steps  and the cls_loss is : tensor(3.0033, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031829612669424107
now it is 800 steps  and the cls_loss is : tensor(6.5264, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00031924538671086484
now it is 820 steps  and the cls_loss is : tensor(6.6717, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000320218476569112
now it is 840 steps  and the cls_loss is : tensor(1.1503, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032121537884384965
now it is 860 steps  and the cls_loss is : tensor(4.3691, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032223607568353414
now it is 880 steps  and the cls_loss is : tensor(3.7846, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032328054881053305
now it is 900 steps  and the cls_loss is : tensor(3.5934, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003243487795214512
now it is 920 steps  and the cls_loss is : tensor(1.8055, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032544074868746725
now it is 940 steps  and the cls_loss is : tensor(1.9649, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00032655643675467364
now it is 960 steps  and the cls_loss is : tensor(1.9388, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003276958237444288
now it is 980 steps  and the cls_loss is : tensor(2.1701, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003288588892537141
now it is 1000 steps  and the cls_loss is : tensor(1.5217, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003300456124554988
now it is 1020 steps  and the cls_loss is : tensor(1.9681, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033125597209911466
now it is 1040 steps  and the cls_loss is : tensor(1.1567, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033248994651063424
now it is 1060 steps  and the cls_loss is : tensor(1.6489, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003337475135932609
now it is 1080 steps  and the cls_loss is : tensor(1.3773, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033502865082772355
now it is 1100 steps  and the cls_loss is : tensor(1.6396, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033633333527267927
now it is 1120 steps  and the cls_loss is : tensor(1.3855, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033766154356512645
now it is 1140 steps  and the cls_loss is : tensor(1.1933, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00033901325192082013
now it is 1160 steps  and the cls_loss is : tensor(1.1633, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003403884361346996
now it is 1180 steps  and the cls_loss is : tensor(1.0272, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00034178707158132255
now it is 1200 steps  and the cls_loss is : tensor(1.1117, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003432091332153048
now it is 1220 steps  and the cls_loss is : tensor(0.9313, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003446545955717692
now it is 1240 steps  and the cls_loss is : tensor(0.9443, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00034612343276679966
now it is 1260 steps  and the cls_loss is : tensor(0.9282, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003476156184979099
now it is 1280 steps  and the cls_loss is : tensor(0.9342, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003491311260445081
now it is 1300 steps  and the cls_loss is : tensor(0.9474, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00035066992826837977
now it is 1320 steps  and the cls_loss is : tensor(0.8775, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00035223199761417285
now it is 1340 steps  and the cls_loss is : tensor(0.8882, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00035381730610988893
now it is 1360 steps  and the cls_loss is : tensor(0.9182, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003554258253673868
now it is 1380 steps  and the cls_loss is : tensor(0.9133, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003570575265828902
now it is 1400 steps  and the cls_loss is : tensor(0.9705, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003587123805375023
now it is 1420 steps  and the cls_loss is : tensor(0.9202, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003603903575977313
now it is 1440 steps  and the cls_loss is : tensor(0.8995, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00036209142771601727
now it is 1460 steps  and the cls_loss is : tensor(0.9243, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00036381556043127514
now it is 1480 steps  and the cls_loss is : tensor(0.8472, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003655627248694356
now it is 1500 steps  and the cls_loss is : tensor(0.8235, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003673328897440013
now it is 1520 steps  and the cls_loss is : tensor(0.8687, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003691260233566044
now it is 1540 steps  and the cls_loss is : tensor(0.8453, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037094209359757714
now it is 1560 steps  and the cls_loss is : tensor(0.9105, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037278106794652426
now it is 1580 steps  and the cls_loss is : tensor(0.9105, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003746429134729064
now it is 1600 steps  and the cls_loss is : tensor(0.8667, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037652759683663023
now it is 1620 steps  and the cls_loss is : tensor(0.8309, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00037843508428864366
now it is 1640 steps  and the cls_loss is : tensor(0.8875, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003803653416715436
now it is 1660 steps  and the cls_loss is : tensor(0.8285, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00038231833442018293
now it is 1680 steps  and the cls_loss is : tensor(0.7946, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00038429402756229476
now it is 1700 steps  and the cls_loss is : tensor(0.7996, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003862923857191132
now it is 1720 steps  and the cls_loss is : tensor(0.7441, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00038831337310601174
now it is 1740 steps  and the cls_loss is : tensor(0.7333, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003903569535331406
now it is 1760 steps  and the cls_loss is : tensor(0.7117, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00039242309040607697
now it is 1780 steps  and the cls_loss is : tensor(0.7055, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00039451174672647943
now it is 1800 steps  and the cls_loss is : tensor(0.5675, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003966228850927501
now it is 1820 steps  and the cls_loss is : tensor(0.6491, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0003987564677007038
now it is 1840 steps  and the cls_loss is : tensor(0.5245, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004009124563442482
now it is 1860 steps  and the cls_loss is : tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00040309081241606546
now it is 1880 steps  and the cls_loss is : tensor(0.5421, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004052914969083013
now it is 1900 steps  and the cls_loss is : tensor(0.5280, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00040751447041326855
now it is 1920 steps  and the cls_loss is : tensor(0.5263, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004097596931241501
now it is 1940 steps  and the cls_loss is : tensor(0.7069, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00041202712483571135
now it is 1960 steps  and the cls_loss is : tensor(0.4850, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004143167249450216
now it is 1980 steps  and the cls_loss is : tensor(0.4171, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004166284524521795
now it is 2000 steps  and the cls_loss is : tensor(0.4260, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004189622659610476
now it is 2020 steps  and the cls_loss is : tensor(0.3934, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004213181236799963
now it is 2040 steps  and the cls_loss is : tensor(0.5547, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000423695983422648
now it is 2060 steps  and the cls_loss is : tensor(0.4288, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004260958026086354
now it is 2080 steps  and the cls_loss is : tensor(0.4347, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000428517538264363
now it is 2100 steps  and the cls_loss is : tensor(0.3723, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00043096114702377607
now it is 2120 steps  and the cls_loss is : tensor(0.3839, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00043342658512913936
now it is 2140 steps  and the cls_loss is : tensor(0.3475, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00043591380843181846
now it is 2160 steps  and the cls_loss is : tensor(0.3405, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004384227723930709
now it is 2180 steps  and the cls_loss is : tensor(0.3083, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004409534320848436
now it is 2200 steps  and the cls_loss is : tensor(0.2983, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00044350574219057925
now it is 2220 steps  and the cls_loss is : tensor(0.3168, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00044607965700602407
now it is 2240 steps  and the cls_loss is : tensor(0.3308, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00044867513044005106
now it is 2260 steps  and the cls_loss is : tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00045129211601548005
now it is 2280 steps  and the cls_loss is : tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004539305668699151
now it is 2300 steps  and the cls_loss is : tensor(0.3129, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00045659043575657903
now it is 2320 steps  and the cls_loss is : tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00045927167504516324
now it is 2340 steps  and the cls_loss is : tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004619742367226792
now it is 2360 steps  and the cls_loss is : tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004646980723943153
now it is 2380 steps  and the cls_loss is : tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00046744313328431035
now it is 2400 steps  and the cls_loss is : tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047020937023682
now it is 2420 steps  and the cls_loss is : tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004729967337168011
now it is 2440 steps  and the cls_loss is : tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047580517381089595
now it is 2460 steps  and the cls_loss is : tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00047863464022833034
now it is 2480 steps  and the cls_loss is : tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000481485082301808
now it is 2500 steps  and the cls_loss is : tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00048435644898842415
now it is 2520 steps  and the cls_loss is : tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004872486888705756
now it is 2540 steps  and the cls_loss is : tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004901617501568826
now it is 2560 steps  and the cls_loss is : tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000493095580683116
now it is 2580 steps  and the cls_loss is : tensor(0.1535, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004960501279131315
now it is 2600 steps  and the cls_loss is : tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0004990253389398113
now it is 2620 steps  and the cls_loss is : tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005020211604860095
now it is 2640 steps  and the cls_loss is : tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005050375389055086
now it is 2660 steps  and the cls_loss is : tensor(0.2073, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005080744201839782
now it is 2680 steps  and the cls_loss is : tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005111317499399423
now it is 2700 steps  and the cls_loss is : tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005142094734257559
now it is 2720 steps  and the cls_loss is : tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005173075355285801
now it is 2740 steps  and the cls_loss is : tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005204258807713752
now it is 2760 steps  and the cls_loss is : tensor(0.1831, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005235644533138884
now it is 2780 steps  and the cls_loss is : tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000526723196953658
now it is 2800 steps  and the cls_loss is : tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005299020551270185
now it is 2820 steps  and the cls_loss is : tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005331009709101104
now it is 2840 steps  and the cls_loss is : tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005363198870199067
now it is 2860 steps  and the cls_loss is : tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005395587458152302
now it is 2880 steps  and the cls_loss is : tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005428174892977916
now it is 2900 steps  and the cls_loss is : tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005460960591132263
now it is 2920 steps  and the cls_loss is : tensor(0.4255, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005493943965521396
now it is 2940 steps  and the cls_loss is : tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005527124425511562
now it is 2960 steps  and the cls_loss is : tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005560501376939806
now it is 2980 steps  and the cls_loss is : tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000559407422212459
now it is 3000 steps  and the cls_loss is : tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005627842359876515
now it is 3020 steps  and the cls_loss is : tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005661805185509074
now it is 3040 steps  and the cls_loss is : tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005695962090849463
now it is 3060 steps  and the cls_loss is : tensor(0.1682, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005730312464249511
now it is 3080 steps  and the cls_loss is : tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005764855690596599
now it is 3100 steps  and the cls_loss is : tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005799591151324696
now it is 3120 steps  and the cls_loss is : tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005834518224425425
now it is 3140 steps  and the cls_loss is : tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005869636284459197
now it is 3160 steps  and the cls_loss is : tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005904944702566427
now it is 3180 steps  and the cls_loss is : tensor(0.1615, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005940442846478779
now it is 3200 steps  and the cls_loss is : tensor(0.1521, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0005976130080530494
now it is 3220 steps  and the cls_loss is : tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006012005765669783
now it is 3240 steps  and the cls_loss is : tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006048069259470246
now it is 3260 steps  and the cls_loss is : tensor(0.4963, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006084319916142399
now it is 3280 steps  and the cls_loss is : tensor(0.3764, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006120757086545236
now it is 3300 steps  and the cls_loss is : tensor(0.1829, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006157380118197828
now it is 3320 steps  and the cls_loss is : tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006194188355291047
now it is 3340 steps  and the cls_loss is : tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000623118113869928
now it is 3360 steps  and the cls_loss is : tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006268357805992233
now it is 3380 steps  and the cls_loss is : tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000630571769144681
now it is 3400 steps  and the cls_loss is : tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006343260126059026
now it is 3420 steps  and the cls_loss is : tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006380984437555984
now it is 3440 steps  and the cls_loss is : tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006418889950407904
now it is 3460 steps  and the cls_loss is : tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006456975985840254
now it is 3480 steps  and the cls_loss is : tensor(0.1790, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006495241861845854
now it is 3500 steps  and the cls_loss is : tensor(0.2150, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006533686893197138
now it is 3520 steps  and the cls_loss is : tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006572310391458388
now it is 3540 steps  and the cls_loss is : tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006611111664998094
now it is 3560 steps  and the cls_loss is : tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006650090019001305
now it is 3580 steps  and the cls_loss is : tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006689244755482093
now it is 3600 steps  and the cls_loss is : tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006728575173296052
now it is 3620 steps  and the cls_loss is : tensor(0.4707, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006768080568152835
now it is 3640 steps  and the cls_loss is : tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006807760232628796
now it is 3660 steps  and the cls_loss is : tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006847613456179625
now it is 3680 steps  and the cls_loss is : tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006887639525153099
now it is 3700 steps  and the cls_loss is : tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000692783772280184
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.19032927984356493
generate label finished(10.02/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:96.07, 93.02, 84.94
bev  AP:92.25, 86.90, 80.67
3d   AP:88.28, 79.05, 71.22
aos  AP:95.84, 92.33, 84.05
Car AP@0.70, 0.50, 0.50:
bbox AP:96.07, 93.02, 84.94
bev  AP:96.07, 95.15, 87.32
3d   AP:96.07, 93.64, 87.08
aos  AP:95.84, 92.33, 84.05

now it is 3720 steps  and the cls_loss is : tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0006968207329296166
now it is 3740 steps  and the cls_loss is : tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007008747621736968
now it is 3760 steps  and the cls_loss is : tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007049457874168672
now it is 3780 steps  and the cls_loss is : tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007090337357592213
now it is 3800 steps  and the cls_loss is : tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007131385339978124
now it is 3820 steps  and the cls_loss is : tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007172601086279603
now it is 3840 steps  and the cls_loss is : tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007213983858445714
now it is 3860 steps  and the cls_loss is : tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007255532915434581
now it is 3880 steps  and the cls_loss is : tensor(0.1824, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007297247513226657
now it is 3900 steps  and the cls_loss is : tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007339126904838062
now it is 3920 steps  and the cls_loss is : tensor(0.1590, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007381170340333954
now it is 3940 steps  and the cls_loss is : tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007423377066841938
now it is 3960 steps  and the cls_loss is : tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007465746328565587
now it is 3980 steps  and the cls_loss is : tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007508277366797926
now it is 4000 steps  and the cls_loss is : tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007550969419935082
now it is 4020 steps  and the cls_loss is : tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007593821723489848
now it is 4040 steps  and the cls_loss is : tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007636833510105442
now it is 4060 steps  and the cls_loss is : tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007680004009569192
now it is 4080 steps  and the cls_loss is : tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007723332448826372
now it is 4100 steps  and the cls_loss is : tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007766818051994011
now it is 4120 steps  and the cls_loss is : tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007810460040374814
now it is 4140 steps  and the cls_loss is : tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007854257632471085
now it is 4160 steps  and the cls_loss is : tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007898210043998737
now it is 4180 steps  and the cls_loss is : tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007942316487901321
now it is 4200 steps  and the cls_loss is : tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0007986576174364136
now it is 4220 steps  and the cls_loss is : tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008030988310828353
now it is 4240 steps  and the cls_loss is : tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008075552102005238
now it is 4260 steps  and the cls_loss is : tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008120266749890356
now it is 4280 steps  and the cls_loss is : tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008165131453777888
now it is 4300 steps  and the cls_loss is : tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008210145410274955
now it is 4320 steps  and the cls_loss is : tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008255307813316015
now it is 4340 steps  and the cls_loss is : tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008300617854177282
now it is 4360 steps  and the cls_loss is : tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008346074721491238
now it is 4380 steps  and the cls_loss is : tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008391677601261114
now it is 4400 steps  and the cls_loss is : tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008437425676875517
now it is 4420 steps  and the cls_loss is : tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008483318129123016
now it is 4440 steps  and the cls_loss is : tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008529354136206828
now it is 4460 steps  and the cls_loss is : tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008575532873759538
now it is 4480 steps  and the cls_loss is : tensor(0.0785, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008621853514857855
now it is 4500 steps  and the cls_loss is : tensor(0.1192, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008668315230037403
now it is 4520 steps  and the cls_loss is : tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000871491718730761
now it is 4540 steps  and the cls_loss is : tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008761658552166578
now it is 4560 steps  and the cls_loss is : tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008808538487616036
now it is 4580 steps  and the cls_loss is : tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008855556154176332
now it is 4600 steps  and the cls_loss is : tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008902710709901445
now it is 4620 steps  and the cls_loss is : tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008950001310394106
now it is 4640 steps  and the cls_loss is : tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0008997427108820861
now it is 4660 steps  and the cls_loss is : tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009044987255927288
now it is 4680 steps  and the cls_loss is : tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009092680900053161
now it is 4700 steps  and the cls_loss is : tensor(0.3493, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009140507187147739
now it is 4720 steps  and the cls_loss is : tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009188465260785029
now it is 4740 steps  and the cls_loss is : tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009236554262179149
now it is 4760 steps  and the cls_loss is : tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009284773330199671
now it is 4780 steps  and the cls_loss is : tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009333121601387078
now it is 4800 steps  and the cls_loss is : tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009381598209968205
now it is 4820 steps  and the cls_loss is : tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009430202287871755
now it is 4840 steps  and the cls_loss is : tensor(0.1087, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009478932964743811
now it is 4860 steps  and the cls_loss is : tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009527789367963489
now it is 4880 steps  and the cls_loss is : tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009576770622658475
now it is 4900 steps  and the cls_loss is : tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000962587585172077
now it is 4920 steps  and the cls_loss is : tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009675104175822353
now it is 4940 steps  and the cls_loss is : tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009724454713430949
now it is 4960 steps  and the cls_loss is : tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009773926580825777
now it is 4980 steps  and the cls_loss is : tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009823518892113424
now it is 5000 steps  and the cls_loss is : tensor(0.1640, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009873230759243697
now it is 5020 steps  and the cls_loss is : tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0009923061292025485
now it is 5040 steps  and the cls_loss is : tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.000997300959814275
now it is 5060 steps  and the cls_loss is : tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010023074783170479
now it is 5080 steps  and the cls_loss is : tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010073255950590705
now it is 5100 steps  and the cls_loss is : tensor(0.2695, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001012355220180857
now it is 5120 steps  and the cls_loss is : tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00101739626361684
now it is 5140 steps  and the cls_loss is : tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010224486350969846
now it is 5160 steps  and the cls_loss is : tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010275122441484046
now it is 5180 steps  and the cls_loss is : tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010325870000969825
now it is 5200 steps  and the cls_loss is : tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010376728120689927
now it is 5220 steps  and the cls_loss is : tensor(0.1143, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010427695889927294
now it is 5240 steps  and the cls_loss is : tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010478772396001373
now it is 5260 steps  and the cls_loss is : tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010529956724284464
now it is 5280 steps  and the cls_loss is : tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010581247958218083
now it is 5300 steps  and the cls_loss is : tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010632645179329393
now it is 5320 steps  and the cls_loss is : tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010684147467247642
now it is 5340 steps  and the cls_loss is : tensor(0.3677, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010735753899720644
now it is 5360 steps  and the cls_loss is : tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010787463552631295
now it is 5380 steps  and the cls_loss is : tensor(0.2711, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010839275500014118
now it is 5400 steps  and the cls_loss is : tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010891188814071855
now it is 5420 steps  and the cls_loss is : tensor(0.1656, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001094320256519206
now it is 5440 steps  and the cls_loss is : tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0010995315821963785
now it is 5460 steps  and the cls_loss is : tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011047527651194204
now it is 5480 steps  and the cls_loss is : tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011099837117925365
now it is 5500 steps  and the cls_loss is : tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011152243285450926
now it is 5520 steps  and the cls_loss is : tensor(0.1676, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001120474521533291
now it is 5540 steps  and the cls_loss is : tensor(0.1472, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011257341967418533
now it is 5560 steps  and the cls_loss is : tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011310032599857018
now it is 5580 steps  and the cls_loss is : tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011362816169116488
now it is 5600 steps  and the cls_loss is : tensor(0.1649, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011415691730000822
now it is 5620 steps  and the cls_loss is : tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011468658335666625
now it is 5640 steps  and the cls_loss is : tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011521715037640149
now it is 5660 steps  and the cls_loss is : tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011574860885834295
now it is 5680 steps  and the cls_loss is : tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011628094928565614
now it is 5700 steps  and the cls_loss is : tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011681416212571375
now it is 5720 steps  and the cls_loss is : tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011734823783026594
now it is 5740 steps  and the cls_loss is : tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011788316683561163
now it is 5760 steps  and the cls_loss is : tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011841893956276975
now it is 5780 steps  and the cls_loss is : tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011895554641765064
now it is 5800 steps  and the cls_loss is : tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0011949297779122777
now it is 5820 steps  and the cls_loss is : tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012003122405971015
now it is 5840 steps  and the cls_loss is : tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012057027558471437
now it is 5860 steps  and the cls_loss is : tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012111012271343723
now it is 5880 steps  and the cls_loss is : tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001216507557788287
now it is 5900 steps  and the cls_loss is : tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00122192165099765
now it is 5920 steps  and the cls_loss is : tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012273434098122185
now it is 5940 steps  and the cls_loss is : tensor(0.1332, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012327727371444824
now it is 5960 steps  and the cls_loss is : tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012382095357714009
now it is 5980 steps  and the cls_loss is : tensor(0.2784, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012436537083361464
now it is 6000 steps  and the cls_loss is : tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012491051573498436
now it is 6020 steps  and the cls_loss is : tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001254563785193321
now it is 6040 steps  and the cls_loss is : tensor(0.1267, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012600294941188526
now it is 6060 steps  and the cls_loss is : tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012655021862519131
now it is 6080 steps  and the cls_loss is : tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012709817635929285
now it is 6100 steps  and the cls_loss is : tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012764681280190307
now it is 6120 steps  and the cls_loss is : tensor(0.0999, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012819611812858163
now it is 6140 steps  and the cls_loss is : tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012874608250291032
now it is 6160 steps  and the cls_loss is : tensor(0.1748, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012929669607666954
now it is 6180 steps  and the cls_loss is : tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0012984794899001428
now it is 6200 steps  and the cls_loss is : tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013039983137165102
now it is 6220 steps  and the cls_loss is : tensor(0.1043, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001309523333390142
now it is 6240 steps  and the cls_loss is : tensor(0.0896, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001315054449984435
now it is 6260 steps  and the cls_loss is : tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013205915644536068
now it is 6280 steps  and the cls_loss is : tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001326134577644472
now it is 6300 steps  and the cls_loss is : tensor(0.1597, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013316833902982158
now it is 6320 steps  and the cls_loss is : tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013372379030521732
now it is 6340 steps  and the cls_loss is : tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013427980164416068
now it is 6360 steps  and the cls_loss is : tensor(0.0990, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001348363630901489
now it is 6380 steps  and the cls_loss is : tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013539346467682848
now it is 6400 steps  and the cls_loss is : tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013595109642817347
now it is 6420 steps  and the cls_loss is : tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013650924835866436
now it is 6440 steps  and the cls_loss is : tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013706791047346683
now it is 6460 steps  and the cls_loss is : tensor(0.5513, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013762707276861054
now it is 6480 steps  and the cls_loss is : tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013818672523116856
now it is 6500 steps  and the cls_loss is : tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013874685783943645
now it is 6520 steps  and the cls_loss is : tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013930746056311175
now it is 6540 steps  and the cls_loss is : tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0013986852336347372
now it is 6560 steps  and the cls_loss is : tensor(0.2109, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014043003619356304
now it is 6580 steps  and the cls_loss is : tensor(0.2103, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001409919889983616
now it is 6600 steps  and the cls_loss is : tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014155437171497274
now it is 6620 steps  and the cls_loss is : tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014211717427280127
now it is 6640 steps  and the cls_loss is : tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014268038659373409
now it is 6660 steps  and the cls_loss is : tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014324399859232016
now it is 6680 steps  and the cls_loss is : tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014380800017595172
now it is 6700 steps  and the cls_loss is : tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014437238124504453
now it is 6720 steps  and the cls_loss is : tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014493713169321891
now it is 6740 steps  and the cls_loss is : tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014550224140748075
now it is 6760 steps  and the cls_loss is : tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014606770026840256
now it is 6780 steps  and the cls_loss is : tensor(0.1190, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014663349815030463
now it is 6800 steps  and the cls_loss is : tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014719962492143641
now it is 6820 steps  and the cls_loss is : tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014776607044415797
now it is 6840 steps  and the cls_loss is : tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014833282457512142
now it is 6860 steps  and the cls_loss is : tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014889987716545268
now it is 6880 steps  and the cls_loss is : tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014946721806093314
now it is 6900 steps  and the cls_loss is : tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015003483710218147
now it is 6920 steps  and the cls_loss is : tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015060272412483558
now it is 6940 steps  and the cls_loss is : tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001511708689597347
now it is 6960 steps  and the cls_loss is : tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001517392614331014
now it is 6980 steps  and the cls_loss is : tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001523078913667237
now it is 7000 steps  and the cls_loss is : tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015287674857813742
now it is 7020 steps  and the cls_loss is : tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015344582288080869
now it is 7040 steps  and the cls_loss is : tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00154015104084316
now it is 7060 steps  and the cls_loss is : tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015458458199453294
now it is 7080 steps  and the cls_loss is : tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001551542464138106
now it is 7100 steps  and the cls_loss is : tensor(0.1730, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015572408714116033
now it is 7120 steps  and the cls_loss is : tensor(0.1626, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015629409397243626
now it is 7140 steps  and the cls_loss is : tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015686425670051827
now it is 7160 steps  and the cls_loss is : tensor(0.1159, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015743456511549431
now it is 7180 steps  and the cls_loss is : tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015800500900484374
now it is 7200 steps  and the cls_loss is : tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015857557815361987
now it is 7220 steps  and the cls_loss is : tensor(0.1667, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015914626234463307
now it is 7240 steps  and the cls_loss is : tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015971705135863347
now it is 7260 steps  and the cls_loss is : tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016028793497449444
now it is 7280 steps  and the cls_loss is : tensor(0.5062, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016085890296939497
now it is 7300 steps  and the cls_loss is : tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016142994511900328
now it is 7320 steps  and the cls_loss is : tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016200105119765975
now it is 7340 steps  and the cls_loss is : tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016257221097855975
now it is 7360 steps  and the cls_loss is : tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016314341423393722
now it is 7380 steps  and the cls_loss is : tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001637146507352475
now it is 7400 steps  and the cls_loss is : tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016428591025335066
now it is 7420 steps  and the cls_loss is : tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016485718255869447
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.19285543166060637
generate label finished(9.17/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:96.45, 93.37, 85.57
bev  AP:91.96, 88.34, 81.12
3d   AP:87.61, 79.05, 71.63
aos  AP:96.27, 92.70, 84.71
Car AP@0.70, 0.50, 0.50:
bbox AP:96.45, 93.37, 85.57
bev  AP:96.59, 95.58, 88.09
3d   AP:96.58, 93.72, 87.94
aos  AP:96.27, 92.70, 84.71

now it is 7440 steps  and the cls_loss is : tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016542845742149792
now it is 7460 steps  and the cls_loss is : tensor(0.2565, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00165999724611934
now it is 7480 steps  and the cls_loss is : tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016657097390031328
now it is 7500 steps  and the cls_loss is : tensor(0.2021, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016714219505726679
now it is 7520 steps  and the cls_loss is : tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016771337785392922
now it is 7540 steps  and the cls_loss is : tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001682845120621224
now it is 7560 steps  and the cls_loss is : tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016885558745453808
now it is 7580 steps  and the cls_loss is : tensor(0.1049, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001694265938049213
now it is 7600 steps  and the cls_loss is : tensor(0.1556, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016999752088825337
now it is 7620 steps  and the cls_loss is : tensor(0.1745, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017056835848093508
now it is 7640 steps  and the cls_loss is : tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017113909636096967
now it is 7660 steps  and the cls_loss is : tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017170972430814613
now it is 7680 steps  and the cls_loss is : tensor(0.1327, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017228023210422172
now it is 7700 steps  and the cls_loss is : tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017285060953310543
now it is 7720 steps  and the cls_loss is : tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017342084638104075
now it is 7740 steps  and the cls_loss is : tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017399093243678854
now it is 7760 steps  and the cls_loss is : tensor(0.1628, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017456085749180982
now it is 7780 steps  and the cls_loss is : tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017513061134044868
now it is 7800 steps  and the cls_loss is : tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001757001837801151
now it is 7820 steps  and the cls_loss is : tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017626956461146747
now it is 7840 steps  and the cls_loss is : tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017683874363859525
now it is 7860 steps  and the cls_loss is : tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017740771066920174
now it is 7880 steps  and the cls_loss is : tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017797645551478642
now it is 7900 steps  and the cls_loss is : tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001785449679908274
now it is 7920 steps  and the cls_loss is : tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017911323791696394
now it is 7940 steps  and the cls_loss is : tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001796812551171785
now it is 7960 steps  and the cls_loss is : tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018024900941997915
now it is 7980 steps  and the cls_loss is : tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018081649065858172
now it is 8000 steps  and the cls_loss is : tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018138368867109188
now it is 8020 steps  and the cls_loss is : tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001819505933006868
now it is 8040 steps  and the cls_loss is : tensor(0.0945, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001825171943957974
now it is 8060 steps  and the cls_loss is : tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001830834818102901
now it is 8080 steps  and the cls_loss is : tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018364944540364822
now it is 8100 steps  and the cls_loss is : tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018421507504115377
now it is 8120 steps  and the cls_loss is : tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00184780360594069
now it is 8140 steps  and the cls_loss is : tensor(0.2372, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018534529193981774
now it is 8160 steps  and the cls_loss is : tensor(0.1315, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018590985896216646
now it is 8180 steps  and the cls_loss is : tensor(0.1517, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001864740515514056
now it is 8200 steps  and the cls_loss is : tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001870378596045307
now it is 8220 steps  and the cls_loss is : tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018760127302542302
now it is 8240 steps  and the cls_loss is : tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001881642817250307
now it is 8260 steps  and the cls_loss is : tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00188726875621549
now it is 8280 steps  and the cls_loss is : tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018928904464060132
now it is 8300 steps  and the cls_loss is : tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018985077871541912
now it is 8320 steps  and the cls_loss is : tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019041206778702263
now it is 8340 steps  and the cls_loss is : tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001909729018044005
now it is 8360 steps  and the cls_loss is : tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019153327072469026
now it is 8380 steps  and the cls_loss is : tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001920931645133578
now it is 8400 steps  and the cls_loss is : tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019265257314437737
now it is 8420 steps  and the cls_loss is : tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019321148660041076
now it is 8440 steps  and the cls_loss is : tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001937698948729869
now it is 8460 steps  and the cls_loss is : tensor(0.2753, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019432778796268117
now it is 8480 steps  and the cls_loss is : tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019488515587929417
now it is 8500 steps  and the cls_loss is : tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00195441988642031
now it is 8520 steps  and the cls_loss is : tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019599827627967948
now it is 8540 steps  and the cls_loss is : tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019655400883078922
now it is 8560 steps  and the cls_loss is : tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019710917634384972
now it is 8580 steps  and the cls_loss is : tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019766376887746864
now it is 8600 steps  and the cls_loss is : tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019821777650054963
now it is 8620 steps  and the cls_loss is : tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019877118929247056
now it is 8640 steps  and the cls_loss is : tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019932399734326088
now it is 8660 steps  and the cls_loss is : tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019987619075377914
now it is 8680 steps  and the cls_loss is : tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002004277596358902
now it is 8700 steps  and the cls_loss is : tensor(0.1233, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020097869411264246
now it is 8720 steps  and the cls_loss is : tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002015289843184446
now it is 8740 steps  and the cls_loss is : tensor(0.0838, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002020786203992422
now it is 8760 steps  and the cls_loss is : tensor(0.7375, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002026275925126944
now it is 8780 steps  and the cls_loss is : tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020317589082834986
now it is 8800 steps  and the cls_loss is : tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00203723505527823
now it is 8820 steps  and the cls_loss is : tensor(0.1530, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002042704268049699
now it is 8840 steps  and the cls_loss is : tensor(0.1324, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020481664486606344
now it is 8860 steps  and the cls_loss is : tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020536214992996943
now it is 8880 steps  and the cls_loss is : tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020590693222832094
now it is 8900 steps  and the cls_loss is : tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002064509820056939
now it is 8920 steps  and the cls_loss is : tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020699428951978125
now it is 8940 steps  and the cls_loss is : tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002075368450415679
now it is 8960 steps  and the cls_loss is : tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020807863885550443
now it is 8980 steps  and the cls_loss is : tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002086196612596817
now it is 9000 steps  and the cls_loss is : tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002091599025660038
now it is 9020 steps  and the cls_loss is : tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020969935310036223
now it is 9040 steps  and the cls_loss is : tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002102380032028087
now it is 9060 steps  and the cls_loss is : tensor(0.2005, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021077584322772842
now it is 9080 steps  and the cls_loss is : tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021131286354401256
now it is 9100 steps  and the cls_loss is : tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021184905453523082
now it is 9120 steps  and the cls_loss is : tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002123844065998037
now it is 9140 steps  and the cls_loss is : tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002129189101511743
now it is 9160 steps  and the cls_loss is : tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021345255561798014
now it is 9180 steps  and the cls_loss is : tensor(0.1281, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021398533344422436
now it is 9200 steps  and the cls_loss is : tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021451723408944705
now it is 9220 steps  and the cls_loss is : tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002150482480288959
now it is 9240 steps  and the cls_loss is : tensor(0.4431, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002155783657536971
now it is 9260 steps  and the cls_loss is : tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00216107577771025
now it is 9280 steps  and the cls_loss is : tensor(0.1965, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002166358746042727
now it is 9300 steps  and the cls_loss is : tensor(0.1658, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021716324679322144
now it is 9320 steps  and the cls_loss is : tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021768968489421013
now it is 9340 steps  and the cls_loss is : tensor(0.1287, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002182151794803043
now it is 9360 steps  and the cls_loss is : tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021873972114146516
now it is 9380 steps  and the cls_loss is : tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021926330048471793
now it is 9400 steps  and the cls_loss is : tensor(0.2042, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021978590813432
now it is 9420 steps  and the cls_loss is : tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002203075347319288
now it is 9440 steps  and the cls_loss is : tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022082817093676973
now it is 9460 steps  and the cls_loss is : tensor(0.0957, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00221347807425803
now it is 9480 steps  and the cls_loss is : tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022186643489389077
now it is 9500 steps  and the cls_loss is : tensor(0.4433, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022238404405396373
now it is 9520 steps  and the cls_loss is : tensor(0.2769, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002229006256371874
now it is 9540 steps  and the cls_loss is : tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002234161703931284
now it is 9560 steps  and the cls_loss is : tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022393066908991946
now it is 9580 steps  and the cls_loss is : tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022444411251442515
now it is 9600 steps  and the cls_loss is : tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002249564914724071
now it is 9620 steps  and the cls_loss is : tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002254677967886882
now it is 9640 steps  and the cls_loss is : tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002259780193073169
now it is 9660 steps  and the cls_loss is : tensor(0.1016, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002264871498917316
now it is 9680 steps  and the cls_loss is : tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022699517942492376
now it is 9700 steps  and the cls_loss is : tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022750209880960143
now it is 9720 steps  and the cls_loss is : tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022800789896835227
now it is 9740 steps  and the cls_loss is : tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022851257084380576
now it is 9760 steps  and the cls_loss is : tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002290161053987955
now it is 9780 steps  and the cls_loss is : tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022951849361652127
now it is 9800 steps  and the cls_loss is : tensor(0.1852, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023001972650071034
now it is 9820 steps  and the cls_loss is : tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023051979507577843
now it is 9840 steps  and the cls_loss is : tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023101869038699065
now it is 9860 steps  and the cls_loss is : tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023151640350062164
now it is 9880 steps  and the cls_loss is : tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023201292550411572
now it is 9900 steps  and the cls_loss is : tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002325082475062467
now it is 9920 steps  and the cls_loss is : tensor(0.1531, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023300236063727633
now it is 9940 steps  and the cls_loss is : tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002334952560491141
now it is 9960 steps  and the cls_loss is : tensor(0.0483, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023398692491547485
now it is 9980 steps  and the cls_loss is : tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002344773584320375
now it is 10000 steps  and the cls_loss is : tensor(0.0728, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023496654781660214
now it is 10020 steps  and the cls_loss is : tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023545448430924774
now it is 10040 steps  and the cls_loss is : tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023594115917248866
now it is 10060 steps  and the cls_loss is : tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023642656369143146
now it is 10080 steps  and the cls_loss is : tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002369106891739306
now it is 10100 steps  and the cls_loss is : tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023739352695074426
now it is 10120 steps  and the cls_loss is : tensor(0.2718, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002378750683756898
now it is 10140 steps  and the cls_loss is : tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002383553048257982
now it is 10160 steps  and the cls_loss is : tensor(0.1515, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023883422770146854
now it is 10180 steps  and the cls_loss is : tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023931182842662235
now it is 10200 steps  and the cls_loss is : tensor(0.1888, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023978809844885677
now it is 10220 steps  and the cls_loss is : tensor(0.1798, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024026302923959787
now it is 10240 steps  and the cls_loss is : tensor(0.2331, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002407366122942535
now it is 10260 steps  and the cls_loss is : tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002412088391323651
now it is 10280 steps  and the cls_loss is : tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002416797012977602
now it is 10300 steps  and the cls_loss is : tensor(0.1586, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024214919035870355
now it is 10320 steps  and the cls_loss is : tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002426172979080479
now it is 10340 steps  and the cls_loss is : tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024308401556338488
now it is 10360 steps  and the cls_loss is : tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024354933496719498
now it is 10380 steps  and the cls_loss is : tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024401324778699713
now it is 10400 steps  and the cls_loss is : tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00244475745715498
now it is 10420 steps  and the cls_loss is : tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024493682047074085
now it is 10440 steps  and the cls_loss is : tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024539646379625342
now it is 10460 steps  and the cls_loss is : tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002458546674611965
now it is 10480 steps  and the cls_loss is : tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024631142326051064
now it is 10500 steps  and the cls_loss is : tensor(0.1278, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024676672301506327
now it is 10520 steps  and the cls_loss is : tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002472205585717955
now it is 10540 steps  and the cls_loss is : tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002476729218038676
now it is 10560 steps  and the cls_loss is : tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00248123804610805
now it is 10580 steps  and the cls_loss is : tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024857319891864287
now it is 10600 steps  and the cls_loss is : tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024902109668007116
now it is 10620 steps  and the cls_loss is : tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002494674898745784
now it is 10640 steps  and the cls_loss is : tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024991237050859556
now it is 10660 steps  and the cls_loss is : tensor(0.1065, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002503557306156388
now it is 10680 steps  and the cls_loss is : tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002507975622564525
now it is 10700 steps  and the cls_loss is : tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025123785751915142
now it is 10720 steps  and the cls_loss is : tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002516766085193622
now it is 10740 steps  and the cls_loss is : tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025211380740036444
now it is 10760 steps  and the cls_loss is : tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025254944633323183
now it is 10780 steps  and the cls_loss is : tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025298351751697184
now it is 10800 steps  and the cls_loss is : tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025341601317866577
now it is 10820 steps  and the cls_loss is : tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025384692557360792
now it is 10840 steps  and the cls_loss is : tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002542762469854438
now it is 10860 steps  and the cls_loss is : tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002547039697263091
now it is 10880 steps  and the cls_loss is : tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025513008613696677
now it is 10900 steps  and the cls_loss is : tensor(0.1036, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002555545885869442
now it is 10920 steps  and the cls_loss is : tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002559774694746701
now it is 10940 steps  and the cls_loss is : tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025639872122761066
now it is 10960 steps  and the cls_loss is : tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025681833630240482
now it is 10980 steps  and the cls_loss is : tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025723630718499963
now it is 11000 steps  and the cls_loss is : tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002576526263907846
now it is 11020 steps  and the cls_loss is : tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002580672864647259
now it is 11040 steps  and the cls_loss is : tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025848027998150004
now it is 11060 steps  and the cls_loss is : tensor(0.1322, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002588915995456262
now it is 11080 steps  and the cls_loss is : tensor(0.1638, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025930123779159915
now it is 11100 steps  and the cls_loss is : tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002597091873840213
now it is 11120 steps  and the cls_loss is : tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026011544101773353
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.2176154933587464
generate label finished(9.57/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:96.06, 93.05, 87.55
bev  AP:91.69, 88.36, 83.26
3d   AP:87.78, 77.22, 71.78
aos  AP:95.82, 92.26, 86.52
Car AP@0.70, 0.50, 0.50:
bbox AP:96.06, 93.05, 87.55
bev  AP:96.14, 95.56, 90.28
3d   AP:96.13, 93.64, 90.03
aos  AP:95.82, 92.26, 86.52

now it is 11140 steps  and the cls_loss is : tensor(0.1832, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002605199914179464
now it is 11160 steps  and the cls_loss is : tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026092283134037026
now it is 11180 steps  and the cls_loss is : tensor(0.1355, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00261323953571345
now it is 11200 steps  and the cls_loss is : tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026172335092796923
now it is 11220 steps  and the cls_loss is : tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026212101625822906
now it is 11240 steps  and the cls_loss is : tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002625169424411257
now it is 11260 steps  and the cls_loss is : tensor(0.1262, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002629111223868036
now it is 11280 steps  and the cls_loss is : tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026330354903667703
now it is 11300 steps  and the cls_loss is : tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002636942153635564
now it is 11320 steps  and the cls_loss is : tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002640831143717745
now it is 11340 steps  and the cls_loss is : tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002644702390973112
now it is 11360 steps  and the cls_loss is : tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002648555826079188
now it is 11380 steps  and the cls_loss is : tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026523913800324565
now it is 11400 steps  and the cls_loss is : tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026562089841495997
now it is 11420 steps  and the cls_loss is : tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002660008570068727
now it is 11440 steps  and the cls_loss is : tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026637900697506016
now it is 11460 steps  and the cls_loss is : tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002667553415479855
now it is 11480 steps  and the cls_loss is : tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026712985398662037
now it is 11500 steps  and the cls_loss is : tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026750253758456525
now it is 11520 steps  and the cls_loss is : tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026787338566816982
now it is 11540 steps  and the cls_loss is : tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026824239159665224
now it is 11560 steps  and the cls_loss is : tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026860954876221834
now it is 11580 steps  and the cls_loss is : tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026897485059017953
now it is 11600 steps  and the cls_loss is : tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002693382905390709
now it is 11620 steps  and the cls_loss is : tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026969986210076827
now it is 11640 steps  and the cls_loss is : tensor(0.2301, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027005955880060467
now it is 11660 steps  and the cls_loss is : tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027041737419748624
now it is 11680 steps  and the cls_loss is : tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027077330188400774
now it is 11700 steps  and the cls_loss is : tensor(0.3168, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002711273354865671
now it is 11720 steps  and the cls_loss is : tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027147946866547972
now it is 11740 steps  and the cls_loss is : tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027182969511509187
now it is 11760 steps  and the cls_loss is : tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027217800856389356
now it is 11780 steps  and the cls_loss is : tensor(0.1691, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002725244027746311
now it is 11800 steps  and the cls_loss is : tensor(0.1742, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027286887154441856
now it is 11820 steps  and the cls_loss is : tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027321140870484877
now it is 11840 steps  and the cls_loss is : tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027355200812210416
now it is 11860 steps  and the cls_loss is : tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027389066369706617
now it is 11880 steps  and the cls_loss is : tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027422736936542473
now it is 11900 steps  and the cls_loss is : tensor(0.1366, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027456211909778674
now it is 11920 steps  and the cls_loss is : tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002748949068997841
now it is 11940 steps  and the cls_loss is : tensor(0.1149, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027522572681218096
now it is 11960 steps  and the cls_loss is : tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027555457291098067
now it is 11980 steps  and the cls_loss is : tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027588143930753145
now it is 12000 steps  and the cls_loss is : tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027620632014863223
now it is 12020 steps  and the cls_loss is : tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002765292096166373
now it is 12040 steps  and the cls_loss is : tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027685010192956038
now it is 12060 steps  and the cls_loss is : tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027716899134117845
now it is 12080 steps  and the cls_loss is : tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027748587214113437
now it is 12100 steps  and the cls_loss is : tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002778007386550392
now it is 12120 steps  and the cls_loss is : tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027811358524457387
now it is 12140 steps  and the cls_loss is : tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002784244063075903
now it is 12160 steps  and the cls_loss is : tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027873319627821124
now it is 12180 steps  and the cls_loss is : tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002790399496269304
now it is 12200 steps  and the cls_loss is : tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002793446608607114
now it is 12220 steps  and the cls_loss is : tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027964732452308593
now it is 12240 steps  and the cls_loss is : tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027994793519425147
now it is 12260 steps  and the cls_loss is : tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028024648749116867
now it is 12280 steps  and the cls_loss is : tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002805429760676573
now it is 12300 steps  and the cls_loss is : tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028083739561449235
now it is 12320 steps  and the cls_loss is : tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028112974085949885
now it is 12340 steps  and the cls_loss is : tensor(0.3532, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002814200065676465
now it is 12360 steps  and the cls_loss is : tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002817081875411432
now it is 12380 steps  and the cls_loss is : tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028199427861952827
now it is 12400 steps  and the cls_loss is : tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028227827467976474
now it is 12420 steps  and the cls_loss is : tensor(0.3203, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028256017063633125
now it is 12440 steps  and the cls_loss is : tensor(0.1667, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00282839961441313
now it is 12460 steps  and the cls_loss is : tensor(0.0845, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002831176420844921
now it is 12480 steps  and the cls_loss is : tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028339320759343746
now it is 12500 steps  and the cls_loss is : tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028366665303359365
now it is 12520 steps  and the cls_loss is : tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028393797350836935
now it is 12540 steps  and the cls_loss is : tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002842071641592251
now it is 12560 steps  and the cls_loss is : tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028447422016576016
now it is 12580 steps  and the cls_loss is : tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028473913674579884
now it is 12600 steps  and the cls_loss is : tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002850019091554764
now it is 12620 steps  and the cls_loss is : tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002852625326893235
now it is 12640 steps  and the cls_loss is : tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028552100268035095
now it is 12660 steps  and the cls_loss is : tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028577731450013305
now it is 12680 steps  and the cls_loss is : tensor(0.2147, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028603146355889045
now it is 12700 steps  and the cls_loss is : tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002862834453055724
now it is 12720 steps  and the cls_loss is : tensor(0.3683, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002865332552279383
now it is 12740 steps  and the cls_loss is : tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002867808888526384
now it is 12760 steps  and the cls_loss is : tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028702634174529386
now it is 12780 steps  and the cls_loss is : tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002872696095105764
now it is 12800 steps  and the cls_loss is : tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028751068779228678
now it is 12820 steps  and the cls_loss is : tensor(0.0802, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002877495722734328
now it is 12840 steps  and the cls_loss is : tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028798625867630678
now it is 12860 steps  and the cls_loss is : tensor(0.0744, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028822074276256193
now it is 12880 steps  and the cls_loss is : tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028845302033328854
now it is 12900 steps  and the cls_loss is : tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028868308722908888
now it is 12920 steps  and the cls_loss is : tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028891093933015185
now it is 12940 steps  and the cls_loss is : tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028913657255632674
now it is 12960 steps  and the cls_loss is : tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002893599828671962
now it is 12980 steps  and the cls_loss is : tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028958116626214866
now it is 13000 steps  and the cls_loss is : tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028980011878045006
now it is 13020 steps  and the cls_loss is : tensor(0.2740, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002900168365013146
now it is 13040 steps  and the cls_loss is : tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029023131554397497
now it is 13060 steps  and the cls_loss is : tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00290443552067752
now it is 13080 steps  and the cls_loss is : tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029065354227212335
now it is 13100 steps  and the cls_loss is : tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002908612823967915
now it is 13120 steps  and the cls_loss is : tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002910667687217511
now it is 13140 steps  and the cls_loss is : tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002912699975673557
now it is 13160 steps  and the cls_loss is : tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029147096529438354
now it is 13180 steps  and the cls_loss is : tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029166966830410273
now it is 13200 steps  and the cls_loss is : tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002918661030383357
now it is 13220 steps  and the cls_loss is : tensor(0.0457, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029206026597952297
now it is 13240 steps  and the cls_loss is : tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029225215365078602
now it is 13260 steps  and the cls_loss is : tensor(0.1070, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002924417626159897
now it is 13280 steps  and the cls_loss is : tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002926290894798035
now it is 13300 steps  and the cls_loss is : tensor(0.1180, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029281413088776283
now it is 13320 steps  and the cls_loss is : tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029299688352632854
now it is 13340 steps  and the cls_loss is : tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002931773441229466
now it is 13360 steps  and the cls_loss is : tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002933555094461066
now it is 13380 steps  and the cls_loss is : tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029353137630539964
now it is 13400 steps  and the cls_loss is : tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002937049415515754
now it is 13420 steps  and the cls_loss is : tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002938762020765986
now it is 13440 steps  and the cls_loss is : tensor(0.0665, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002940451548137046
now it is 13460 steps  and the cls_loss is : tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029421179673745452
now it is 13480 steps  and the cls_loss is : tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029437612486378894
now it is 13500 steps  and the cls_loss is : tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029453813625008192
now it is 13520 steps  and the cls_loss is : tensor(0.1258, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029469782799519334
now it is 13540 steps  and the cls_loss is : tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029485519723952084
now it is 13560 steps  and the cls_loss is : tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002950102411650512
now it is 13580 steps  and the cls_loss is : tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029516295699541064
now it is 13600 steps  and the cls_loss is : tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002953133419959147
now it is 13620 steps  and the cls_loss is : tensor(0.1206, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002954613934736171
now it is 13640 steps  and the cls_loss is : tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029560710877735794
now it is 13660 steps  and the cls_loss is : tensor(0.3606, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029575048529781127
now it is 13680 steps  and the cls_loss is : tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029589152046753174
now it is 13700 steps  and the cls_loss is : tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002960302117610006
now it is 13720 steps  and the cls_loss is : tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029616655669467092
now it is 13740 steps  and the cls_loss is : tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002963005528270121
now it is 13760 steps  and the cls_loss is : tensor(0.4854, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029643219775855353
now it is 13780 steps  and the cls_loss is : tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002965614891319276
now it is 13800 steps  and the cls_loss is : tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029668842463191182
now it is 13820 steps  and the cls_loss is : tensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029681300198547054
now it is 13840 steps  and the cls_loss is : tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002969352189617952
now it is 13860 steps  and the cls_loss is : tensor(0.3060, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002970550733723449
now it is 13880 steps  and the cls_loss is : tensor(0.1092, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002971725630708849
now it is 13900 steps  and the cls_loss is : tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029728768595352556
now it is 13920 steps  and the cls_loss is : tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002974004399587599
now it is 13940 steps  and the cls_loss is : tensor(0.1248, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029751082306750027
now it is 13960 steps  and the cls_loss is : tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029761883330311485
now it is 13980 steps  and the cls_loss is : tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002977244687314629
now it is 14000 steps  and the cls_loss is : tensor(0.3110, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029782772746092924
now it is 14020 steps  and the cls_loss is : tensor(0.2687, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002979286076424584
now it is 14040 steps  and the cls_loss is : tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029802710746958763
now it is 14060 steps  and the cls_loss is : tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002981232251784791
now it is 14080 steps  and the cls_loss is : tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002982169590479516
now it is 14100 steps  and the cls_loss is : tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029830830739951157
now it is 14120 steps  and the cls_loss is : tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029839726859738273
now it is 14140 steps  and the cls_loss is : tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029848384104853563
now it is 14160 steps  and the cls_loss is : tensor(0.0671, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029856802320271628
now it is 14180 steps  and the cls_loss is : tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029864981355247357
now it is 14200 steps  and the cls_loss is : tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029872921063318664
now it is 14220 steps  and the cls_loss is : tensor(0.1181, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029880621302309086
now it is 14240 steps  and the cls_loss is : tensor(0.1021, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029888081934330334
now it is 14260 steps  and the cls_loss is : tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029895302825784765
now it is 14280 steps  and the cls_loss is : tensor(0.1046, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029902283847367777
now it is 14300 steps  and the cls_loss is : tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002990902487407012
now it is 14320 steps  and the cls_loss is : tensor(0.1523, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002991552578518014
now it is 14340 steps  and the cls_loss is : tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002992178646428592
now it is 14360 steps  and the cls_loss is : tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029927806799277404
now it is 14380 steps  and the cls_loss is : tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002993358668234836
now it is 14400 steps  and the cls_loss is : tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029939126009998346
now it is 14420 steps  and the cls_loss is : tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029944424683034545
now it is 14440 steps  and the cls_loss is : tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029949482606573545
now it is 14460 steps  and the cls_loss is : tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002995429969004304
now it is 14480 steps  and the cls_loss is : tensor(0.1205, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029958875847183445
now it is 14500 steps  and the cls_loss is : tensor(0.0474, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029963210996049455
now it is 14520 steps  and the cls_loss is : tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029967305059011495
now it is 14540 steps  and the cls_loss is : tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029971157962757127
now it is 14560 steps  and the cls_loss is : tensor(0.1361, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997476963829235
now it is 14580 steps  and the cls_loss is : tensor(0.0607, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997814002094283
now it is 14600 steps  and the cls_loss is : tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029981269050355095
now it is 14620 steps  and the cls_loss is : tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029984156670497556
now it is 14640 steps  and the cls_loss is : tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998680282966157
now it is 14660 steps  and the cls_loss is : tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998920748046232
now it is 14680 steps  and the cls_loss is : tensor(0.2589, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029991370579839694
now it is 14700 steps  and the cls_loss is : tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029993292089059045
now it is 14720 steps  and the cls_loss is : tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999497197371188
now it is 14740 steps  and the cls_loss is : tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999641020371647
now it is 14760 steps  and the cls_loss is : tensor(0.1053, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029997606753318423
now it is 14780 steps  and the cls_loss is : tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029998561601091104
now it is 14800 steps  and the cls_loss is : tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029999274729936042
now it is 14820 steps  and the cls_loss is : tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029999746127083227
now it is 14840 steps  and the cls_loss is : tensor(0.1451, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029999975784091347
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.19309842725640053
generate label finished(9.82/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:96.55, 91.02, 85.48
bev  AP:91.83, 86.52, 81.26
3d   AP:87.42, 77.27, 71.82
aos  AP:96.35, 90.27, 84.52
Car AP@0.70, 0.50, 0.50:
bbox AP:96.55, 91.02, 85.48
bev  AP:96.57, 93.55, 86.04
3d   AP:96.56, 93.49, 85.97
aos  AP:96.35, 90.27, 84.52

now it is 14860 steps  and the cls_loss is : tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029999982204688383
now it is 14880 steps  and the cls_loss is : tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029999856856881262
now it is 14900 steps  and the cls_loss is : tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999961213121653
now it is 14920 steps  and the cls_loss is : tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999924802964188
now it is 14940 steps  and the cls_loss is : tensor(0.1295, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029998764555055077
now it is 14960 steps  and the cls_loss is : tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029998161711303943
now it is 14980 steps  and the cls_loss is : tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999743950318632
now it is 15000 steps  and the cls_loss is : tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029996597936450026
now it is 15020 steps  and the cls_loss is : tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029995637017792825
now it is 15040 steps  and the cls_loss is : tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999455675486236
now it is 15060 steps  and the cls_loss is : tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029993357156256092
now it is 15080 steps  and the cls_loss is : tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002999203823152125
now it is 15100 steps  and the cls_loss is : tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029990599991154727
now it is 15120 steps  and the cls_loss is : tensor(0.1589, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998904244660302
now it is 15140 steps  and the cls_loss is : tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029987365610262126
now it is 15160 steps  and the cls_loss is : tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998556949547745
now it is 15180 steps  and the cls_loss is : tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002998365411654369
now it is 15200 steps  and the cls_loss is : tensor(0.3205, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029981619488704736
now it is 15220 steps  and the cls_loss is : tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029979465628153534
now it is 15240 steps  and the cls_loss is : tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997719255203198
now it is 15260 steps  and the cls_loss is : tensor(0.1961, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997480027843074
now it is 15280 steps  and the cls_loss is : tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002997228882638917
now it is 15300 steps  and the cls_loss is : tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029969658215895107
now it is 15320 steps  and the cls_loss is : tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029966908467884737
now it is 15340 steps  and the cls_loss is : tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029964039604242422
now it is 15360 steps  and the cls_loss is : tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029961051647800527
now it is 15380 steps  and the cls_loss is : tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029957944622339234
now it is 15400 steps  and the cls_loss is : tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029954718552586378
now it is 15420 steps  and the cls_loss is : tensor(0.0862, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029951373464217196
now it is 15440 steps  and the cls_loss is : tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002994790938385419
now it is 15460 steps  and the cls_loss is : tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002994432633906686
now it is 15480 steps  and the cls_loss is : tensor(0.5699, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00299406243583715
now it is 15500 steps  and the cls_loss is : tensor(0.1725, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029936803471231
now it is 15520 steps  and the cls_loss is : tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029932863708054575
now it is 15540 steps  and the cls_loss is : tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029928805100197533
now it is 15560 steps  and the cls_loss is : tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029924627679961038
now it is 15580 steps  and the cls_loss is : tensor(0.0606, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002992033148059183
now it is 15600 steps  and the cls_loss is : tensor(0.1670, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029915916536281994
now it is 15620 steps  and the cls_loss is : tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002991138288216865
now it is 15640 steps  and the cls_loss is : tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002990673055433369
now it is 15660 steps  and the cls_loss is : tensor(0.2126, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029901959589803515
now it is 15680 steps  and the cls_loss is : tensor(0.1186, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029897070026548692
now it is 15700 steps  and the cls_loss is : tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029892061903483693
now it is 15720 steps  and the cls_loss is : tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029886935260466565
now it is 15740 steps  and the cls_loss is : tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029881690138298606
now it is 15760 steps  and the cls_loss is : tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002987632657872408
now it is 15780 steps  and the cls_loss is : tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002987084462442982
now it is 15800 steps  and the cls_loss is : tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002986524431904495
now it is 15820 steps  and the cls_loss is : tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029859525707140516
now it is 15840 steps  and the cls_loss is : tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00298536888342291
now it is 15860 steps  and the cls_loss is : tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029847733746764505
now it is 15880 steps  and the cls_loss is : tensor(0.3634, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002984166049214138
now it is 15900 steps  and the cls_loss is : tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002983546911869479
now it is 15920 steps  and the cls_loss is : tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029829159675699908
now it is 15940 steps  and the cls_loss is : tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029822732213371553
now it is 15960 steps  and the cls_loss is : tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002981618678286385
now it is 15980 steps  and the cls_loss is : tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029809523436269787
now it is 16000 steps  and the cls_loss is : tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002980274222662078
now it is 16020 steps  and the cls_loss is : tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029795843207886326
now it is 16040 steps  and the cls_loss is : tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029788826434973496
now it is 16060 steps  and the cls_loss is : tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002978169196372653
now it is 16080 steps  and the cls_loss is : tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002977443985092641
now it is 16100 steps  and the cls_loss is : tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029767070154290364
now it is 16120 steps  and the cls_loss is : tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029759582932471452
now it is 16140 steps  and the cls_loss is : tensor(0.0805, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002975197824505807
now it is 16160 steps  and the cls_loss is : tensor(0.2315, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00297442561525735
now it is 16180 steps  and the cls_loss is : tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002973641671647538
now it is 16200 steps  and the cls_loss is : tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002972845999915528
now it is 16220 steps  and the cls_loss is : tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029720386063938164
now it is 16240 steps  and the cls_loss is : tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002971219497508189
now it is 16260 steps  and the cls_loss is : tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002970388679777671
now it is 16280 steps  and the cls_loss is : tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029695461598144746
now it is 16300 steps  and the cls_loss is : tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029686919443239457
now it is 16320 steps  and the cls_loss is : tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002967826040104512
now it is 16340 steps  and the cls_loss is : tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029669484540476273
now it is 16360 steps  and the cls_loss is : tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029660591931377177
now it is 16380 steps  and the cls_loss is : tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002965158264452126
now it is 16400 steps  and the cls_loss is : tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029642456751610546
now it is 16420 steps  and the cls_loss is : tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002963321432527509
now it is 16440 steps  and the cls_loss is : tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029623855439072405
now it is 16460 steps  and the cls_loss is : tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029614380167486865
now it is 16480 steps  and the cls_loss is : tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029604788585929115
now it is 16500 steps  and the cls_loss is : tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002959508077073548
now it is 16520 steps  and the cls_loss is : tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029585256799167354
now it is 16540 steps  and the cls_loss is : tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029575316749410573
now it is 16560 steps  and the cls_loss is : tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029565260700574808
now it is 16580 steps  and the cls_loss is : tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002955508873269292
now it is 16600 steps  and the cls_loss is : tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029544800926720356
now it is 16620 steps  and the cls_loss is : tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029534397364534455
now it is 16640 steps  and the cls_loss is : tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002952387812893384
now it is 16660 steps  and the cls_loss is : tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029513243303637728
now it is 16680 steps  and the cls_loss is : tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002950249297328529
now it is 16700 steps  and the cls_loss is : tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029491627223434957
now it is 16720 steps  and the cls_loss is : tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002948064614056375
now it is 16740 steps  and the cls_loss is : tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002946954981206659
now it is 16760 steps  and the cls_loss is : tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002945833832625559
now it is 16780 steps  and the cls_loss is : tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002944701177235938
now it is 16800 steps  and the cls_loss is : tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002943557024052237
now it is 16820 steps  and the cls_loss is : tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029424013821804044
now it is 16840 steps  and the cls_loss is : tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002941234260817823
now it is 16860 steps  and the cls_loss is : tensor(0.3449, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002940055669253238
now it is 16880 steps  and the cls_loss is : tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002938865616866682
now it is 16900 steps  and the cls_loss is : tensor(0.1032, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029376641131293995
now it is 16920 steps  and the cls_loss is : tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002936451167603775
now it is 16940 steps  and the cls_loss is : tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029352267899432527
now it is 16960 steps  and the cls_loss is : tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029339909898922615
now it is 16980 steps  and the cls_loss is : tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002932743777286138
now it is 17000 steps  and the cls_loss is : tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002931485162051048
now it is 17020 steps  and the cls_loss is : tensor(0.2103, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029302151542039056
now it is 17040 steps  and the cls_loss is : tensor(0.1646, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029289337638522973
now it is 17060 steps  and the cls_loss is : tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002927641001194398
now it is 17080 steps  and the cls_loss is : tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029263368765188903
now it is 17100 steps  and the cls_loss is : tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002925021400204885
now it is 17120 steps  and the cls_loss is : tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002923694582721837
now it is 17140 steps  and the cls_loss is : tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002922356434629461
now it is 17160 steps  and the cls_loss is : tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029210069665776485
now it is 17180 steps  and the cls_loss is : tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029196461893063828
now it is 17200 steps  and the cls_loss is : tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002918274113645655
now it is 17220 steps  and the cls_loss is : tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029168907505153748
now it is 17240 steps  and the cls_loss is : tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002915496110925286
now it is 17260 steps  and the cls_loss is : tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002914090205974878
now it is 17280 steps  and the cls_loss is : tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029126730468532975
now it is 17300 steps  and the cls_loss is : tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029112446448392604
now it is 17320 steps  and the cls_loss is : tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029098050113009594
now it is 17340 steps  and the cls_loss is : tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029083541576959767
now it is 17360 steps  and the cls_loss is : tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029068920955711915
now it is 17380 steps  and the cls_loss is : tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002905418836562687
now it is 17400 steps  and the cls_loss is : tensor(0.0993, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00290393439239566
now it is 17420 steps  and the cls_loss is : tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029024387748843253
now it is 17440 steps  and the cls_loss is : tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0029009319959318234
now it is 17460 steps  and the cls_loss is : tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028994140675301255
now it is 17480 steps  and the cls_loss is : tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002897885001759936
now it is 17500 steps  and the cls_loss is : tensor(0.3476, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028963448107906004
now it is 17520 steps  and the cls_loss is : tensor(0.1265, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002894793506880004
now it is 17540 steps  and the cls_loss is : tensor(0.2733, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028932311023744774
now it is 17560 steps  and the cls_loss is : tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002891657609708698
now it is 17580 steps  and the cls_loss is : tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028900730414055894
now it is 17600 steps  and the cls_loss is : tensor(0.0751, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002888477410076222
now it is 17620 steps  and the cls_loss is : tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028868707284197145
now it is 17640 steps  and the cls_loss is : tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028852530092231318
now it is 17660 steps  and the cls_loss is : tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002883624265361381
now it is 17680 steps  and the cls_loss is : tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002881984509797114
now it is 17700 steps  and the cls_loss is : tensor(0.1042, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002880333755580618
now it is 17720 steps  and the cls_loss is : tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028786720158497188
now it is 17740 steps  and the cls_loss is : tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028769993038296683
now it is 17760 steps  and the cls_loss is : tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028753156328330458
now it is 17780 steps  and the cls_loss is : tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028736210162596497
now it is 17800 steps  and the cls_loss is : tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002871915467596389
now it is 17820 steps  and the cls_loss is : tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00287019900041718
now it is 17840 steps  and the cls_loss is : tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028684716283828345
now it is 17860 steps  and the cls_loss is : tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002866733365240952
now it is 17880 steps  and the cls_loss is : tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002864984224825812
now it is 17900 steps  and the cls_loss is : tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028632242210582626
now it is 17920 steps  and the cls_loss is : tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028614533679456092
now it is 17940 steps  and the cls_loss is : tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002859671679581505
now it is 17960 steps  and the cls_loss is : tensor(0.2078, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002857879170145836
now it is 17980 steps  and the cls_loss is : tensor(0.1317, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00285607585390461
now it is 18000 steps  and the cls_loss is : tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028542617452098425
now it is 18020 steps  and the cls_loss is : tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028524368584994437
now it is 18040 steps  and the cls_loss is : tensor(0.1991, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028506012082971026
now it is 18060 steps  and the cls_loss is : tensor(0.2029, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028487548092121693
now it is 18080 steps  and the cls_loss is : tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002846897675939543
now it is 18100 steps  and the cls_loss is : tensor(0.0646, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028450298232595523
now it is 18120 steps  and the cls_loss is : tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028431512660378375
now it is 18140 steps  and the cls_loss is : tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002841262019225234
now it is 18160 steps  and the cls_loss is : tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002839362097857651
now it is 18180 steps  and the cls_loss is : tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028374515170559536
now it is 18200 steps  and the cls_loss is : tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002835530292025842
now it is 18220 steps  and the cls_loss is : tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028335984380577304
now it is 18240 steps  and the cls_loss is : tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028316559705266254
now it is 18260 steps  and the cls_loss is : tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028297029048920033
now it is 18280 steps  and the cls_loss is : tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002827739256697688
now it is 18300 steps  and the cls_loss is : tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028257650415717244
now it is 18320 steps  and the cls_loss is : tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00282378027522626
now it is 18340 steps  and the cls_loss is : tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028217849734574123
now it is 18360 steps  and the cls_loss is : tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028197791521451486
now it is 18380 steps  and the cls_loss is : tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002817762827253159
now it is 18400 steps  and the cls_loss is : tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028157360148287256
now it is 18420 steps  and the cls_loss is : tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028136987310026
now it is 18440 steps  and the cls_loss is : tensor(0.1346, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028116509919888697
now it is 18460 steps  and the cls_loss is : tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028095928140848343
now it is 18480 steps  and the cls_loss is : tensor(0.0868, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002807524213670871
now it is 18500 steps  and the cls_loss is : tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0028054452072103085
now it is 18520 steps  and the cls_loss is : tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002803355811249292
now it is 18540 steps  and the cls_loss is : tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002801256042416654
now it is 18560 steps  and the cls_loss is : tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002799145917423782
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.22824651850677746
generate label finished(9.25/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:97.04, 91.63, 81.64
bev  AP:92.50, 85.03, 77.59
3d   AP:88.24, 78.03, 68.58
aos  AP:96.87, 90.89, 80.80
Car AP@0.70, 0.50, 0.50:
bbox AP:97.04, 91.63, 81.64
bev  AP:97.12, 91.91, 81.90
3d   AP:97.11, 91.88, 81.87
aos  AP:96.87, 90.89, 80.80

now it is 18580 steps  and the cls_loss is : tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002797025453064485
now it is 18600 steps  and the cls_loss is : tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002794894666214858
now it is 18620 steps  and the cls_loss is : tensor(0.1153, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002792753573833151
now it is 18640 steps  and the cls_loss is : tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027906021929596323
now it is 18660 steps  and the cls_loss is : tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027884405407164518
now it is 18680 steps  and the cls_loss is : tensor(0.1921, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002786268634307507
now it is 18700 steps  and the cls_loss is : tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002784086491018305
now it is 18720 steps  and the cls_loss is : tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027818941282158247
now it is 18740 steps  and the cls_loss is : tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002779691563348379
now it is 18760 steps  and the cls_loss is : tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002777478813945476
now it is 18780 steps  and the cls_loss is : tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002775255897617678
now it is 18800 steps  and the cls_loss is : tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002773022832056464
now it is 18820 steps  and the cls_loss is : tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002770779635034087
now it is 18840 steps  and the cls_loss is : tensor(0.1208, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002768526324403433
now it is 18860 steps  and the cls_loss is : tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027662629180978788
now it is 18880 steps  and the cls_loss is : tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027639894341311495
now it is 18900 steps  and the cls_loss is : tensor(0.0907, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002761705890597176
now it is 18920 steps  and the cls_loss is : tensor(0.0747, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027594123056699483
now it is 18940 steps  and the cls_loss is : tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027571086976033747
now it is 18960 steps  and the cls_loss is : tensor(0.0840, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027547950847311323
now it is 18980 steps  and the cls_loss is : tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002752471485466525
now it is 19000 steps  and the cls_loss is : tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027501379183023336
now it is 19020 steps  and the cls_loss is : tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002747794401810673
now it is 19040 steps  and the cls_loss is : tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027454409546428375
now it is 19060 steps  and the cls_loss is : tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027430775955291603
now it is 19080 steps  and the cls_loss is : tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027407043432788585
now it is 19100 steps  and the cls_loss is : tensor(0.0623, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027383212167798854
now it is 19120 steps  and the cls_loss is : tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002735928234998782
now it is 19140 steps  and the cls_loss is : tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027335254169805223
now it is 19160 steps  and the cls_loss is : tensor(0.0873, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002731112781848365
now it is 19180 steps  and the cls_loss is : tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027286903488037
now it is 19200 steps  and the cls_loss is : tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027262581371258953
now it is 19220 steps  and the cls_loss is : tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027238161661721433
now it is 19240 steps  and the cls_loss is : tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027213644553773088
now it is 19260 steps  and the cls_loss is : tensor(0.1163, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027189030242537717
now it is 19280 steps  and the cls_loss is : tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002716431892391274
now it is 19300 steps  and the cls_loss is : tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002713951079456761
now it is 19320 steps  and the cls_loss is : tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027114606051942287
now it is 19340 steps  and the cls_loss is : tensor(0.1196, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0027089604894245623
now it is 19360 steps  and the cls_loss is : tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002706450752045382
now it is 19380 steps  and the cls_loss is : tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002703931413030884
now it is 19400 steps  and the cls_loss is : tensor(0.1556, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002701402492431679
now it is 19420 steps  and the cls_loss is : tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002698864010374636
now it is 19440 steps  and the cls_loss is : tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00269631598706272
now it is 19460 steps  and the cls_loss is : tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002693758442774831
now it is 19480 steps  and the cls_loss is : tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002691191397865645
now it is 19500 steps  and the cls_loss is : tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002688614872765449
now it is 19520 steps  and the cls_loss is : tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026860288879799804
now it is 19540 steps  and the cls_loss is : tensor(0.3990, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002683433464090264
now it is 19560 steps  and the cls_loss is : tensor(0.2322, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002680828621752445
now it is 19580 steps  and the cls_loss is : tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026782143816976296
now it is 19600 steps  and the cls_loss is : tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026755907647317166
now it is 19620 steps  and the cls_loss is : tensor(0.1321, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026729577917352313
now it is 19640 steps  and the cls_loss is : tensor(0.3584, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026703154836631633
now it is 19660 steps  and the cls_loss is : tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026676638615447945
now it is 19680 steps  and the cls_loss is : tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026650029464835353
now it is 19700 steps  and the cls_loss is : tensor(0.1379, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026623327596567567
now it is 19720 steps  and the cls_loss is : tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026596533223156187
now it is 19740 steps  and the cls_loss is : tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026569646557849046
now it is 19760 steps  and the cls_loss is : tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002654266781462849
now it is 19780 steps  and the cls_loss is : tensor(0.1345, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026515597208209693
now it is 19800 steps  and the cls_loss is : tensor(0.2268, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002648843495403894
now it is 19820 steps  and the cls_loss is : tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026461181268291885
now it is 19840 steps  and the cls_loss is : tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00264338363678719
now it is 19860 steps  and the cls_loss is : tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026406400470408266
now it is 19880 steps  and the cls_loss is : tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00263788737942545
now it is 19900 steps  and the cls_loss is : tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00263512565584866
now it is 19920 steps  and the cls_loss is : tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026323548982901284
now it is 19940 steps  and the cls_loss is : tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002629575128801427
now it is 19960 steps  and the cls_loss is : tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026267863695058494
now it is 19980 steps  and the cls_loss is : tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002623988642598238
now it is 20000 steps  and the cls_loss is : tensor(0.1144, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002621181970344804
now it is 20020 steps  and the cls_loss is : tensor(0.1344, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026183663750829513
now it is 20040 steps  and the cls_loss is : tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026155418792211007
now it is 20060 steps  and the cls_loss is : tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00261270850523851
now it is 20080 steps  and the cls_loss is : tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002609866275685094
now it is 20100 steps  and the cls_loss is : tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026070152131812455
now it is 20120 steps  and the cls_loss is : tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002604155340417659
now it is 20140 steps  and the cls_loss is : tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0026012866801551435
now it is 20160 steps  and the cls_loss is : tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002598409255224447
now it is 20180 steps  and the cls_loss is : tensor(0.1253, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025955230885260725
now it is 20200 steps  and the cls_loss is : tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025926282030300954
now it is 20220 steps  and the cls_loss is : tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025897246217759812
now it is 20240 steps  and the cls_loss is : tensor(0.0963, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002586812367872402
now it is 20260 steps  and the cls_loss is : tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025838914644970546
now it is 20280 steps  and the cls_loss is : tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025809619348964707
now it is 20300 steps  and the cls_loss is : tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025780238023858384
now it is 20320 steps  and the cls_loss is : tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025750770903488125
now it is 20340 steps  and the cls_loss is : tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002572121822237329
now it is 20360 steps  and the cls_loss is : tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00256915802157142
now it is 20380 steps  and the cls_loss is : tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002566185711939025
now it is 20400 steps  and the cls_loss is : tensor(0.0946, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002563204916995803
now it is 20420 steps  and the cls_loss is : tensor(0.6423, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002560215660464946
now it is 20440 steps  and the cls_loss is : tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025572179661369886
now it is 20460 steps  and the cls_loss is : tensor(0.1739, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025542118578696185
now it is 20480 steps  and the cls_loss is : tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025511973595874877
now it is 20500 steps  and the cls_loss is : tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002548174495282022
now it is 20520 steps  and the cls_loss is : tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025451432890112296
now it is 20540 steps  and the cls_loss is : tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002542103764899509
now it is 20560 steps  and the cls_loss is : tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002539055947137459
now it is 20580 steps  and the cls_loss is : tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025359998599816837
now it is 20600 steps  and the cls_loss is : tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002532935527754602
now it is 20620 steps  and the cls_loss is : tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025298629748442504
now it is 20640 steps  and the cls_loss is : tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002526782225704093
now it is 20660 steps  and the cls_loss is : tensor(0.0551, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025236933048528253
now it is 20680 steps  and the cls_loss is : tensor(0.0807, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025205962368741778
now it is 20700 steps  and the cls_loss is : tensor(0.0571, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025174910464167213
now it is 20720 steps  and the cls_loss is : tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025143777581936723
now it is 20740 steps  and the cls_loss is : tensor(0.0824, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002511256396982693
now it is 20760 steps  and the cls_loss is : tensor(0.2287, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025081269876256968
now it is 20780 steps  and the cls_loss is : tensor(0.0985, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00250498955502865
now it is 20800 steps  and the cls_loss is : tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0025018441241613726
now it is 20820 steps  and the cls_loss is : tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024986907200573406
now it is 20840 steps  and the cls_loss is : tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024955293678134865
now it is 20860 steps  and the cls_loss is : tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024923600925899994
now it is 20880 steps  and the cls_loss is : tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002489182919610125
now it is 20900 steps  and the cls_loss is : tensor(0.1342, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024859978741599647
now it is 20920 steps  and the cls_loss is : tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024828049815882737
now it is 20940 steps  and the cls_loss is : tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024796042673062607
now it is 20960 steps  and the cls_loss is : tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002476395756787385
now it is 20980 steps  and the cls_loss is : tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002473179475567153
now it is 21000 steps  and the cls_loss is : tensor(0.1086, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002469955449242916
now it is 21020 steps  and the cls_loss is : tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024667237034736666
now it is 21040 steps  and the cls_loss is : tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002463484263979832
now it is 21060 steps  and the cls_loss is : tensor(0.1247, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024602371565430746
now it is 21080 steps  and the cls_loss is : tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00245698240700608
now it is 21100 steps  and the cls_loss is : tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002453720041272357
now it is 21120 steps  and the cls_loss is : tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00245045008530603
now it is 21140 steps  and the cls_loss is : tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024471725651316278
now it is 21160 steps  and the cls_loss is : tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024438875068338844
now it is 21180 steps  and the cls_loss is : tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002440594936557526
now it is 21200 steps  and the cls_loss is : tensor(0.0841, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024372948805070627
now it is 21220 steps  and the cls_loss is : tensor(0.0973, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002433987364946584
now it is 21240 steps  and the cls_loss is : tensor(0.1135, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002430672416199546
now it is 21260 steps  and the cls_loss is : tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002427350060648562
now it is 21280 steps  and the cls_loss is : tensor(0.0764, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002424020324735196
now it is 21300 steps  and the cls_loss is : tensor(0.0865, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024206832349597486
now it is 21320 steps  and the cls_loss is : tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024173388178810465
now it is 21340 steps  and the cls_loss is : tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024139871001162346
now it is 21360 steps  and the cls_loss is : tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024106281083405593
now it is 21380 steps  and the cls_loss is : tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024072618692871596
now it is 21400 steps  and the cls_loss is : tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024038884097468535
now it is 21420 steps  and the cls_loss is : tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0024005077565679234
now it is 21440 steps  and the cls_loss is : tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002397119936655905
now it is 21460 steps  and the cls_loss is : tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023937249769733705
now it is 21480 steps  and the cls_loss is : tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023903229045397155
now it is 21500 steps  and the cls_loss is : tensor(0.0562, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023869137464309445
now it is 21520 steps  and the cls_loss is : tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002383497529779454
now it is 21540 steps  and the cls_loss is : tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023800742817738168
now it is 21560 steps  and the cls_loss is : tensor(0.0942, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002376644029658567
now it is 21580 steps  and the cls_loss is : tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023732068007339814
now it is 21600 steps  and the cls_loss is : tensor(0.1700, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002369762622355863
now it is 21620 steps  and the cls_loss is : tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002366311521935324
now it is 21640 steps  and the cls_loss is : tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002362853526938565
now it is 21660 steps  and the cls_loss is : tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002359388664886662
now it is 21680 steps  and the cls_loss is : tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002355916963355339
now it is 21700 steps  and the cls_loss is : tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002352438449974757
now it is 21720 steps  and the cls_loss is : tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002348953152429289
now it is 21740 steps  and the cls_loss is : tensor(0.1179, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023454610984573
now it is 21760 steps  and the cls_loss is : tensor(0.1275, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023419623158509296
now it is 21780 steps  and the cls_loss is : tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023384568324558656
now it is 21800 steps  and the cls_loss is : tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023349446761711276
now it is 21820 steps  and the cls_loss is : tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023314258749488406
now it is 21840 steps  and the cls_loss is : tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023279004567940166
now it is 21860 steps  and the cls_loss is : tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002324368449764328
now it is 21880 steps  and the cls_loss is : tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023208298819698873
now it is 21900 steps  and the cls_loss is : tensor(0.1115, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00231728478157302
now it is 21920 steps  and the cls_loss is : tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002313733176788045
now it is 21940 steps  and the cls_loss is : tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023101750958810455
now it is 21960 steps  and the cls_loss is : tensor(0.2412, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002306610567169647
now it is 21980 steps  and the cls_loss is : tensor(0.1350, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0023030396190227916
now it is 22000 steps  and the cls_loss is : tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022994622798605106
now it is 22020 steps  and the cls_loss is : tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002295878578153699
now it is 22040 steps  and the cls_loss is : tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00229228854242389
now it is 22060 steps  and the cls_loss is : tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022886922012430276
now it is 22080 steps  and the cls_loss is : tensor(0.1497, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022850895832332387
now it is 22100 steps  and the cls_loss is : tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002281480717066605
now it is 22120 steps  and the cls_loss is : tensor(0.1197, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002277865631464935
now it is 22140 steps  and the cls_loss is : tensor(0.0554, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002274244355199537
now it is 22160 steps  and the cls_loss is : tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022706169170909865
now it is 22180 steps  and the cls_loss is : tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022669833460089027
now it is 22200 steps  and the cls_loss is : tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002263343670871711
now it is 22220 steps  and the cls_loss is : tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002259697920646421
now it is 22240 steps  and the cls_loss is : tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022560461243483886
now it is 22260 steps  and the cls_loss is : tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022523883110410906
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.2257476870598765
generate label finished(9.51/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:96.77, 91.47, 83.97
bev  AP:92.00, 87.00, 79.85
3d   AP:87.33, 77.34, 70.32
aos  AP:96.53, 90.72, 83.06
Car AP@0.70, 0.50, 0.50:
bbox AP:96.77, 91.47, 83.97
bev  AP:96.90, 94.17, 86.69
3d   AP:96.88, 94.11, 86.64
aos  AP:96.53, 90.72, 83.06

now it is 22280 steps  and the cls_loss is : tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022487245098358906
now it is 22300 steps  and the cls_loss is : tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022450547498918077
now it is 22320 steps  and the cls_loss is : tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022413790604152847
now it is 22340 steps  and the cls_loss is : tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022376974706599575
now it is 22360 steps  and the cls_loss is : tensor(0.1073, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022340100099264163
now it is 22380 steps  and the cls_loss is : tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002230316707561981
now it is 22400 steps  and the cls_loss is : tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00222661759296046
now it is 22420 steps  and the cls_loss is : tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002222912695561922
now it is 22440 steps  and the cls_loss is : tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002219202044852456
now it is 22460 steps  and the cls_loss is : tensor(0.1040, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022154856703639433
now it is 22480 steps  and the cls_loss is : tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002211763601673816
now it is 22500 steps  and the cls_loss is : tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002208035868404826
now it is 22520 steps  and the cls_loss is : tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0022043025002248073
now it is 22540 steps  and the cls_loss is : tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002200563526846441
now it is 22560 steps  and the cls_loss is : tensor(0.0597, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021968189780270167
now it is 22580 steps  and the cls_loss is : tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021930688835681993
now it is 22600 steps  and the cls_loss is : tensor(0.1136, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021893132733157876
now it is 22620 steps  and the cls_loss is : tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021855521771594806
now it is 22640 steps  and the cls_loss is : tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002181785625032636
now it is 22660 steps  and the cls_loss is : tensor(0.0576, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002178013646912035
now it is 22680 steps  and the cls_loss is : tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002174236272817643
now it is 22700 steps  and the cls_loss is : tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021704535328123695
now it is 22720 steps  and the cls_loss is : tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021666654570018282
now it is 22740 steps  and the cls_loss is : tensor(0.6382, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021628720755341017
now it is 22760 steps  and the cls_loss is : tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021590734185994967
now it is 22780 steps  and the cls_loss is : tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002155269516430306
now it is 22800 steps  and the cls_loss is : tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021514603993005683
now it is 22820 steps  and the cls_loss is : tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021476460975258242
now it is 22840 steps  and the cls_loss is : tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021438266414628804
now it is 22860 steps  and the cls_loss is : tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002140002061509562
now it is 22880 steps  and the cls_loss is : tensor(0.0825, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002136172388104476
now it is 22900 steps  and the cls_loss is : tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021323376517267648
now it is 22920 steps  and the cls_loss is : tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021284978828958667
now it is 22940 steps  and the cls_loss is : tensor(0.0826, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021246531121712703
now it is 22960 steps  and the cls_loss is : tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002120803370152273
now it is 22980 steps  and the cls_loss is : tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021169486874777384
now it is 23000 steps  and the cls_loss is : tensor(0.2026, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021130890948258497
now it is 23020 steps  and the cls_loss is : tensor(0.0949, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002109224622913868
now it is 23040 steps  and the cls_loss is : tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002105355302497886
now it is 23060 steps  and the cls_loss is : tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0021014811643725846
now it is 23080 steps  and the cls_loss is : tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020976022393709875
now it is 23100 steps  and the cls_loss is : tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002093718558364216
now it is 23120 steps  and the cls_loss is : tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002089830152261241
now it is 23140 steps  and the cls_loss is : tensor(0.0965, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002085937052008641
now it is 23160 steps  and the cls_loss is : tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020820392885903525
now it is 23180 steps  and the cls_loss is : tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002078136893027426
now it is 23200 steps  and the cls_loss is : tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020742298963777757
now it is 23220 steps  and the cls_loss is : tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020703183297359367
now it is 23240 steps  and the cls_loss is : tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020664022242328135
now it is 23260 steps  and the cls_loss is : tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020624816110354337
now it is 23280 steps  and the cls_loss is : tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002058556521346702
now it is 23300 steps  and the cls_loss is : tensor(0.1002, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002054626986405149
now it is 23320 steps  and the cls_loss is : tensor(0.1553, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002050693037484683
now it is 23340 steps  and the cls_loss is : tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002046754705894343
now it is 23360 steps  and the cls_loss is : tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002042812022978047
now it is 23380 steps  and the cls_loss is : tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020388650201143455
now it is 23400 steps  and the cls_loss is : tensor(0.1337, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020349137287161683
now it is 23420 steps  and the cls_loss is : tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020309581802305777
now it is 23440 steps  and the cls_loss is : tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002026998406138515
now it is 23460 steps  and the cls_loss is : tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020230344379545536
now it is 23480 steps  and the cls_loss is : tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002019066307226646
now it is 23500 steps  and the cls_loss is : tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002015094045535872
now it is 23520 steps  and the cls_loss is : tensor(0.0854, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0020111176844961895
now it is 23540 steps  and the cls_loss is : tensor(0.0944, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002007137255754181
now it is 23560 steps  and the cls_loss is : tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.002003152790988803
now it is 23580 steps  and the cls_loss is : tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001999164321911133
now it is 23600 steps  and the cls_loss is : tensor(0.1964, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001995171880264119
now it is 23620 steps  and the cls_loss is : tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019911754978223233
now it is 23640 steps  and the cls_loss is : tensor(0.0746, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019871752063916727
now it is 23660 steps  and the cls_loss is : tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001983171037809205
now it is 23680 steps  and the cls_loss is : tensor(0.1347, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019791630239428134
now it is 23700 steps  and the cls_loss is : tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001975151196690997
now it is 23720 steps  and the cls_loss is : tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019711355879826016
now it is 23740 steps  and the cls_loss is : tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00196711622977657
now it is 23760 steps  and the cls_loss is : tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019630931540616857
now it is 23780 steps  and the cls_loss is : tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001959066392856319
now it is 23800 steps  and the cls_loss is : tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001955035978208171
now it is 23820 steps  and the cls_loss is : tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019510019421940207
now it is 23840 steps  and the cls_loss is : tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019469643169194668
now it is 23860 steps  and the cls_loss is : tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001942923134518675
now it is 23880 steps  and the cls_loss is : tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001938878427154121
now it is 23900 steps  and the cls_loss is : tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019348302270163337
now it is 23920 steps  and the cls_loss is : tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019307785663236399
now it is 23940 steps  and the cls_loss is : tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001926723477321909
now it is 23960 steps  and the cls_loss is : tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019226649922842942
now it is 23980 steps  and the cls_loss is : tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019186031435109764
now it is 24000 steps  and the cls_loss is : tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001914537963328909
now it is 24020 steps  and the cls_loss is : tensor(0.1858, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019104694840915576
now it is 24040 steps  and the cls_loss is : tensor(0.1137, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0019063977381786443
now it is 24060 steps  and the cls_loss is : tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001902322757995889
now it is 24080 steps  and the cls_loss is : tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018982445759747535
now it is 24100 steps  and the cls_loss is : tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018941632245721804
now it is 24120 steps  and the cls_loss is : tensor(0.0888, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001890078736270338
now it is 24140 steps  and the cls_loss is : tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018859911435763592
now it is 24160 steps  and the cls_loss is : tensor(0.1749, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018819004790220839
now it is 24180 steps  and the cls_loss is : tensor(0.1889, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018778067751638
now it is 24200 steps  and the cls_loss is : tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018737100645819839
now it is 24220 steps  and the cls_loss is : tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018696103798810425
now it is 24240 steps  and the cls_loss is : tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018655077536890517
now it is 24260 steps  and the cls_loss is : tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018614022186574984
now it is 24280 steps  and the cls_loss is : tensor(0.0625, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00185729380746102
now it is 24300 steps  and the cls_loss is : tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018531825527971443
now it is 24320 steps  and the cls_loss is : tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018490684873860286
now it is 24340 steps  and the cls_loss is : tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001844951643970202
now it is 24360 steps  and the cls_loss is : tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018408320553143006
now it is 24380 steps  and the cls_loss is : tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.00183670975420481
now it is 24400 steps  and the cls_loss is : tensor(0.1068, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018325847734498033
now it is 24420 steps  and the cls_loss is : tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018284571458786806
now it is 24440 steps  and the cls_loss is : tensor(0.2177, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018243269043419059
now it is 24460 steps  and the cls_loss is : tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018201940817107484
now it is 24480 steps  and the cls_loss is : tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0018160587108770178
now it is 24500 steps  and the cls_loss is : tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001811920824752806
now it is 24520 steps  and the cls_loss is : tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001807780456270221
now it is 24540 steps  and the cls_loss is : tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001803637638381129
now it is 24560 steps  and the cls_loss is : tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017994924040568897
now it is 24580 steps  and the cls_loss is : tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001795344786288094
now it is 24600 steps  and the cls_loss is : tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017911948180843024
now it is 24620 steps  and the cls_loss is : tensor(0.0713, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017870425324737812
now it is 24640 steps  and the cls_loss is : tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017828879625032413
now it is 24660 steps  and the cls_loss is : tensor(0.2105, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017787311412375726
now it is 24680 steps  and the cls_loss is : tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017745721017595833
now it is 24700 steps  and the cls_loss is : tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001770410877169735
now it is 24720 steps  and the cls_loss is : tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017662475005858812
now it is 24740 steps  and the cls_loss is : tensor(0.1681, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017620820051430007
now it is 24760 steps  and the cls_loss is : tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017579144239929369
now it is 24780 steps  and the cls_loss is : tensor(0.3187, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017537447903041325
now it is 24800 steps  and the cls_loss is : tensor(0.1181, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001749573137261365
now it is 24820 steps  and the cls_loss is : tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017453994980654835
now it is 24840 steps  and the cls_loss is : tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017412239059331448
now it is 24860 steps  and the cls_loss is : tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017370463940965485
now it is 24880 steps  and the cls_loss is : tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017328669958031715
now it is 24900 steps  and the cls_loss is : tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017286857443155057
now it is 24920 steps  and the cls_loss is : tensor(0.0989, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001724502672910791
now it is 24940 steps  and the cls_loss is : tensor(0.0778, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017203178148807521
now it is 24960 steps  and the cls_loss is : tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001716131203531332
now it is 24980 steps  and the cls_loss is : tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017119428721824293
now it is 25000 steps  and the cls_loss is : tensor(0.0536, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017077528541676297
now it is 25020 steps  and the cls_loss is : tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0017035611828339439
now it is 25040 steps  and the cls_loss is : tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016993678915415405
now it is 25060 steps  and the cls_loss is : tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016951730136634806
now it is 25080 steps  and the cls_loss is : tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016909765825854524
now it is 25100 steps  and the cls_loss is : tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001686778631705506
now it is 25120 steps  and the cls_loss is : tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016825791944337861
now it is 25140 steps  and the cls_loss is : tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016783783041922687
now it is 25160 steps  and the cls_loss is : tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016741759944144921
now it is 25180 steps  and the cls_loss is : tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016699722985452925
now it is 25200 steps  and the cls_loss is : tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016657672500405385
now it is 25220 steps  and the cls_loss is : tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016615608823668626
now it is 25240 steps  and the cls_loss is : tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016573532290013971
now it is 25260 steps  and the cls_loss is : tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016531443234315067
now it is 25280 steps  and the cls_loss is : tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016489341991545205
now it is 25300 steps  and the cls_loss is : tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016447228896774688
now it is 25320 steps  and the cls_loss is : tensor(0.0546, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016405104285168138
now it is 25340 steps  and the cls_loss is : tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016362968491981835
now it is 25360 steps  and the cls_loss is : tensor(0.0774, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001632082185256105
now it is 25380 steps  and the cls_loss is : tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016278664702337375
now it is 25400 steps  and the cls_loss is : tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016236497376826058
now it is 25420 steps  and the cls_loss is : tensor(0.0736, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016194320211623322
now it is 25440 steps  and the cls_loss is : tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016152133542403707
now it is 25460 steps  and the cls_loss is : tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016109937704917386
now it is 25480 steps  and the cls_loss is : tensor(0.1056, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016067733034987506
now it is 25500 steps  and the cls_loss is : tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0016025519868507509
now it is 25520 steps  and the cls_loss is : tensor(0.0820, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015983298541438454
now it is 25540 steps  and the cls_loss is : tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015941069389806349
now it is 25560 steps  and the cls_loss is : tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015898832749699473
now it is 25580 steps  and the cls_loss is : tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001585658895726571
now it is 25600 steps  and the cls_loss is : tensor(0.0694, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015814338348709856
now it is 25620 steps  and the cls_loss is : tensor(0.1800, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001577208126029096
now it is 25640 steps  and the cls_loss is : tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015729818028319652
now it is 25660 steps  and the cls_loss is : tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015687548989155441
now it is 25680 steps  and the cls_loss is : tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015645274479204065
now it is 25700 steps  and the cls_loss is : tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001560299483491479
now it is 25720 steps  and the cls_loss is : tensor(0.0693, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015560710392777761
now it is 25740 steps  and the cls_loss is : tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015518421489321293
now it is 25760 steps  and the cls_loss is : tensor(0.1116, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001547612846110921
now it is 25780 steps  and the cls_loss is : tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001543383164473817
now it is 25800 steps  and the cls_loss is : tensor(0.1565, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001539153137683498
now it is 25820 steps  and the cls_loss is : tensor(0.0839, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015349227994053904
now it is 25840 steps  and the cls_loss is : tensor(0.1328, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001530692183307401
now it is 25860 steps  and the cls_loss is : tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015264613230596474
now it is 25880 steps  and the cls_loss is : tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015222302523341896
now it is 25900 steps  and the cls_loss is : tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.001517999004804764
now it is 25920 steps  and the cls_loss is : tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015137676141465121
now it is 25940 steps  and the cls_loss is : tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015095361140357165
now it is 25960 steps  and the cls_loss is : tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015053045381495302
now it is 25980 steps  and the cls_loss is : tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0015010729201657092
#################################
# EVAL
#################################
Generate output labels...
validation_loss: 0.23373750276948146
generate label finished(9.64/s). start eval:
Car AP@0.70, 0.70, 0.70:
bbox AP:95.91, 92.71, 87.54
bev  AP:91.63, 88.17, 83.34
3d   AP:87.30, 76.86, 71.77
aos  AP:95.72, 91.96, 86.57
Car AP@0.70, 0.50, 0.50:
bbox AP:95.91, 92.71, 87.54
bev  AP:96.21, 95.34, 90.33
3d   AP:96.20, 95.06, 90.15
aos  AP:95.72, 91.96, 86.57

now it is 26000 steps  and the cls_loss is : tensor(0.5802, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014968412937623446
now it is 26020 steps  and the cls_loss is : tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014926096926175941
now it is 26040 steps  and the cls_loss is : tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>) learning_rate:  0.0014883781504094152
